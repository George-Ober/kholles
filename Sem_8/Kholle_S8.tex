\documentclass{article}
\date{19 novembre 2023}

\usepackage{../kholles}

\begin{document}
	\maketitle
	
	\flushleft
	
	\begin{question_kholle}{Preuve de l’expression des solutions réelles des EDL homogènes d’ordre 2 à coefficients constants réels dans le cas $\Delta < 0$ (en admettant la connaissance de l’expression des solutions à valeurs complexes des EDLH2 à coeff. constants).}
		Notons $\Sol_{H, \C}$ et $\Sol_{H, \R}$ les ensembles des solutions complexes et réelles de l'équation différentielle, puisque nous nous plaçons dans le cas $\Delta = 0$ et $\alpha \pm i \beta$ les deux racines complexes conjuguées.
		$$
		\Sol_{H, \C} = 
		\left\{
		\begin{array}{l}
	    \R \to \C  \\
	    t \mapsto \lambda e^{(\alpha + i \beta) t}  + \mu e^{(\alpha - i \beta)t}
    	\end{array}
		\middle\vert  (\lambda, \mu) \in \C ^2 \right\}	
		$$
		
		Montrons que $\forall f \in \Sol_{H ,\C}, \Re(f) \in  \Sol_{H ,\R}$\\
		Soit $f \in \Sol_{H ,\C}$ fq.
		$$f \in \mathcal D^2(\R, \C) \implies \Re(f) \in \mathcal D^2(\R, \R)$$
		Et, de plus, par morphisme additif de \Re
		$$
		a_2\Re(f)'' + a_1\Re(f)' + a_0\Re(f) = \Re( a_2 f'' + a_1 f' + a_0 f) = 0
		$$
		D'où, avec $f:t \mapsto e^{(\alpha + i \beta)t}$; $\Re(f(t)) = \Re(e^{(\alpha + i \beta)t}) = e^{\alpha t } \cos (\beta t)$. Qui appartient donc à $\Sol_{H, \R}$\\
		En suivant le même raisonnement pour $\Im(f)$, $(t \mapsto e^\alpha \sin(\beta t)) \in \Sol_{H, \R}$
		
		
		Ainsi, par combinaison linéaire (qui se base sur le principe de superposition),
		$$
		\left\{ 
		\begin{array}{l}
	    \R \to \R  \\
	    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
	  	\end{array}
		\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
		\subset \Sol_{H ,\R}
		$$
		
		Réciproquement, soit $ f \in \Sol_{H ,\R}$ fq. Puisque $\R \subset \C$,  $ f \in \Sol_{H ,\C}$.
		
		$$
		\exists (a, b) \in \C^2 : f \left| \begin{array}{l}
	    \R \to \C  \\
	    t \mapsto a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t}
		\end{array}\right.$$
	
		Or, puisque toutes les valeurs de $f$ sont réelles, en notant $(a_r, a_i, b_r, b_i)$ les parties réelles et imaginaires respectives de $a$ et $b$.
		\begin{align*}
			\forall t \in \R, f(t) &= \Re(f(t)) \\
					&= \Re(a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t})\\
					&= \Re((a_r + i a_i) e^{(\alpha + i \beta) t}  + (b_r + i b_i) e^{(\alpha - i \beta)t})\\
				    &= a_r \cos(\beta t)e^\alpha - a_i\sin(\beta t)e^\alpha + b_r \cos(\beta t)e^\alpha + b_i \sin(\beta t) e^\alpha \\
				    &= (a_r + b_r) \cos(\beta t) e^\alpha + (b_i - a_i) \sin(\beta t) e^\alpha
		\end{align*}
		Ainsi,
		$$f\in \left\{ 
		\begin{array}{l}
	    \R \to \R  \\
	    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
	  \end{array}
		\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
	$$
	Ce qui conclut la preuve par double inclusion.
	\end{question_kholle}
	
	\begin{question_kholle}[
		Considérons le problème de Cauchy suivant :
		$$\left\{ \begin{array}{l}
			a_{2}y''+a_{1}y'+a_{0}y = b \text{ sur } J  \\
			y(t_{0}) = \alpha_{0} \\
			y'(t_{0}) = \alpha_{1}
		\end{array} \right. \text{ où } (\alpha_{0}, \alpha_{1}) \in \mathbb{K}^{2}, t_{0} \in J, (a_{0}, a_{1}, a_{2}) \in \mathbb{K}^{2} \times \mathbb{K}^{*}, b \in \mathcal{F}(J, \mathbb{K})$$
		Si $b$ est continu sur $J$, alors ce problème de Cauchy admet une unique solution définie sur $J$.
		]
		{Existence et unicité d'une solution au problème de Cauchy pour les EDL d'ordre 2 à coefficients constants et second membre continu sur $I$ (cas complexe puis cas réel).}
	 
	\textbf{Cas 1. } $\mathbb{K} = \mathbb{C}$ \\
	Nous savons que sous l'hyphothèse de continuité de $b$ sur $J$, les solutions de (EDL2) définies sur $J$ constituent le plan affine $S$ :
	$$S = \left\{ \lambda f_{1} + \mu f_{2} + s | (\lambda, \mu) \in \mathbb{C}^{2} \right\}$$
	où $s$ est une solution particulière de (EDL2), $(f_{1}, f_{2})$ sont deux solutions de (EDLH2) qui engendrent $S_{h}$. On a : \\
	
	$$\begin{array}{ccl}
	    f : J \to \mathbb{C} \text{ est sol. du pb de Cauchy } 
	    &\iff &\left\{ \begin{array}{l}
	      f \text{ sol de (EDL2) sur } J    \\
	      f(t_{0}) = \alpha_{0}    \\
	      f'(t_{0}) = \alpha_{1}
	    \end{array}  \right. \\\\
	    &\iff &\left\{ \begin{array}{l}
	      f \in S    \\
	      f(t_{0}) = \alpha_{0}    \\
	      f'(t_{0}) = \alpha_{1}
	    \end{array}\right. \\\\
	    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
	      f = \lambda f_{1} + \mu f_{2} + s \\
	      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) + s(t_{0}) = \alpha_{0} \\
	      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) + s'(t_{0}) = \alpha_{1} \\
	    \end{array} \right. \\\\
	    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
	      f = \lambda f_{1} + \mu f_{2} + s \\
	      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) = \alpha_{0} - s(t_{0}) \\
	      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) = \alpha_{1} - s'(t_{0}) \\
	    \end{array} \right. \\\\
	\end{array} $$
	On en déduit donc que $(\lambda, \mu)$ doit être solution d'un système linéaire $(2,2)$. On a une unique solution si et seulement si les déterminant de ce système est nul. \\
	Explicitons alors le déterminant de ce système, que l'on notera $D$.
	$$D = \left| 
	\begin{array}{cc}
	f_{1}(t_{0}) &f_{2}(t_{0}) \\
	f'_{1}(t_{0}) &f'_{2}(t_{0}) \\
	\end{array}
	\right| = f_{1}(t_{0}) \cdot f'_{2}(t_{0}) - f_{2}(t_{0}) \cdot f'_{1}(t_{0}) $$
	Notons $\Delta$ le discriminant de l'équation caractéristique de (EDL2) ($a_{2}r^{2} + a_{1}r^{1} + a_{0} = 0$). On distingue alors deux cas selon la nullité ou non de $\Delta$. Traitons d'abord le cas $\Delta \neq 0$. On peut choisir : 
	$$ f_{1}(t_{0}) = e^{r_{1}t_{0}} \text{ et } f_{2}(t_{0}) = e^{r_{2}t_{0}}$$
	$$ f'_{1}(t_{0}) = r_{1}e^{r_{1}t_{0}} \text{ et } f'_{2}(t_{0}) = r_{2}e^{r_{2}t_{0}}$$
	Donc (en sachant que $\Delta \neq 0 \Rightarrow r_{1} \neq r_{2}$):
	$$ D = e^{r_{1}t_{0}} \cdot r_{2}e^{r_{2}t_{0}} - r_{1}e^{r_{1}t_{0}} \cdot e^{r_{2}t_{0}} = (r_{2} - r_{1}) \cdot e^{r_{1}t_{0} + r_{2}t_{0}} \neq 0$$
	
	Dans le deuxième cas, on a $\Delta = 0$ ; on peut alors prendre :
	$$ f_{1}(t_{0}) = e^{r_{0}t_{0}} \text{ et } f_{2}(t_{0}) = t_{0}e^{r_{0}t_{0}}$$
	Ainsi : 
	$$ D = e^{r_{0}t_{0}} \left(r_{0}t_{0}e^{r_{0}t_{0}} + e^{r_{0}t_{0}} \right) - r_{0}e^{r_{0}t_{0}} \times t_{0}e^{r_{0}t_{0}} = e^{2r_{0}t_{0}} \neq 0$$
	On remarque alors que, dans les deux cas, $D \neq 0$, donc le système $(2, 2)$ étudié admet une unique solution, donc il existe un unique couple $(\lambda, \mu)$ le vérifiant d'où l'unicité et existence d'une solution au problème de Cauchy. 
	\newline\newline
	
	\textbf{Cas 2. } $\mathbb{K} = \mathbb{R}$ \\
	$(a_{0}, a_{1}, a_{2}) \in \mathbb{R}^{2} \times \mathbb{R}^{*},(\alpha_{0}, \alpha_{1}) \in \mathbb{R}^{2}, b \in C^{0}(J, \mathbb{R})$ 
	\newline
	\textbf{Existence :} Puisque $\mathbb{R} \subset \mathbb{C}$, le problème de Cauchy admet, dans $\mathbb{R}$, une solution à valeurs complexes $g$. Posons $f = \Re(g)$ et montrons que $f$ est une solution réelle du problème de Cauchy. \\
	\begin{itemize}
	    \item[$\star$] $g \in \mathcal{D}^{2}(J, \mathbb{C}) \text{ donc } f \in \mathcal{D}^{2}(J, \mathbb{R})$
	    \item[$\star$] $g$ vérifie $a_{2}g'' + a_{1}g' + a_{0}g = b$ sur $J$ donc en prenant $\Re(\cdot)$ : 
	    $$\begin{array}{ccl}
	      \Re(a_{2}g'' + a_{1}g' + a_{0}g = b) = \Re(b)   
	      &\iff &a_{2}\Re(g'') + a_{1}\Re(g') + a_{0}\Re(g) = b  \\\\
	      &\iff & a_{2}f'' + a_{1}f' + a_{0}f = b \text{ sur } J
	    \end{array}$$
	    \item[$\star$] $f(t_{0}) = \Re(g(t_{0})) = \Re(\alpha_{0}) = \alpha_{0}$
	    \item[$\star$] $f'(t_{0}) = \Re(g(t_{0}))' = \Re(g'(t_{0})) = \Re(\alpha_{1}) = \alpha_{1}$
	\end{itemize}
	Donc $f$ est une solution réelle définie sur $J$ au problème de Cauchy. 
	\newline
	
	\textbf{Unicité : }Soient $f_{1}$ et $f_{2}$ deux fonctions à valeurs réelles solutions du problème de Cauchy ci-dessus fixées quelconques : puisque $\mathbb{R} \subset \mathbb{C}$, $f_{1}$ et $f_{2}$ sont des fonctions à valeurs dans $\mathbb{C}$ solutions du même problème de Cauchy; or il y a unicité de la solution au problème de Cauchy dans les fonctions à valeurs complexes, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{C})$, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{R})$.
	\end{question_kholle}
	
	\begin{question_kholle}[
		Soient $(a,b)\in \mathbb{C}^2$, $f$ et $g$ les  solutions, définies sur $\mathbb{R}$ à valeurs
		dans $\mathbb{C}$, des problèmes de Cauchy suivants :
		\[
		    \left\{ \begin{array}{cl}
		        y'' +ay'+by = 0 \\
		        y(3) = 1\\
		        y'(3) = 0
		        \end{array} \right.        
			\quad \text{et} \quad
		    \left\{ \begin{array}{cl}
		        y'' +ay'+by = 0 \\
		        y(3) = 0\\
		        y'(3) = 1
		        \end{array} \right.
		\]
		
		Comment s'exprime la solution définie sur $\mathbb{R}$ de $\left\{ \begin{array}{cl}
		    y'' +ay'+by = 0 \\
		    y(3) = \alpha \\
		    y'(3) = \beta
		    \end{array} \right. $ pour $(\alpha, \beta)\in \mathbb{R}^2$ fixés ? 
		
		Peut-on affirmer que le plan vectoriel des solutions définies sur $\mathbb{R}$ à valeurs dans 
		$\mathbb{C}$ de $y'' + ay' + by = 0$ est $\{ \lambda \cdot f + \mu \cdot g  | 
		(\lambda, \mu)\in \mathbb{C}^2\}$
		]
		{Les solutions d'une EDL$_2$ constituent un espace vectoriel.}
	
	    La solution s'exprime simplement comme combinaison linéaire de f et g, plus précisément, la 
	    combinaison linéaire en $\alpha$ et $\beta$. En effet, soient de tels scalaires, et soient $f$ et 
	    $g$ de telles solutions, on a : 
	    \[
	        (\alpha \cdot f + \beta \cdot g)'' + a (\alpha \cdot f + \beta \cdot g)' + b (\alpha \cdot f + 
	        \beta \cdot g) = 0 \text{, par définition des espaces vectoriels.}
	    \]
	    Et de même, $(\alpha \cdot f + \beta \cdot g)'(3) = \alpha \cdot f'(3) + \beta \cdot g'(3) = \alpha$,
	    et $(\alpha \cdot f + \beta \cdot g)''(3) = \alpha \cdot f''(3) + \beta \cdot g''(3) = \beta$.
	    \newline
	    Ce qui suffit par unicité des solutions ( de la donc) d'un problème de Cauchy dans le cadre du 
	    théorème du cours.
	    \newline
	    Pour ce qui est du plan vectoriel des solutions, noté $\Omega$, notons aussi $\Phi$ l'ensemble proposé.
	    L'inclusion $\Phi \subset \Omega$ est triviale par propriété de linéarité des espaces vectoriels.
	    Finalement, pour $\Omega \subset \Phi$, soit $\omega \in \Omega$, forcément, $\omega$ vérifie 
	    l'$EDL_2$, mais aussi des conditions de Cauchy bien que celles-ci soient non-spécifiées, ainsi
	    posons $\omega'(3) = \delta$ et $\omega''(3) = \theta$, donc en particulier, $ \omega = 
	    \delta \cdot f + \theta \cdot g$, d'où l'égalité par double inclusion.
	\end{question_kholle}

	\begin{question_kholle}
		[
		Résolution générale des systèmes linéaires à 2 équations et 2 inconnues en fonction du déterminant du systèmes (\textbf{tous les cas ne sont pas nécessairement à envisager})
		
		Considérons le système linéaire à deux équations et à deux inconnues $(x,y)$ :
		\begin{equation}
			(S)
			\left\{
				\begin{matrix}
					ax + by = b_1 &(E_1) \\
					cx + dy = b_2 &(E_2)
				\end{matrix}
			\right.
		\end{equation}
		dont $(a,b,c,d) \in \K^4$ sont les coefficients et $(b_1,b_2) \in \K^2$ sont les seconds membres.
		
		\begin{enumerate}
			\item (S) admet une unique solution si et seulement si
			$\begin{vmatrix}
				a & b \\
				c & d
			\end{vmatrix}
			= ad - bc \neq 0$. De plus, dans ce cas, la solution est
			\begin{equation}
				\left(
					\frac
						{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}
						{\begin{vmatrix}a&b\\c&d\end{vmatrix}},
					\frac
						{\begin{vmatrix}a&b_1\\c&b_2\end{vmatrix}}
						{\begin{vmatrix}a&b\\c&d\end{vmatrix}}
				\right)
			\end{equation}
			\item Si $ad - bc = 0$, alors l'ensemble des solutions est soit vide, soit une droite affine de $\K^2$, soit $\K^2$.
		\end{enumerate}
		]
		{Formules de Cramer pour les systèmes 2 $\times$ 2}
		Procédons par disjonction de cas.
		
		\begin{itemize}[label=$\bullet$ Supposons]
			\item que $ad - bc \neq 0$.
			\begin{itemize}[label=$\bullet$ Supposons]
				\item que $a \neq 0$.
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{
							\begin{array}{cccccc}
								ax &+& by &=& b_1 \\
								&&\left(d - \frac{bc}{a}\right)y &=& b_2 - \frac{c}{a} b_1 &(L_1 \leftarrow L_1 - \frac{c}{a} L_2) \\
							\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{cccccc}
							ax &+& by &=& b_1 \\
							&&\left(ad - bc\right)y &=& a b_2 - c b_1 &(L_1 \leftarrow aL_1) \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccc}
							ax &=& \frac{1}{a} \left(b_1 - b\frac{ab_2 - cb_1}{ad - bc}\right) = \frac{1}{a} \frac{adb_1 - bcb_1 + abb_2 - bcb_2}{ad - bc} \\
							y &=& \frac{ab_2 - cb_1}{ad - bc} \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccccc}
							ax &=& \frac{db_1 - bb_2}{ad - bc} &=& \frac{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}{\begin{vmatrix}a&b\\c&d\end{vmatrix}} \\
							y &=& \frac{ab_2 - cb_1}{ad - bc} &=& \frac{\begin{vmatrix}a&b_1\\c&b_2\end{vmatrix}}{\begin{vmatrix}a&b\\c&d\end{vmatrix}}\\
						\end{array}
						\right.
					\end{aligned}
				\end{equation*}
				Donc le système admet une unique solution qui est celle annoncée.
				
				\item que a = 0. L'hypothèse $ad - bc \neq 0$ implique $bc \neq 0$ donc $b \neq 0$ et $c \neq 0$.
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{
						\begin{array}{ccccc}
							&& by &=& b_1 \\
							cx &+& dy &=&  b_2 \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccc}
							x &=&  \frac{1}{c} \left( b_2 - d\frac{b_1}{b} \right) \\
							y &=& \frac{b_1}{b} \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccccc}
							ax &=& \frac{db_1 - bb_2}{- bc} &=& \frac{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}{\begin{vmatrix}0&b\\c&d\end{vmatrix}} \\
							y &=& \frac{- cb_1}{- bc} &=& \frac{\begin{vmatrix}0&b_1\\c&b_2\end{vmatrix}}{\begin{vmatrix}0&b\\c&d\end{vmatrix}}\\
						\end{array}
						\right.
					\end{aligned}
				\end{equation*}
			\end{itemize}
			Donc le système admet une unique solution qui est celle annoncée.
		\end{itemize}
	
		\item $ad - bc = 0$.
		\begin{itemize}[label=$\bullet$ Supposons]
			\item $a \neq 0$. En reprenant la méthode pivot de Gauss,
			\begin{equation*}
				\begin{aligned}
					(S)
					&\iff \left\{
					\begin{array}{cccccc}
						ax &+& by &=& b_1 \\
						&&\left(d - \frac{bc}{a}\right)y &=& b_2 - \frac{c}{a} b_1 &(L_1 \leftarrow L_1 - \frac{c}{a} L_2) \\
					\end{array}
					\right. \\
					&\iff \left\{
					\begin{array}{cccccc}
						ax &+& by &=& b_1 \\
						&& \underbrace{\left(ad - bc\right)}_0 y &=& a b_2 - c b_1 &(L_1 \leftarrow aL_1) \\
					\end{array}
					\right. \\
				\end{aligned}
			\end{equation*}
			Donc le système est de rang 1 avec une condition de compatibilité. \\
			Si $ab_2 - cb_1 \neq 0$, (S) n'admet aucune solution. \\
			Sinon $ab_2 - cb_1 = 0$
			\begin{equation}
				(S) \iff
				ax + by = b_1 \iff
				\begin{pmatrix} x \\ y \end{pmatrix} \in \left\{
					\begin{pmatrix} \frac{b_1}{a} - b\frac{t}{a} \\ t \end{pmatrix}
					|\; t \in \K
				\right\}
			\end{equation}
			Donc (S) admet un droite affine de solutions.
			
			\item $a = 0$. Puisque $ad - bc = 0$, alors $bc = 0$ donc b ou c est nul.
			
			\begin{itemize}[label=$\bullet$ Si]
				\item $c = 0$,
				\begin{equation*}
					(S) \iff
					\left\{ \begin{array}{ccc}
							by &=& b_1 \\
							dy &=& b_2
					\end{array} \right.
				\end{equation*}
				
				\begin{itemize}[label=$\bullet$ Si]
					\item $b = 0$, 
					\begin{equation*}
						(S) \iff
						\left\{ \begin{array}{ccc}
							by &=& b_1 \\
							0 &=& b_2
						\end{array} \right.
					\end{equation*}
					\begin{itemize}[label=$\bullet$ Si]
						\item $b_2 = 0$, (S) n'admet aucune solution.
						\item $b_2 \neq 0$, $(S) \iff dy = b_2$
							\subitem$\bullet$ Si $d = 0$, $(S) \iff 0 = b_2$. (S) n'admet aucune solution ($b_2 \neq 0$) ou admet $\K^2$ comme ensemble des solutions ($b_2 = 0$).
							\subitem$\bullet$ Si $d \neq 0$, $(S) \iff y = \frac{b_2}{d} \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} t \\ \frac{b_2}{d} \end{pmatrix} |\; t \in \K \end{Bmatrix}$. Donc (S) admet une droite affine de solutions.
					\end{itemize}
					\item $b \neq 0$
					\begin{equation*}
						(S) \iff
						\left\{ \begin{array}{ccc}
							y &=& \frac{b_1}{b} \\
							0 &=& b_2 - \frac{db_1}{b}
						\end{array} \right.
					\end{equation*}
					\begin{itemize}[label=$\bullet$ Si]
						\item $b_2 - \frac{db_1}{b} \neq 0$, (S) n'admet aucune solution.
						\item $b_2 - \frac{db_1}{b} = 0$, $(S) \iff y = \frac{b_1}{b} \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} t \\ \frac{b_1}{d} \end{pmatrix} |\; t \in \K \end{Bmatrix}$ donc (S) admet une droite affine de solutions.
					\end{itemize}
				\end{itemize}
				\item $c \neq 0$ alors $b = 0$
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{ \begin{array}{ccc}
							0 &=& b_1 \\
							cx + dy &=& b_2
						\end{array} \right.
					\end{aligned}
				\end{equation*}
				\begin{itemize}[label=$\bullet$ Si]
					\item $b_1 \neq 0$, (S) n'admet aucune solution.
					\item $b_1 = 0$, $(S) \iff x = \frac{b_2}{c} - \frac{d}{c}y \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} \frac{b_2}{c} - \frac{d}{c}t \\ t \end{pmatrix} |\; t \in \K \end{Bmatrix}$ donc (S) admet une droite affine de solutions.
				\end{itemize}
			\end{itemize}
		\end{itemize}
		
	\end{question_kholle}

\end{document}
