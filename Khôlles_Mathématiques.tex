% Ceci est un fichier généré automatiquement.
% Ne pas le modifier directement. Exécuter $ make pour le générer.
% Il rassemble les questions de khôlles de toutes les semaines.

\documentclass{article}

\usepackage{kholles}

\renewenvironment{question_kholle}[2][ ]
{
	\subsection{\texorpdfstring{#2}{}}
	\notblank{#1}
	{
		\noindent #1
		\bigbreak
	}
	{}
	\begin{proof}
}
{
	\end{proof}
}

\begin{document}
	\maketitle
	
	\begin{abstract}
		Bienvenue très chers camarades sereins, ce document contient les questions de khôlles de mathématiques de la MP1 de Fermat. Il est coécrit par Kylian Boyet, George Ober, Hugo \textit{Vangi}lluwen (qui maintient la structure du projet, la compilation et le paquet kholles.sty) avec la contribution de Jérémie Menard.
		Il n'est malheureusement pas exhaustif. Si vous voulez nous aider, lisez CONTRIBUER.md et envoyez-nous votre code \LaTeX ou plus simplement dites-nous quand vous rencontrez une erreur.
	\end{abstract}
	
	\tableofcontents
\pagebreak\section{Semaine 6}


\begin{question_kholle}{Montrer que si $f$ est impaire et bijective, alors $f^{-1}$ est aussi impaire. Donnez un/des exemples.} 
	Soit $f: I \to F$, avec $I,F$ deux parties non-vides de $\mathbb{R}$, une telle fonction et notons $f^{-1}$ sa bijection réciproque. Si $f$ est impaire sur $I$, alors pour tout $x\in I$, $-x\in I$, ainsi $I$ est centré en $0$ et on a : 
	
	\begin{equation*}
	    \forall x \in I, \ f(-x) = -f(x).
	\end{equation*}
	
	Ainsi, prenons $y\in F$, alors $-y \in F$ par imparité et bijectivité de $f$. On a donc : 
	
	\begin{eqnarray*}
		f^{-1}(-y) & = & f^{-1}(-f(f^{-1}(y))) \\
			& = & f^{-1}(f(-f^{-1}(y))) \\
		    & = & -f^{-1}(y).
	\end{eqnarray*}
	
	\
	
	D'où l'imparité de $f^{-1}$.
	
	\
	
	Pour ce qui est de l'exemple, prenons notre fonction bijective impaire préférée, la fonction $\textstyle \sin |_{\left[ -\frac{\pi}{2}, \frac{\pi}{2}\right] }^{[-1,1]}$ que l'on notera $\widetilde{\sin}$. Sa bijection réciproque est bien entendu $\textstyle \arcsin : [-1,1] \to \left[ -\frac{\pi}{2}, \frac{\pi}{2}\right]$.
	
	De la même manière que dans la démonstration du cas général, prenons $y\in [-1, 1]$, comme $[-1,1]$ est centré en $0$, $-y\in [-1,1]$, on a dès lors : 
	
	\begin{eqnarray*}
		\arcsin(-y) & = & \arcsin(-\widetilde{\sin}(\arcsin(y))) \\
			& = & \arcsin(\widetilde{\sin}(-\arcsin(y))) \\
		    & = & -\arcsin(y).
	\end{eqnarray*}
\end{question_kholle}

\begin{question_kholle}{Limite (et preuve) lorsque $x$ tend vers $+\infty$ de $\frac{(\ln x)^{\alpha}}{x^{\beta}}$ pour $\alpha ,\beta \in \left( \mathbb{R}_+^*\right) ^2$.} 

	Premièrement, posons : 
	
	\begin{equation*}
	    \forall  (x,\alpha,\beta)\in [1,+\infty[ \times \left( \mathbb{R}_+^*\right) ^2, \quad  f_{\alpha,\beta}(x)=\frac{(\ln x)^{\alpha}}{x^{\beta}}.
	\end{equation*}
	
	Deuxièmement, montrons que : 
	\[ \frac{\ln (x)}{x^2}\xrightarrow[n \to +\infty ]{} 0. \]
	
	Soit $x \in [1,+\infty[ \ = \mathcal{A}$. Nous savons que la fonction $\ln$ est concave sur $\mathbb{R}_+^*$, donc en particulier sur $\mathcal{A}$. Ainsi, $\ln$ est en dessous de toutes ses tangentes, d'où : 
	\[ 
	\forall x \in \mathcal{A}, \quad 0 \; \leq \; \ln (x) \; \leq \; x-1.
	\]
	
	\newpage
	
	Illustration de l'inégalité : 
	
	\
	
	\begin{center}
		\definecolor{ttttff}{rgb}{0.2,0.2,1}
		\definecolor{ffttww}{rgb}{1,0.2,0.4}
		\definecolor{cqcqcq}{rgb}{0.75,0.75,0.75}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
			\draw [color=cqcqcq,dash pattern=on 1pt off 1pt, xstep=1.0cm,ystep=1.0cm] (-1,-2) grid (3,2);
			\draw[->,color=black] (-1,0) -- (3,0);
			\foreach \x in {-1,1,2}
			\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
			\draw[->,color=black] (0,-2) -- (0,2);
			\foreach \y in {-2,-1,1}
			\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
			\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
			\clip(-1,-2) rectangle (3,2);
			\draw[color=ffttww, smooth,samples=100,domain=3.244085366007135E-3:3.0] plot(\x,{ln(\x)});
			\draw[color=ttttff, smooth,samples=100,domain=-1.0:3.0] plot(\x,{\x-1});
			\draw (12.46,5.36) node[anchor=north west] {y = x-1};
			\draw (9.62,5.22) node[anchor=north west] {y = ln(x)};
		\end{tikzpicture}
		
		\
		
		\textbf{Figure 1.} $\ln$ en rouge et la première bissectrice en bleu. 
	\end{center}
	
	\
	
	On peut alors diviser par $x^2$ (car $x \neq 0$): 
	
	\
	
	\[
		\forall x \in \mathcal{A},\quad 0 \; \leq \; \underset{f_{1,2}(x)}{\underbrace{\frac{\ln (x)}{x^2}}} \; \leq \; \underset{\xrightarrow[x\to+\infty]{} \ 0}{\underbrace{\frac{1}{x}}} - \underset{\xrightarrow[x\to+\infty]{} \ 0}{\underbrace{\frac{1}{x^2}}}.
	\]
	
	\
	
	Donc par théorème d'encadrement $f_{1,2}(x)\xrightarrow[x\to+\infty]{} 0$.
	
	\
	
	Dernièrement, le cas général. Soit $x\in \mathcal{A}$ et soient $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2$. On fait une preuve directe. 
	
	\begin{eqnarray*}
	    \frac{(\ln (x))^\alpha}{x^\beta} & = & \left( \frac{\ln (x)}{x^{\frac{\beta}{\alpha}}} \right)^\alpha \\[1.5ex]
	    & = & \underset{\underset{\text{par produit}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{\underset{c^{\underline{te}} \ \text{(définie!)}}{\underbrace{\left( \frac{2\alpha}{\beta} \right)^\alpha}} \cdot \underset{\underset{\text{par composition des limites}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{\left[ \underset{\underset{\text{d'après le dernier point}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{ \frac{\ln \left( x^{\frac{\beta}{2 \alpha}} \right) }{\left( x^{\frac{\beta}{2\alpha}} \right)^2} }}\right]^\alpha}}}}.
	\end{eqnarray*}

\end{question_kholle}

\

%-------------------------------------------------------------

\begin{question_kholle}{Limite en $0$ de $\frac{1-\cos (x)}{x^2}$ et limite en $+\infty$ suivant $n$ de $\frac{\left(q^n \right)^\alpha}{(n!)^\beta}$ pour $q\in \mathbb{R}$ et $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2.$} 

	\
	
	Montrons que $\frac{1-\cos (x)}{x^2} \xrightarrow[x\to 0]{} \frac{1}{2}$.
	
	\
	
	On fait toujours une preuve directe. 
	\begin{eqnarray*}
	    \lim_{x\to0} \ \frac{1-\cos (x)}{x^2} & = & \lim_{x\to0} \ \frac{1-\cos \left( \frac{2x}{2}\right) }{x^2} \\[1ex]
	    & = & \lim_{x\to0} \ \frac{1-\left( 1-2\sin ^2 \left( \frac{x}{2}\right) \right) }{x^2} \\[1ex]
	    & = &  \lim_{x\to0} \ \frac{2\sin ^2 \left( \frac{x}{2}\right) }{4 \left( \frac{x}{2}\right) ^2} \\[1ex]
	    & = & \lim_{x\to0} \ \underset{\underset{\text{par produit}}{\xrightarrow[x\to 0]{} \ \frac{1}{2}}}{\underbrace{\underset{c^{\underline{te}}}{\underbrace{\frac{1}{2}}} \cdot \underset{\underset{\text{par composition}}{\xrightarrow[x\to 0]{} \ 1}}{\underbrace{\left[\underset{\underset{\text{limite usuelle}}{\xrightarrow[x\to 0]{} \ 1}}{\underbrace{\frac{\sin \left( \frac{x}{2}\right) }{\left( \frac{x}{2}\right)} }} \right] ^2}}}} \\[1ex]
	    & = & \frac{1}{2}
	\end{eqnarray*}
	
	\
	
	
	
	\
	
	Trouvons la limite, sous réserve d'existence, de $\frac{\left(q^n \right)^\alpha}{(n!)^\beta}$ pour $q\in \mathbb{R}$ et $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2$ suivant $n$ en $+\infty$.
	
	\
	
	Remarquons que si $q\leq0$, il est \textbf{\textit{nécessaire}} d'avoir $\alpha\in\mathbb{Z}^*$ sinon l'expression n'a tout simplement \textbf{\textit{aucun sens}}. De fait, on supposera $q>0$ tout le long, les cas $q<0$ se font naturellement (convergence pour $q\in \mathbb{R_-}$).
	
	\
	
	Soit donc $0<q<1$, ce cas est immédiat, $\left( \left(q^n \right)^\alpha\right)_{n\in\mathbb{N}}=\left( \left(q^\alpha \right)^n\right)_{n\in\mathbb{N}}$, donc il s'agit de la suite géométrique de raison $q^\alpha \in ]0,1[$ et de premier terme $q^{\min_{I}(n)\alpha}$ ($\min_{I}(n)$, avec $I$ une partie non vide de $\mathbb{N}$, car la suite ne démarre pas forcément à $0$), donc elle converge vers $0$.
	
	\
	
	Si $q\geq 1$, on montre le cas trivial $\alpha = \beta =1$ : 
	\[
	\forall n\in [\![ \lfloor q \rfloor +1,+\infty [\![, \quad 0 \leq \frac{q^n}{n!} = \underset{=\ \lambda \text{ (une constante)}}{\underbrace{\frac{q}{1} \times \frac{q}{2} \times \dots \times \frac{q}{\lfloor q \rfloor} }}\times \underset{\leq 1}{\underbrace{\frac{q}{\lfloor q\rfloor +1}}} \times \dots \times \underset{\leq1}{\underbrace{\frac{q}{n-1}}} \times \frac{q}{n} \leq \underset{\xrightarrow[n\to +\infty]{} \ 0}{\underbrace{\frac{\lambda q}{n}}}
	\]
	
	\
	
	Par théorème d'existence de limite par encadrement, $\left( \frac{q^n}{n!} \right)_{n\in \mathbb{N}}$ converge et sa limite est $0$.
	
	\
	
	Soient $(\alpha,\beta)\in \mathbb{R}^*_+$, montrons le cas général pour $q\geq 1$.
	
	\[
	\forall n \in \mathbb{N}, \quad \frac{(q^n)^\alpha}{(n!)\beta} = \left( \frac{\left(q^{\frac{\alpha}{\beta}}\right)^n}{n!} \right)^\beta = \underset{\underset{\text{par composition des limites }(\beta>0)}{\xrightarrow[n\to +\infty]{} 0}}{\underbrace{\left( \underset{\underset{\text{c'est le cas trivial}}{\xrightarrow[n\to +\infty]{} 0}}{\underbrace{\frac{\left(q^{\frac{\alpha}{\beta}}\right)^n}{n!}}} \right)^\beta}}
	\]
	
\end{question_kholle}

\begin{question_kholle}{Présentation exhaustive de la fonction $\arcsin$.}
	Premièrement, ladite fonction est la bijection réciproque de la fonction $\widetilde{\sin}$ (voir \textbf{1}.). D'où : 
	\begin{equation*}
		\arcsin = \left\{  
		\begin{array}{c c c}
		[-1,1] & \to & [-\frac{\pi}{2} , \frac{\pi}{2}] \\ [1ex]
		x & \mapsto & \left( \widetilde{\sin} \right)^{-1}(x)
		\end{array} 
		\right.
	\end{equation*}
	
	\
	
	Ainsi, pour $x\in [-1,1]$, $\arcsin (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle \left[-\frac{\pi}{2} , \frac{\pi}{2}\right]$, $\sin(\theta) = x$. 
	
	\
	
	\noindent Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\sin}$ : 
	
	\begin{enumerate}
	    \item $\arcsin$ est impaire.
	    \item $\arcsin$ est strictement croissante sur $[-1,1]$.
	    \item $\arcsin \in \mathcal{C}^0\left([-1,1],[-\frac{\pi}{2} , \frac{\pi}{2}] \right)$.
	    \item $\arcsin \in \mathcal{D}^1\left(]-1,1[,\left]-\frac{\pi}{2} , \frac{\pi}{2}\right[ \right)$.
	    \item $\arcsin'(x) = \frac{1}{\sqrt{1-x^2}}$ pour tout $x\in]-1,1[$.
	    \item $\arcsin$ admet deux demi-tangentes verticales en $-1$ et $1$.
	\end{enumerate}
	
	\
	
	Graphe de $\arcsin$ : 
	\begin{center}
		\definecolor{ffttww}{rgb}{1,0.2,0.4}
		\definecolor{ttzzff}{rgb}{0.2,0.6,1}
		\definecolor{zzffzz}{rgb}{0.6,1,0.6}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.910828025477707cm,y=1.910828025477707cm]
			\draw[->,color=black] (-1.57,0) -- (1.57,0);
			\foreach \x in {-1.5,-1,-0.5,0.5,1,1.5}
			\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
			\draw[->,color=black] (0,-1.57) -- (0,1.57);
			\foreach \y in {-1.5,-1,-0.5,0.5,1,1.5}
			\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
			\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
			\clip(-1.57,-1.57) rectangle (1.57,1.57);
			\draw[color=zzffzz] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.57:1.57]; plot sin(x)};
			\draw[color=ttzzff] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-1.57:1.57]; plot asin(x)};
			\draw[color=ffttww] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-1.57:1.57]; plot x};
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(--1.57-0*\x)/1});
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (1,-1.57) -- (1,1.57);
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (1.57,-1.57) -- (1.57,1.57);
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(--1-0*\x)/1});
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (-1.57,-1.57) -- (-1.57,1.57);
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (-1,-1.57) -- (-1,1.57);
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(-1-0*\x)/1});
			\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(-1.57-0*\x)/1});
			\draw [->] (-1.57,-1) -- (-1.18,-1);
			\draw [->] (-1,-1.57) -- (-1,-1.16);
			\draw [->] (1,1.57) -- (1,1.16);
			\draw [->] (1.57,1) -- (1.12,1);
		\end{tikzpicture}
		
		\
		
		\textbf{Figure 2.} $\arcsin$ en bleu, $\widetilde{\sin}$ en vert et la première bissectrice en rouge.
	\end{center}
	
	\
	
	On a aussi, grâce au taux d'accroissement en 0 d'$\arcsin$ : 
	\[
		\lim_{x\to0} \frac{\arcsin(x)}{x} \ = \ 1.
	\]
	
	\
	
	Puis finalement (visible sur le graphe) : 
	\[
		\forall x \in [0,1], \quad \arcsin(x) \geq x.
	\]
\end{question_kholle}

\begin{question_kholle}{Présentation exhaustive de la fonction $\arccos$.} 

	Premièrement, ladite fonction est la bijection réciproque de la fonction $\cos |_{[0,\pi]}^{[-1,1]} := \widetilde{\cos}$. D'où : 
	\begin{equation*}
		\arccos = \left\{  
		\begin{array}{c c c}
		[-1,1] & \to & [0 , \pi] \\ [1ex]
		x & \mapsto & \left( \widetilde{\cos} \right)^{-1}(x)
		
		\end{array} 
		\right.
	\end{equation*}
	
	\
	
	Ainsi, pour $x\in [-1,1]$, $\arccos (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle [0 ,\pi]$, $\cos(\theta) = x$.
	
	\noindent Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\cos}$ : 
	
	\begin{enumerate}
	    \item $\arccos$ est strictement décroissante sur $[-1,1]$.
	    \item $\arccos \in \mathcal{C}^0\left([-1,1],[0 , \pi] \right)$.
	    \item $\arccos \in \mathcal{D}^1\left(]-1,1[,]0 ,\pi [ \right)$.
	    \item $\arccos'(x) = -\frac{1}{\sqrt{1-x^2}}$ pour tout $x\in]-1,1[$.
	    \item $\arccos$ admet deux demi-tangentes verticales en $-1$ et $1$.
	\end{enumerate}
	
	\
	
	Graphe de $\arccos$ : 
	\begin{center}
		\definecolor{cczzff}{rgb}{0.8,0.6,1.0}
		\definecolor{qqffqq}{rgb}{0.0,1.0,0.0}
		\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
		\definecolor{xfqqff}{rgb}{0.4980392156862745,0.0,1.0}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.3636363636363635cm,y=1.3636363636363635cm]
			\draw[->,color=black] (-1.2,0.0) -- (3.2,0.0);
			\foreach \x in {-1.0,-0.5,0.5,1.0,1.5,2.0,2.5,3.0}
			\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
			\draw[->,color=black] (0.0,-1.2) -- (0.0,3.2);
			\foreach \y in {-1.0,-0.5,0.5,1.0,1.5,2.0,2.5,3.0}
			\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
			\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
			\clip(-1.2,-1.2) rectangle (3.2,3.2);
			\draw[color=xfqqff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [0:3.14]; plot cos(x)};
			\draw[color=ffqqqq] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-1.2:3.2]; plot x};
			\draw[color=qqffqq] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-1:1]; plot acos(x)};
			\draw[dotted,color=cczzff] plot[raw gnuplot, id=func3] function{set samples 100; set xrange [-1.2:3.2]; plot 3.1415926535/2.0-x};
			\draw [dotted] (-1.0,0.0)-- (-1.0,3.141592653589793);
			\draw [dotted] (-1.0,3.141592653589793)-- (0.0,3.141592653589793);
			\draw [dotted] (0.0,1.0)-- (1.0,1.0);
			\draw [dotted] (1.0,0.0)-- (1.0,1.0);
			\draw [dotted] (0.0,-1.0)-- (3.141592653589793,-1.0);
			\draw [dotted] (3.141592653589793,0.0)-- (3.141592653589793,-1.0);
			\draw [->] (-1.0,3.141592653589793) -- (-1.0,2.6982051899765422);
			\draw [->] (0.0,1.0) -- (0.41398424427733616,1.0);
			\draw [->] (1.0,0.0) -- (1.0,0.41498464079523883);
			\draw [->] (3.141592653589793,-1.0) -- (2.697204793458636,-1.0);
		\end{tikzpicture}
	
		\
	
		\textbf{Figure 3.} $\arccos$ en vert, $\widetilde{\cos}$ en violet, la première bissectrice en rouge et $y = \frac{\pi}{2} - x$ en rose.
	\end{center}

\end{question_kholle}

\begin{question_kholle}{Présentation exhaustive de la fonction $\arctan$.} 

	\
	
	Premièrement, ladite fonction est la bijection réciproque de la fonction $\tan |_{\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ }:=\widetilde{\tan}$. D'où : 
	\begin{center}
	
	$\arctan = \left\{  
	\begin{array}{c c c}
	\mathbb{R} & \to & \left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \\ [1ex]
	x & \mapsto & \left( \widetilde{\tan} \right)^{-1}(x)
	\end{array} 
	\right.
	$
	\end{center}
	
	\
	
	Ainsi, pour $x\in \mathbb{R}$, $\arctan (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle \left] -\frac{\pi}{2}, \frac{\pi}{2}\right[$, $\tan(\theta) = x$. 
	
	\
	
	\noindent Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\tan}$ : 
	
	\begin{enumerate}
	    \item $\arctan$ est impaire.
	    \item $\arctan \in \mathcal{C}^0\left(\mathbb{R},\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \right)$.
	    \item $\arctan \in \mathcal{D}^1\left(\mathbb{R},\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \right)$.
	    \item $\arctan'(x) = \frac{1}{1+x^2}$ pour tout $x\in\mathbb{R}$.
	\end{enumerate}
	
	\newpage
	
	Graphe de $\arctan$ : 
	\begin{center}
		\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
		\definecolor{qqffqq}{rgb}{0.0,1.0,0.0}
		\definecolor{qqffff}{rgb}{0.0,1.0,1.0}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
			\draw[->,color=black] (-3.0,0.0) -- (3.0,0.0);
			\foreach \x in {-3.0,-2.5,-2.0,-1.5,-1.0,-0.5,0.5,1.0,1.5,2.0,2.5}
			\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
			\draw[->,color=black] (0.0,-3.0) -- (0.0,3.0);
			\foreach \y in {-3.0,-2.5,-2.0,-1.5,-1.0,-0.5,0.5,1.0,1.5,2.0,2.5}
			\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
			\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
			\clip(-3.0,-3.0) rectangle (3.0,3.0);
			\draw[color=qqffff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.56:1.56]; plot tan(x)};
			\draw[color=qqffqq] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-3:3]; plot atan(x)};
			\draw[color=ffqqqq] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-3:3]; plot x};
			\draw [domain=-3.0:3.0] plot(\x,{(--1.5707963267948966-0.0*\x)/1.0});
			\draw (1.5707963267948966,-3.0) -- (1.5707963267948966,3.0);
			\draw [domain=-3.0:3.0] plot(\x,{(-1.5707963267948966-0.0*\x)/1.0});
			\draw (-1.5707963267948966,-3.0) -- (-1.5707963267948966,3.0);
			\draw [dotted] (0.7853981633974483,1.0)-- (0.7853981633974483,0.0);
			\draw [dotted] (0.0,0.7853981633974483)-- (1.0,0.7853981633974483);
			\draw [dotted] (0.0,1.0)-- (1.0,1.0);
			\draw [dotted] (1.0,0.0)-- (1.0,1.0);
			\draw [dotted] (-1.0,0.0)-- (-1.0,-1.0);
			\draw [dotted] (0.0,-1.0)-- (-1.0,-1.0);
			\draw [dotted] (-0.7853981633974483,0.0)-- (-0.7853981633974483,-1.0);
			\draw [dotted] (0.0,-0.7853981633974483)-- (-1.0,-0.7853981633974483);
			\begin{scriptsize}
				\draw[color=qqffff] (-3.1177254400173355,-0.014744648606977613) node {$f$};
				\draw[color=qqffqq] (-3.1177254400173355,-1.3072326284088318) node {};
				\draw[color=ffqqqq] (-1.8026940652189338,-1.8332451783281911) node {};
				\draw[color=black] (-3.1177254400173355,1.5106917461591645) node {$a$};
				\draw[color=black] (1.4660982092799508,2.322253966034747) node {};
				\draw[color=black] (-3.1177254400173355,-1.4500074633869435) node {$c$};
				\draw[color=black] (-1.4946010002661654,2.322253966034747) node {};
			\end{scriptsize}
		\end{tikzpicture}
		
		\
		
		\textbf{Figure 4.} $\arctan$ en vert, $\widetilde{\tan}$ en bleu, la première bissectrice en rouge, et les fonctions $y = \pm \frac{\pi}{2}$ et $x = \pm \frac{\pi}{2}$ en noir.
	\end{center}
	
	\
	
	On a aussi (visible sur le graphe) : 
	\[
		\forall x \in \mathbb{R}_+, \quad \arctan(x) \leq x.
	\]
	
	Et enfin : 
	\[
		\forall x \in \mathbb{R}^*, \quad \arctan(x) + \arctan \left( \frac{1}{x} \right) = 
		\left\{ \begin{array}{cl}
		\frac{\pi}{2} & \text{si } x \ > \ 0 \\
		-\frac{\pi}{2} & \text{si } x \ < \ 0.
		\end{array} \right.
	\]

\end{question_kholle}

%-------------------------------------------------------------
\begin{question_kholle}{$2$ preuves de $\arcsin(x) + \arccos(x) =\frac{\pi}{2}$ sur $[-1,1]$, dont une basée sur une interprétation géométrique du cercle trigonométrique.} 

	L'interprétation géométrique sur $[0,1]$, celle sur $[-1,0]$ est laissée au lecteur car il s'agit du même principe modulo des détails : 
	
	\begin{center}
		\definecolor{eqbqff}{rgb}{0.8784313725490196,0.6901960784313725,1.0}
		\definecolor{xfqqff}{rgb}{0.4980392156862745,0.0,1.0}
		\definecolor{uuuuuu}{rgb}{0.26666666666666666,0.26666666666666666,0.26666666666666666}
		\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
		\definecolor{qqffff}{rgb}{0.0,1.0,1.0}
		\definecolor{cqcqcq}{rgb}{0.7529411764705882,0.7529411764705882,0.7529411764705882}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=2.5cm,y=2.5cm]
			\clip(-1.2,-1.2) rectangle (1.2,1.2);
			\fill[fill=black,fill opacity=1.0] (0.08956860342780414,0.20707624336357297) -- (0.08145277478981197,0.18983010750783963) -- (0.0742401101509475,0.2039730262575521) -- cycle;
			\fill[fill=black,fill opacity=1.0] (0.3604343842207928,0.11272973544691409) -- (0.3441578360574464,0.12526320821437803) -- (0.33811585546631434,0.10562838538867093) -- cycle;
			\draw [color=cqcqcq] (0.0,0.0) circle (2.5cm);
			\draw [shift={(0.0,0.0)},line width=1.2000000000000002pt,color=qqffff]  plot[domain=0.0:3.141592653589793,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
			\draw [shift={(3.061616997868383E-17,0.0)},line width=1.2000000000000002pt,color=ffqqqq]  plot[domain=-1.5707963267948966:1.5707963267948963,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
			\draw [shift={(0.0,-0.0)},line width=1.2000000000000002pt,color=xfqqff]  plot[domain=0.0:1.5707963267948966,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
			\draw [line width=1.2000000000000002pt,color=qqffff] (-1.0589461703485412,0.0)-- (-0.9410538296514588,0.0);
			\draw [line width=1.2000000000000002pt,color=qqffff] (1.0589461703485412,0.0)-- (0.9410538296514588,0.0);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,1.0589461703485412)-- (5.762292801540088E-17,0.9410538296514588);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (-1.945252556980033E-16,-1.0589461703485412)-- (-1.7286878404620264E-16,-0.9410538296514588);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,1.0589461703485412)-- (0.05398708109469719,1.0589461703485412);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (5.762292801540088E-17,0.9410538296514588)-- (0.05398708109469719,0.9410538296514588);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,-1.0589461703485412)-- (0.05398708109469719,-1.0589461703485412);
			\draw [line width=1.2000000000000002pt,color=ffqqqq] (5.762292801540088E-17,-0.9410538296514588)-- (0.05398708109469719,-0.9410538296514588);
			\draw [line width=1.2000000000000002pt,color=qqffff] (-1.0589461703485412,1.2968350379866888E-16)-- (-1.0589461703485412,0.05398708109469725);
			\draw [line width=1.2000000000000002pt,color=qqffff] (-0.9410538296514588,1.1524585603080177E-16)-- (-0.9410538296514588,0.05398708109469724);
			\draw [line width=1.2000000000000002pt,color=qqffff] (0.9410538296514588,1.1524585603080177E-16)-- (0.9410538296514588,0.05398708109469724);
			\draw [line width=1.2000000000000002pt,color=qqffff] (1.0589461703485412,1.2968350379866888E-16)-- (1.0589461703485412,0.05398708109469725);
			\draw [dash pattern=on 1pt off 1pt on 3pt off 4pt] (6.123233995736766E-17,1.0)-- (0.0,-1.0);
			\draw [dash pattern=on 1pt off 1pt on 3pt off 4pt] (-1.0,0.0)-- (1.0,-0.0);
			\draw[color=eqbqff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.0999999999999999:1.0999999999999999]; plot x};
			\draw (0.3420201433256688,0.9396926207859083)-- (0.0,-0.0);
			\draw (0.0,-0.0)-- (0.9396926207859084,0.3420201433256687);
			\draw [shift={(0.0,-0.0)}] plot[domain=0.0:0.3490658503988659,variable=\t]({1.0*0.36624511935574344*cos(\t r)+-0.0*0.36624511935574344*sin(\t r)},{0.0*0.36624511935574344*cos(\t r)+1.0*0.36624511935574344*sin(\t r)});
			\draw [shift={(0.0,-0.0)}] plot[domain=0.0:1.2217304763960306,variable=\t]({1.0*0.21706356072793254*cos(\t r)+-0.0*0.21706356072793254*sin(\t r)},{0.0*0.21706356072793254*cos(\t r)+1.0*0.21706356072793254*sin(\t r)});
			\draw (0.08956860342780414,0.20707624336357297)-- (0.08145277478981197,0.18983010750783963);
			\draw (0.08145277478981197,0.18983010750783963)-- (0.0742401101509475,0.2039730262575521);
			\draw (0.0742401101509475,0.2039730262575521)-- (0.08956860342780414,0.20707624336357297);
			\draw (0.3604343842207928,0.11272973544691409)-- (0.3441578360574464,0.12526320821437803);
			\draw (0.3441578360574464,0.12526320821437803)-- (0.33811585546631434,0.10562838538867093);
			\draw (0.33811585546631434,0.10562838538867093)-- (0.3604343842207928,0.11272973544691409);
			\draw [dash pattern=on 3pt off 3pt] (5.938595898438009E-17,0.9396926207859083)-- (0.3420201433256688,0.9396926207859083);
			\draw [dash pattern=on 3pt off 3pt] (4.108751682287631E-17,0.34202014332566877)-- (0.9396926207859084,0.3420201433256687);
			\draw [dash pattern=on 3pt off 3pt] (0.3420201433256688,0.9396926207859083)-- (0.3420201433256688,-0.0);
			\draw [dash pattern=on 3pt off 3pt] (0.9396926207859084,0.3420201433256687)-- (0.9396926207859084,-0.0);
			\draw (0.3106196735830377,0.20690669566269085) node[anchor=north west] {arccos(x)};
			\draw (0.06201603682796799,0.3536235960427321) node[anchor=north west] {arcsin(x)};
			\draw (-0.18658759992710172,0.9853213615679096) node[anchor=north west] {x};
			\draw (0.8241288249131816,0.0031332229126335774) node[anchor=north west] {x};
			\begin{scriptsize}
				\draw [fill=uuuuuu] (0.0,-0.0) circle (1.5pt);
				\draw[color=uuuuuu] (-0.011342413362052578,0.09279355092265877) node {$\Omega$};
				\draw [fill=uuuuuu] (5.938595898438009E-17,0.9396926207859083) circle (1.5pt);
				\draw [fill=uuuuuu] (0.9396926207859084,-0.0) circle (1.5pt);
			\end{scriptsize}
		\end{tikzpicture}
		
		\
		
		\textbf{Figure 5.}
	\end{center}
	
	\
	
	Preuve formelle : 
	
	\
	
	Soit $x\in [-1,1]$. Posons  $\varphi \ = \ \arcsin(x) \in \left[-\frac{\pi}{2},\frac{\pi}{2}\right]$. Ainsi : 
	
	\[
		\arcsin(x) + \arccos(x) \ = \ \varphi + \arccos(\sin(\varphi)) \ = \ \varphi + \arccos \left( \cos \left( \frac{\pi}{2}- \varphi \right) \right),
	\]
	
	\
	
	or $\varphi \in \left[-\frac{\pi}{2},\frac{\pi}{2}\right]$ donc
	$\frac{\pi}{2}- \varphi \in [0,\pi]$ d'où $\arccos \left( \cos \left( \frac{\pi}{2}- \varphi \right) \right) = \frac{\pi}{2}- \varphi$ si bien que : 
	\[
		\arcsin(x) + \arccos(x) \ = \  \varphi +\frac{\pi}{2} - \varphi \ = \ \frac{\pi}{2}.
	\]

\end{question_kholle}

\begin{question_kholle}{Présentation analytique rapide des fonctions \(\cosh\) et \(\sinh \).}
	~\smallbreak
	
	\begin{itemize}[label=$\bullet$]
		\item Domaine de définition et symétries.
		\newline
		$\sinh$ et $\cosh$ sont définies sur $\mathbb{R}$. 
		\newline
		De plus, 
		\newline
		$(i)$ $\forall x \in \mathbb{R}$, $-x\in \mathbb{R}$, 
		\newline
		$(ii)$ $\forall x \in \mathbb{R}$, 
		$
			\left\{ \begin{array}{c c c c c c c}
			\sinh (-x) & = & \frac{e^{-x} - e^{x}}{2} & = & - \frac{e^x - e^{-x}}{2} & = & -\sinh(x) \\
			\text{et} & & & & & & \\ 
			\cosh (-x) & = & \frac{e^{-x} + e^{-(-x)}}{2} & = &  \frac{e^x + e^{-x}}{2} & = & \cosh(x).
			\end{array} 
			\right.
		$
		\newline
		Donc $\sinh$ et $\cosh$ sont respectivement impaire et paire.
		\newline
		Nous les étudierons sur $\mathbb{R}_+$ et pour les obtenir les graphes $(\mathcal{C}_{\sinh} \text{ et } \mathcal{C}_{\cosh})$ de ces fonctions sur $\mathbb{R}$ à partir de ceux $(\mathcal{C}_{\sinh}^+ \text{ et } \mathcal{C}_{\cosh}^+)$ obtenus sur $\mathbb{R}_+$, nous le complèterons en traçant les images de ces graphes par la symétrie centrale $s$ de centre $O$ et par la réflexion $r$ d'axe $\left( O, \overrightarrow{\jmath} \right)$ : 
		\[
			\mathcal{C}_{\sinh} = \mathcal{C}_{\sinh}^+ \cup s \left( \mathcal{C}_{\sinh}^+ \right) \qquad \text{ et } \qquad \mathcal{C}_{\cosh} = \mathcal{C}_{\cosh}^+ \cup r \left( \mathcal{C}_{\cosh}^+ \right)
		\]
		
		\
		
		\item Variations : triviales.
		
		\
		
		\item Branches infinies en $+\infty$ et position relative de $\mathcal{C}_{\sinh}$ et $\mathcal{C}_{\cosh}$.
		
		\[
			\frac{\cosh(x)}{x} = \underset{\xrightarrow[x\to +\infty]{} \ +\infty}{\underbrace{\frac{e^{x}}{x}}} + \underset{\xrightarrow[x\to +\infty]{} \ 0}{\underbrace{\frac{e^{-x}}{x}}} \xrightarrow[x\to +\infty]{} \ +\infty
		\]
		Donc le graphe de $\cosh$ admet une branche parabolique de direction asymptotique $\left( O, \overrightarrow{\jmath}\right)$.
		\newline
		On a : 
		\[
			\forall x \in \mathbb{R}, \quad \cosh(x) - \sinh(x) = e^{-x} \xrightarrow[x\to +\infty]{} 0^+
		\]
		Donc les graphes des deux fonctions se rapprochent l'un de l'autre arbitrairement près lorsque $x \to +\infty$, et le graphe de $\cosh$ est au-dessus de celui de $\sinh$.
		
		\
		
		\item Tangente au graphe de $\sinh$ à l'origine et position relative.
	\end{itemize}

	Il s'agira d'étudier $g : x\in \mathbb{R}_+ \mapsto \sinh(x) -x$, de remarquer sa dérivabilité d'en étudier les variations puis de conclure, en précisant que cette étude révèle l'inflexion du graphe de $\sinh$ en 0.
\end{question_kholle}

\pagebreak\section{Semaine 7}

\begin{question_kholle}{Calcul de $\int_0^{2\pi}e^{imt}dt$ en fonction de $m \in \Z$. En Déduire qu'une fonction polynomiale nulle sur un cercle centré en l'origine a tous ses coefficients nuls.}
	Soit $m \in \Z$ fq. Calculons:
	$$\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt$$
	Si $m \neq 0$:
	\begin{align*}
		\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt &= \frac{1}{2 \pi} \Big[ \frac{e^{mt}}{im} \Big]_0^{2\pi}\\
		&= \frac{1}{2 \pi} \Big( \frac{1}{im} - \frac{1}{im} \Big) = 0
	\end{align*}
	Si $m = 0$:
	$$
		\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt = \frac{1}{2 \pi} \int_0^{2\pi}dt = \frac{2 \pi}{2 \pi} = 1
	$$
	\\
	Donc $$\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt = 
	\begin{cases}
		1 \text{ si } m=0\\
		0 \text{ si } m \neq 0
	\end{cases}
	$$
	\\
	Soit $n\in \N$ fq
	
	Soient $(a_0, ..., a_n) \in \C^{n+1}$ les coefficients de $P(z) = \sum_{k=0}^n a_k z^k$, et $s\in \Z$, et $r \in \R_+^*$ fq. tels que P soit nulle lorsqu'elle est évaluée sur $\mathscr C(0,r)$
	\begin{align*}
		\frac{1}{2 \pi} \int_0^{2\pi} P(re^{it}) e^{-imt}dt &= \frac{1}{2 \pi} \int_0^{2\pi} \bigg (\sum_{k=0}^n a_k (re^{it})^k \bigg) e^{-imt}dt\\
		&= \sum_{k=0}^n a_k r^k \underbrace{\int_0^{2\pi} \frac{e^{it(k-s)}}{2 \pi} dt}_{I_k}
	\end{align*}
	On remarque que:
	\begin{itemize}
		\item Si $s \notin [[0, n]], \{k \in [[0, n]] \text{ }| \text{ } k = s\}$ = $\emptyset$, Donc $$\sum_{k \in [[0, n]]} a_k s^k I_k  = \sum_{\substack{k \in [[0, n]] \\ k = s}} a_k r^k  = 0$$
		\item Si $s \in [[0, n]], \{k \in [[0, n]] \text{ }| \text{ } k = s\}$ = ${s}$, Donc $$\sum_{k \in [[0, n]]} a_k s^k I_k = \sum_{\substack{k \in [[0, n]] \\ k = s}} a_k s^k = a_s r^s \label{1}$$
	\end{itemize}
	Or, puisque $P$ s'annule sur le cercle de rayon $r$ et de centre $0$,  $\mathscr C(0,r)$, ces sommes sont aussi nulles. On en déduit, en particularisant pour un $s \in [[0, n]]$ fixé quelconque que:
	$$
		\sum_{k \in [[0, n]]} a_k s^k I_k = a_sr^s = 0 \implies a_s = 0
	$$
	
	Donc $$
		(\exists r \in \R_+^* : \forall \theta \in \R, P(re^{i\theta})=0) \implies \forall s \in [[0, n]]
	$$
	\\
	Pour la preuve réciproque,  soit $n \in \N$ fq. Soient $(a_0,...,a_n) \in \{ 0 \} ^{n+1}$ les coefficients nuls de la fonction polynomiale $P \in \C[z]$ définie pour tout $z \in \C$.
	
	En remarquant que $\forall z \in \C , P(z) = 0$, puisque n'importe quel cercle centré en 0 est un sous ensemble de $\C$,  $\exists r \in \R_+^*: \forall z \in \mathscr C(0, r), P(z) = 0$.
\end{question_kholle}

\begin{question_kholle}{Preuve de la Linéarité de la dérivation d'une fonction complexe}
	Définissons les fonctions $f_r$ et $f_i$ comme les parties réelles et imaginaires de $f$.

	Soient $(f, g) \in \mathcal{F}(I, \C)^2$, $(\alpha, \beta) \in \C^2$ fixés quelconques.
	\begin{align*}
		f_r = \Re(f) &, f_i = \Im(f) &g_r = \Re(f) &, g_i = \Im(g)\\
		\alpha_r = \Re(\alpha) &, \alpha_i = \Im(f) &\beta_r = \Re(f) &, \beta_i = \Im(g)
	\end{align*}
	
	\begin{align*}
		\Re( \alpha f + \beta g) &= \Re((\alpha_r + i \alpha_i)(f_r + i f_i) + (\beta_r+ i\beta_i)(g_r+ i g_i)) \\
		&= \underbrace{\alpha_r f_r + \beta_r g_r - \alpha_i f_i - \beta_i g_i}_{\text{Combinaison linéaire de } \underbrace{(f_r, f_i, g_r, g_i) \in \mathcal D^1(I, \R)^4}_{car (f,g) \in D^1(I, \R)^2}}
	\end{align*}
	Donc, selon le théorème de stabilité par combinaison linéaire des fonctions à valeurs réelles, $\Re(\alpha f + \beta g) \in \mathcal D^1(I, \R)$ et $\big(\Re(\alpha f + \beta g)\big)' = \alpha_r f_r' + \beta_r g_r' - \alpha_i f_i' - \beta_i g_i'$
	\\
	On montre de même que $\Im(\alpha f + \beta g) \in \mathcal D^1(I, \R)$ et $\big(\alpha f + \beta g\big)' = \alpha_r f_i' +\alpha f_r' +\beta_r g_i' +\beta_i g_r'$
	
	Ainsi,
	\begin{align*}
		\big( \alpha f + \beta g \big)' &= (\alpha_r f_r' + \beta_r g_r' - \alpha_i f_i' - \beta_i g_i') + i (\alpha_r f_i' +\alpha f_r' +\beta_r g_i' +\beta_i g_r') \\
		&= \alpha_r(f_r' + if_i') + \beta_r(g_r' + ig_i') + \alpha_i \underbrace{(-f_i' + if_r')}_{i(f_r' + if_i')} + \beta_i \underbrace{( -g_i' + ig_r')}_{i(g_r' + ig_i')} \\
		&=\alpha f' + \beta g'
	\end{align*}
\end{question_kholle}

\begin{question_kholle}{Dérivée composée d'une fonction à valeurs complexes}
	Soient $f \in \mathcal D ^1(J, \C) $ et $h \in \mathcal D^1(I, J)$ (I et J sont deux intervalles réels) fixés quelconques. Notons $f_r$ et $f_i$ respectivement la partie réelle et imaginaire de $f$.
	
	\begin{align*}
		\left .
		\begin{array}{ll}
			h \in \mathcal D^1(I, J) \\
			f_r \in \mathcal D^1(J, \R) \text{, car } f \in \mathcal D^1(J, \C)
		\end{array}
		\right \}
		\implies f_r \circ h \in \mathcal D^1(I, \R)
	\end{align*}
	
	On montre de même que $f_i \circ h \in \mathcal D^1(I, \mathbb  R)$ donc $f \circ h \in \mathcal D^1(I, \C)$.
	
	De plus,
	
	\begin{align*}
		(f \circ h)' &= (f_r \circ h)' + i (f_i \circ h)' \\
		&= (f_r' \circ h ) \times h' + i((f_i' \circ h) \times h') \\
		&=(f_r' \circ h + if_i' \circ h) \times h' \\
		&= (f' \circ h) \times h'
	\end{align*}
\end{question_kholle}

\begin{question_kholle}{Caractérisation des fonctions dérivables de dérivée nulle sur un intervalle}
	Soit $f \in \mathcal D ^1 (I, \C)$ où $I$ est un intervalle réel;
	Posons $f_r = \Re (f)$ et $f_i = \Im(f)$.
	
	\begin{align*}
	\forall t \in I, f'(t) = 0 &\iff \forall t \in I, f_r'(t) + i f_i'(t) = 0 \\
	&\iff \begin{cases}
		\forall t \in I, f_r'(t) = 0 \\
		\forall t \in I, f_i'(t) = 0
	\end{cases} \\
	&\iff \begin{cases}
		\exists \lambda_r \in \R : \forall t \in I,  f_r(t) = \lambda_r \\
			\exists \lambda_i \in \R : \forall t \in I,  f_i(t) = \lambda_i
	\end{cases} \\
	&\iff \exists \lambda \in \C : \forall t \in I,  f(t) = \lambda
	\end{align*}
\end{question_kholle}

\pagebreak\section{Semaine 8}

	\begin{question_kholle}{Preuve de l’expression des solutions réelles des EDL homogènes d’ordre 2 à coefficients constants réels dans le cas $\Delta < 0$ (en admettant la connaissance de l’expression des solutions à valeurs complexes des EDLH2 à coeff. constants).}
		Notons $\Sol_{H, \C}$ et $\Sol_{H, \R}$ les ensembles des solutions complexes et réelles de l'équation différentielle, puisque nous nous plaçons dans le cas $\Delta < 0$ et $\alpha \pm i \beta$ les deux racines complexes conjuguées.
		$$
		\Sol_{H, \C} =
		\left\{
		\begin{array}{l}
	    \R \to \C  \\
	    t \mapsto \lambda e^{(\alpha + i \beta) t}  + \mu e^{(\alpha - i \beta)t}
    	\end{array}
		\middle\vert  (\lambda, \mu) \in \C ^2 \right\}
		$$

		Montrons que $\forall f \in \Sol_{H ,\C}, \Re(f) \in  \Sol_{H ,\R}$\\
		Soit $f \in \Sol_{H ,\C}$ fq.
		$$f \in \mathcal D^2(\R, \C) \implies \Re(f) \in \mathcal D^2(\R, \R)$$
		Et, de plus, par morphisme additif de \Re
		$$
		a_2\Re(f)'' + a_1\Re(f)' + a_0\Re(f) = \Re( a_2 f'' + a_1 f' + a_0 f) = 0
		$$
		D'où, avec $f:t \mapsto e^{(\alpha + i \beta)t}$; $\Re(f(t)) = \Re(e^{(\alpha + i \beta)t}) = e^{\alpha t } \cos (\beta t)$. Qui appartient donc à $\Sol_{H, \R}$\\
		En suivant le même raisonnement pour $\Im(f)$, $(t \mapsto e^\alpha \sin(\beta t)) \in \Sol_{H, \R}$


		Ainsi, par combinaison linéaire (qui se base sur le principe de superposition),
		$$
		\left\{
		\begin{array}{l}
	    \R \to \R  \\
	    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
	  	\end{array}
		\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
		\subset \Sol_{H ,\R}
		$$

		Réciproquement, soit $ f \in \Sol_{H ,\R}$ fq. Puisque $\R \subset \C$,  $ f \in \Sol_{H ,\C}$.

		$$
		\exists (a, b) \in \C^2 : f \left| \begin{array}{l}
	    \R \to \C  \\
	    t \mapsto a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t}
		\end{array}\right.$$

		Or, puisque toutes les valeurs de $f$ sont réelles, en notant $(a_r, a_i, b_r, b_i)$ les parties réelles et imaginaires respectives de $a$ et $b$.
		\begin{align*}
			\forall t \in \R, f(t) &= \Re(f(t)) \\
					&= \Re(a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t})\\
					&= \Re((a_r + i a_i) e^{(\alpha + i \beta) t}  + (b_r + i b_i) e^{(\alpha - i \beta)t})\\
				    &= a_r \cos(\beta t)e^\alpha - a_i\sin(\beta t)e^\alpha + b_r \cos(\beta t)e^\alpha + b_i \sin(\beta t) e^\alpha \\
				    &= (a_r + b_r) \cos(\beta t) e^\alpha + (b_i - a_i) \sin(\beta t) e^\alpha
		\end{align*}
		Ainsi,
		$$f\in \left\{
		\begin{array}{l}
	    \R \to \R  \\
	    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
	  \end{array}
		\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
	$$
	Ce qui conclut la preuve par double inclusion.
	\end{question_kholle}

	\begin{question_kholle}[
		Considérons le problème de Cauchy suivant :
		$$\left\{ \begin{array}{l}
			a_{2}y''+a_{1}y'+a_{0}y = b \text{ sur } J  \\
			y(t_{0}) = \alpha_{0} \\
			y'(t_{0}) = \alpha_{1}
		\end{array} \right. \text{ où } (\alpha_{0}, \alpha_{1}) \in \mathbb{K}^{2}, t_{0} \in J, (a_{0}, a_{1}, a_{2}) \in \mathbb{K}^{2} \times \mathbb{K}^{*}, b \in \mathcal{F}(J, \mathbb{K})$$
		Si $b$ est continu sur $J$, alors ce problème de Cauchy admet une unique solution définie sur $J$.
		]
		{Existence et unicité d'une solution au problème de Cauchy pour les EDL d'ordre 2 à coefficients constants et second membre continu sur $I$ (cas complexe puis cas réel).}

	\textbf{Cas 1. } $\mathbb{K} = \mathbb{C}$ \\
	Nous savons que sous l'hyphothèse de continuité de $b$ sur $J$, les solutions de (EDL2) définies sur $J$ constituent le plan affine $S$ :
	$$S = \left\{ \lambda f_{1} + \mu f_{2} + s | (\lambda, \mu) \in \mathbb{C}^{2} \right\}$$
	où $s$ est une solution particulière de (EDL2), $(f_{1}, f_{2})$ sont deux solutions de (EDLH2) qui engendrent $S_{h}$. On a : \\

	$$\begin{array}{ccl}
	    f : J \to \mathbb{C} \text{ est sol. du pb de Cauchy }
	    &\iff &\left\{ \begin{array}{l}
	      f \text{ sol de (EDL2) sur } J    \\
	      f(t_{0}) = \alpha_{0}    \\
	      f'(t_{0}) = \alpha_{1}
	    \end{array}  \right. \\\\
	    &\iff &\left\{ \begin{array}{l}
	      f \in S    \\
	      f(t_{0}) = \alpha_{0}    \\
	      f'(t_{0}) = \alpha_{1}
	    \end{array}\right. \\\\
	    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
	      f = \lambda f_{1} + \mu f_{2} + s \\
	      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) + s(t_{0}) = \alpha_{0} \\
	      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) + s'(t_{0}) = \alpha_{1} \\
	    \end{array} \right. \\\\
	    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
	      f = \lambda f_{1} + \mu f_{2} + s \\
	      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) = \alpha_{0} - s(t_{0}) \\
	      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) = \alpha_{1} - s'(t_{0}) \\
	    \end{array} \right. \\\\
	\end{array} $$
	On en déduit donc que $(\lambda, \mu)$ doit être solution d'un système linéaire $(2,2)$. On a une unique solution si et seulement si les déterminant de ce système est nul. \\
	Explicitons alors le déterminant de ce système, que l'on notera $D$.
	$$D = \left|
	\begin{array}{cc}
	f_{1}(t_{0}) &f_{2}(t_{0}) \\
	f'_{1}(t_{0}) &f'_{2}(t_{0}) \\
	\end{array}
	\right| = f_{1}(t_{0}) \cdot f'_{2}(t_{0}) - f_{2}(t_{0}) \cdot f'_{1}(t_{0}) $$
	Notons $\Delta$ le discriminant de l'équation caractéristique de (EDL2) ($a_{2}r^{2} + a_{1}r^{1} + a_{0} = 0$). On distingue alors deux cas selon la nullité ou non de $\Delta$. Traitons d'abord le cas $\Delta \neq 0$. On peut choisir :
	$$ f_{1}(t_{0}) = e^{r_{1}t_{0}} \text{ et } f_{2}(t_{0}) = e^{r_{2}t_{0}}$$
	$$ f'_{1}(t_{0}) = r_{1}e^{r_{1}t_{0}} \text{ et } f'_{2}(t_{0}) = r_{2}e^{r_{2}t_{0}}$$
	Donc (en sachant que $\Delta \neq 0 \Rightarrow r_{1} \neq r_{2}$):
	$$ D = e^{r_{1}t_{0}} \cdot r_{2}e^{r_{2}t_{0}} - r_{1}e^{r_{1}t_{0}} \cdot e^{r_{2}t_{0}} = (r_{2} - r_{1}) \cdot e^{r_{1}t_{0} + r_{2}t_{0}} \neq 0$$

	Dans le deuxième cas, on a $\Delta = 0$ ; on peut alors prendre :
	$$ f_{1}(t_{0}) = e^{r_{0}t_{0}} \text{ et } f_{2}(t_{0}) = t_{0}e^{r_{0}t_{0}}$$
	Ainsi :
	$$ D = e^{r_{0}t_{0}} \left(r_{0}t_{0}e^{r_{0}t_{0}} + e^{r_{0}t_{0}} \right) - r_{0}e^{r_{0}t_{0}} \times t_{0}e^{r_{0}t_{0}} = e^{2r_{0}t_{0}} \neq 0$$
	On remarque alors que, dans les deux cas, $D \neq 0$, donc le système $(2, 2)$ étudié admet une unique solution, donc il existe un unique couple $(\lambda, \mu)$ le vérifiant d'où l'unicité et existence d'une solution au problème de Cauchy.
	\newline\newline

	\textbf{Cas 2. } $\mathbb{K} = \mathbb{R}$ \\
	$(a_{0}, a_{1}, a_{2}) \in \mathbb{R}^{2} \times \mathbb{R}^{*},(\alpha_{0}, \alpha_{1}) \in \mathbb{R}^{2}, b \in C^{0}(J, \mathbb{R})$
	\newline
	\textbf{Existence :} Puisque $\mathbb{R} \subset \mathbb{C}$, le problème de Cauchy admet, dans $\mathbb{R}$, une solution à valeurs complexes $g$. Posons $f = \Re(g)$ et montrons que $f$ est une solution réelle du problème de Cauchy. \\
	\begin{itemize}
	    \item[$\star$] $g \in \mathcal{D}^{2}(J, \mathbb{C}) \text{ donc } f \in \mathcal{D}^{2}(J, \mathbb{R})$
	    \item[$\star$] $g$ vérifie $a_{2}g'' + a_{1}g' + a_{0}g = b$ sur $J$ donc en prenant $\Re(\cdot)$ :
	    $$\begin{array}{ccl}
	      \Re(a_{2}g'' + a_{1}g' + a_{0}g = b) = \Re(b)
	      &\iff &a_{2}\Re(g'') + a_{1}\Re(g') + a_{0}\Re(g) = b  \\\\
	      &\iff & a_{2}f'' + a_{1}f' + a_{0}f = b \text{ sur } J
	    \end{array}$$
	    \item[$\star$] $f(t_{0}) = \Re(g(t_{0})) = \Re(\alpha_{0}) = \alpha_{0}$
	    \item[$\star$] $f'(t_{0}) = \Re(g(t_{0}))' = \Re(g'(t_{0})) = \Re(\alpha_{1}) = \alpha_{1}$
	\end{itemize}
	Donc $f$ est une solution réelle définie sur $J$ au problème de Cauchy.
	\newline

	\textbf{Unicité : }Soient $f_{1}$ et $f_{2}$ deux fonctions à valeurs réelles solutions du problème de Cauchy ci-dessus fixées quelconques : puisque $\mathbb{R} \subset \mathbb{C}$, $f_{1}$ et $f_{2}$ sont des fonctions à valeurs dans $\mathbb{C}$ solutions du même problème de Cauchy; or il y a unicité de la solution au problème de Cauchy dans les fonctions à valeurs complexes, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{C})$, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{R})$.
	\end{question_kholle}

	\begin{question_kholle}[
		Soient $(a,b)\in \mathbb{C}^2$, $f$ et $g$ les  solutions, définies sur $\mathbb{R}$ à valeurs
		dans $\mathbb{C}$, des problèmes de Cauchy suivants :
		\[
		    \left\{ \begin{array}{cl}
		        y'' +ay'+by = 0 \\
		        y(3) = 1\\
		        y'(3) = 0
		        \end{array} \right.
			\quad \text{et} \quad
		    \left\{ \begin{array}{cl}
		        y'' +ay'+by = 0 \\
		        y(3) = 0\\
		        y'(3) = 1
		        \end{array} \right.
		\]

		Comment s'exprime la solution définie sur $\mathbb{R}$ de $\left\{ \begin{array}{cl}
		    y'' +ay'+by = 0 \\
		    y(3) = \alpha \\
		    y'(3) = \beta
		    \end{array} \right. $ pour $(\alpha, \beta)\in \mathbb{R}^2$ fixés ?

		Peut-on affirmer que le plan vectoriel des solutions définies sur $\mathbb{R}$ à valeurs dans
		$\mathbb{C}$ de $y'' + ay' + by = 0$ est $\{ \lambda \cdot f + \mu \cdot g  |
		(\lambda, \mu)\in \mathbb{C}^2\}$
		]
		{Les solutions d'une EDL$_2$ constituent un espace vectoriel.}

	    La solution s'exprime simplement comme combinaison linéaire de f et g, plus précisément, la
	    combinaison linéaire en $\alpha$ et $\beta$. En effet, soient de tels scalaires, et soient $f$ et
	    $g$ de telles solutions, on a :
	    \[
	        (\alpha \cdot f + \beta \cdot g)'' + a (\alpha \cdot f + \beta \cdot g)' + b (\alpha \cdot f +
	        \beta \cdot g) = 0 \text{, par définition des espaces vectoriels.}
	    \]
	    Et de même, $(\alpha \cdot f + \beta \cdot g)'(3) = \alpha \cdot f'(3) + \beta \cdot g'(3) = \alpha$,
	    et $(\alpha \cdot f + \beta \cdot g)''(3) = \alpha \cdot f''(3) + \beta \cdot g''(3) = \beta$.
	    \newline
	    Ce qui suffit par unicité des solutions ( de la donc) d'un problème de Cauchy dans le cadre du
	    théorème du cours.
	    \newline
	    Pour ce qui est du plan vectoriel des solutions, noté $\Omega$, notons aussi $\Phi$ l'ensemble proposé.
	    L'inclusion $\Phi \subset \Omega$ est triviale par propriété de linéarité des espaces vectoriels.
	    Finalement, pour $\Omega \subset \Phi$, soit $\omega \in \Omega$, forcément, $\omega$ vérifie
	    l'$EDL_2$, mais aussi des conditions de Cauchy bien que celles-ci soient non-spécifiées, ainsi
	    posons $\omega'(3) = \delta$ et $\omega''(3) = \theta$, donc en particulier, $ \omega =
	    \delta \cdot f + \theta \cdot g$, d'où l'égalité par double inclusion.
	\end{question_kholle}

	\begin{question_kholle}
		[
		Résolution générale des systèmes linéaires à 2 équations et 2 inconnues en fonction du déterminant du systèmes (\textbf{tous les cas ne sont pas nécessairement à envisager})

		Considérons le système linéaire à deux équations et à deux inconnues $(x,y)$ :
		\begin{equation}
			(S)
			\left\{
				\begin{matrix}
					ax + by = b_1 &(E_1) \\
					cx + dy = b_2 &(E_2)
				\end{matrix}
			\right.
		\end{equation}
		dont $(a,b,c,d) \in \K^4$ sont les coefficients et $(b_1,b_2) \in \K^2$ sont les seconds membres.

		\begin{enumerate}
			\item (S) admet une unique solution si et seulement si
			$\begin{vmatrix}
				a & b \\
				c & d
			\end{vmatrix}
			= ad - bc \neq 0$. De plus, dans ce cas, la solution est
			\begin{equation}
				\left(
					\frac
						{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}
						{\begin{vmatrix}a&b\\c&d\end{vmatrix}},
					\frac
						{\begin{vmatrix}a&b_1\\c&b_2\end{vmatrix}}
						{\begin{vmatrix}a&b\\c&d\end{vmatrix}}
				\right)
			\end{equation}
			\item Si $ad - bc = 0$, alors l'ensemble des solutions est soit vide, soit une droite affine de $\K^2$, soit $\K^2$.
		\end{enumerate}
		]
		{Formules de Cramer pour les systèmes 2 $\times$ 2}
		Procédons par disjonction de cas.

		\begin{itemize}[label=$\bullet$ Supposons]
			\item que $ad - bc \neq 0$.
			\begin{itemize}[label=$\bullet$ Supposons]
				\item que $a \neq 0$.
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{
							\begin{array}{cccccc}
								ax &+& by &=& b_1 \\
								&&\left(d - \frac{bc}{a}\right)y &=& b_2 - \frac{c}{a} b_1 &(L_1 \leftarrow L_1 - \frac{c}{a} L_2) \\
							\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{cccccc}
							ax &+& by &=& b_1 \\
							&&\left(ad - bc\right)y &=& a b_2 - c b_1 &(L_1 \leftarrow aL_1) \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccc}
							ax &=& \frac{1}{a} \left(b_1 - b\frac{ab_2 - cb_1}{ad - bc}\right) = \frac{1}{a} \frac{adb_1 - bcb_1 + abb_2 - bcb_2}{ad - bc} \\
							y &=& \frac{ab_2 - cb_1}{ad - bc} \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccccc}
							ax &=& \frac{db_1 - bb_2}{ad - bc} &=& \frac{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}{\begin{vmatrix}a&b\\c&d\end{vmatrix}} \\
							y &=& \frac{ab_2 - cb_1}{ad - bc} &=& \frac{\begin{vmatrix}a&b_1\\c&b_2\end{vmatrix}}{\begin{vmatrix}a&b\\c&d\end{vmatrix}}\\
						\end{array}
						\right.
					\end{aligned}
				\end{equation*}
				Donc le système admet une unique solution qui est celle annoncée.

				\item que a = 0. L'hypothèse $ad - bc \neq 0$ implique $bc \neq 0$ donc $b \neq 0$ et $c \neq 0$.
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{
						\begin{array}{ccccc}
							&& by &=& b_1 \\
							cx &+& dy &=&  b_2 \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccc}
							x &=&  \frac{1}{c} \left( b_2 - d\frac{b_1}{b} \right) \\
							y &=& \frac{b_1}{b} \\
						\end{array}
						\right. \\
						&\iff \left\{
						\begin{array}{ccccc}
							ax &=& \frac{db_1 - bb_2}{- bc} &=& \frac{\begin{vmatrix}b_1&b\\b_2&d\end{vmatrix}}{\begin{vmatrix}0&b\\c&d\end{vmatrix}} \\
							y &=& \frac{- cb_1}{- bc} &=& \frac{\begin{vmatrix}0&b_1\\c&b_2\end{vmatrix}}{\begin{vmatrix}0&b\\c&d\end{vmatrix}}\\
						\end{array}
						\right.
					\end{aligned}
				\end{equation*}
			\end{itemize}
			Donc le système admet une unique solution qui est celle annoncée.
		\end{itemize}

		\item $ad - bc = 0$.
		\begin{itemize}[label=$\bullet$ Supposons]
			\item $a \neq 0$. En reprenant la méthode pivot de Gauss,
			\begin{equation*}
				\begin{aligned}
					(S)
					&\iff \left\{
					\begin{array}{cccccc}
						ax &+& by &=& b_1 \\
						&&\left(d - \frac{bc}{a}\right)y &=& b_2 - \frac{c}{a} b_1 &(L_1 \leftarrow L_1 - \frac{c}{a} L_2) \\
					\end{array}
					\right. \\
					&\iff \left\{
					\begin{array}{cccccc}
						ax &+& by &=& b_1 \\
						&& \underbrace{\left(ad - bc\right)}_0 y &=& a b_2 - c b_1 &(L_1 \leftarrow aL_1) \\
					\end{array}
					\right. \\
				\end{aligned}
			\end{equation*}
			Donc le système est de rang 1 avec une condition de compatibilité. \\
			Si $ab_2 - cb_1 \neq 0$, (S) n'admet aucune solution. \\
			Sinon $ab_2 - cb_1 = 0$
			\begin{equation}
				(S) \iff
				ax + by = b_1 \iff
				\begin{pmatrix} x \\ y \end{pmatrix} \in \left\{
					\begin{pmatrix} \frac{b_1}{a} - b\frac{t}{a} \\ t \end{pmatrix}
					|\; t \in \K
				\right\}
			\end{equation}
			Donc (S) admet un droite affine de solutions.

			\item $a = 0$. Puisque $ad - bc = 0$, alors $bc = 0$ donc b ou c est nul.

			\begin{itemize}[label=$\bullet$ Si]
				\item $c = 0$,
				\begin{equation*}
					(S) \iff
					\left\{ \begin{array}{ccc}
							by &=& b_1 \\
							dy &=& b_2
					\end{array} \right.
				\end{equation*}

				\begin{itemize}[label=$\bullet$ Si]
					\item $b = 0$,
					\begin{equation*}
						(S) \iff
						\left\{ \begin{array}{ccc}
							by &=& b_1 \\
							0 &=& b_2
						\end{array} \right.
					\end{equation*}
					\begin{itemize}[label=$\bullet$ Si]
						\item $b_2 = 0$, (S) n'admet aucune solution.
						\item $b_2 \neq 0$, $(S) \iff dy = b_2$
							\subitem$\bullet$ Si $d = 0$, $(S) \iff 0 = b_2$. (S) n'admet aucune solution ($b_2 \neq 0$) ou admet $\K^2$ comme ensemble des solutions ($b_2 = 0$).
							\subitem$\bullet$ Si $d \neq 0$, $(S) \iff y = \frac{b_2}{d} \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} t \\ \frac{b_2}{d} \end{pmatrix} |\; t \in \K \end{Bmatrix}$. Donc (S) admet une droite affine de solutions.
					\end{itemize}
					\item $b \neq 0$
					\begin{equation*}
						(S) \iff
						\left\{ \begin{array}{ccc}
							y &=& \frac{b_1}{b} \\
							0 &=& b_2 - \frac{db_1}{b}
						\end{array} \right.
					\end{equation*}
					\begin{itemize}[label=$\bullet$ Si]
						\item $b_2 - \frac{db_1}{b} \neq 0$, (S) n'admet aucune solution.
						\item $b_2 - \frac{db_1}{b} = 0$, $(S) \iff y = \frac{b_1}{b} \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} t \\ \frac{b_1}{d} \end{pmatrix} |\; t \in \K \end{Bmatrix}$ donc (S) admet une droite affine de solutions.
					\end{itemize}
				\end{itemize}
				\item $c \neq 0$ alors $b = 0$
				\begin{equation*}
					\begin{aligned}
						(S)
						&\iff \left\{ \begin{array}{ccc}
							0 &=& b_1 \\
							cx + dy &=& b_2
						\end{array} \right.
					\end{aligned}
				\end{equation*}
				\begin{itemize}[label=$\bullet$ Si]
					\item $b_1 \neq 0$, (S) n'admet aucune solution.
					\item $b_1 = 0$, $(S) \iff x = \frac{b_2}{c} - \frac{d}{c}y \iff \begin{pmatrix} x \\ y \end{pmatrix} \in \begin{Bmatrix} \begin{pmatrix} \frac{b_2}{c} - \frac{d}{c}t \\ t \end{pmatrix} |\; t \in \K \end{Bmatrix}$ donc (S) admet une droite affine de solutions.
				\end{itemize}
			\end{itemize}
		\end{itemize}

	\end{question_kholle}

\pagebreak\section{Semaine 9}
	
	\begin{question_kholle}
		[\noindent Soit \Rel une relation d'équivalence sur $E$. \\
		Soit $x \in E$. \\
		La classe de $x$, notée $\bar{x}$, est l'ensemble des éléments de $E$ en relation avec x.
		\begin{equation}
			\bar{x} = \left\{ y \in E \;|\; x \Rel y \right\}
		\end{equation}]
		{Deux classes d'équivalence sont disjointes ou confondues. Les classes d'équivalence constituent une partition de l'ensemble sur lequel on considère la relation d'équivalence.}
		
		\textit{Montrons que deux classes d'équivalence sont disjointes ou confondues.}
		
		Soit $(x, y) \in E^2$ fq.
		\begin{itemize}[label=\textemdash]
			\item Si $\bar{x} \cap \bar{y} = \emptyset$, rien à démontrer.
			\item Sinon $\bar{x} \cap \bar{y} \neq \emptyset$ donc $\exists z \in \bar{x} \cap \bar{y}$. Fixons un tel $z$.

			Soit $x' \in \bar{x}$ fq.
			\begin{equation*}
				\left.
				\begin{matrix}
					\left. \begin{matrix}
						x' \in \bar{x} \implies x \Rel x' \underset{sym\acute{e}trie}{\implies} x' \Rel x \\
						z \in \bar{x} \implies x \Rel z
					\end{matrix}
					\right\} \underset{transitivit\acute{e}}{\implies} x' \Rel z \\
					z \in \bar{y} \implies y \Rel z \underset{sym\acute{e}trie}{\implies} z \Rel y
				\end{matrix}
				\right\} \underset{transitivit\acute{e}}{\implies} x' \Rel y
				\underset{sym\acute{e}trie}{\implies} y \Rel x'
			\end{equation*}
			
			Donc $x' \in \bar{y}$ donc $\bar{x} \subset \bar{y}$.
			
			En échangeant les rôles de $x$ et $y$, on montre la deuxième inclusion $\bar{y} \subset \bar{x}$.
		\end{itemize}
		\bigbreak
	
		\textit{Montrons que les classes d'équivalence de E constituent une partition de E.}
		
		Soit $\Sol$ un système de représentant des classes fixé quelconque.
		
		\begin{itemize}[label=\textemdash]
			\item Soit $s\in \Sol$ fq. $\bar{s} \neq \emptyset$ car $s \Rel s$ par réflexivité.
			\item Soit $(s, s') \in \Sol^2$ fq. D'après la démonstration ci-dessus ci-dessus, $\bar{s} \cap \bar{s'} = \emptyset$ ou $\bar{s} = \bar{s'}$. Si $\bar{s} = \bar{s'}$ alors $s$ et $s'$ représente la même classe ce qui est impossible car un système de représentants des classes contient un unique représentant de chaque classe. Par conséquent, $\bar{s}$ et $\bar{s'}$ sont disjoints.
			\item $\underset{s \in \Sol}{\bigcup} \bar{s} \subset E$ car $\forall s \in \Sol, \bar{s} \in E$ par définition d'une classe d'équivalence. \\
			Réciproquement, soit $x \in E$ fq. \\
			Par réflexivité de \Rel, $x \in \bar{x}$. \\
			Par définition d'un système de classe $\exists ! s_x \in \Sol : s_x \in \bar{x}$ donc $\bar{s_x} = \bar{x}$. Donc $x \in \bar{s_x} \subset \underset{s \in \Sol}{\bigcup} \bar{s}$. Donc $E \subset \underset{s \in \Sol}{\bigcup} \bar{s}$. \\
			Par double inclusion, $E = \underset{s \in \Sol}{\bigcup} \bar{s}$.			
		\end{itemize}
		
		Ainsi,
		\begin{equation}
			E = \coprod_{s \in \Sol} \bar{s}
		\end{equation}
		
	\end{question_kholle}

	\begin{question_kholle}
		[\noindent Soit $(E, \leq)$ un ensemble ordonné, et $A$ une partie non-vide de $E$. \\
		Si $A$ admet un plus grand élément alors $A$ admet une borne supérieure et $\sup{A} = \max{A}$. \\
		Si $A$ admet une borne supérieure appartenant à elle-même alors $A$ admet un plus grand élément et $\max{A} = \sup{A}$.]
		{Si $A$ admet un plus grand élément c'est aussi sa borne supérieure. Si $A$ admet une borne supérieure dans $A$ c'est sont plus grand élément.}
		
		Soient un tel ensemble $E$ et une telle partie $A$ et notons $M$ son plus grand élément. \\
		Posons l'ensemble des majorants de $A$, $M(A) = \{ m\in E \ | \ \forall a \in A, \ a \leq m\}$. \\
		Par définition : 
		\[
		\forall m \in M(A), \ M \leq m,
		\]
		car $M\in A$, mais comme $M\in M(A)$, on a directement que $M = \min{M(A)} = \sup{A}$. \\
		
		Pseudo-réciproquement, soit $A$ une partie de $E$ admettant une borne supérieure dans elle même, notons cette borne $S$. \\
		Comme $S \in M(A)$, par définition, $S$ est plus grand que tous les éléments de $A$ mais appartient à $A$, donc de tous les éléments de $A$, $S$ est le plus grand.
	\end{question_kholle}

	\begin{question_kholle}
		[\begin{equation}
			\forall (a, b) \in \Z^2,
			\exists ! (q, r) \in \Z \times \N :
			\left\{ \begin{matrix}
				a = b q + r \\
				r \in {[\![} 0 ; |b|-1 {]\!]}
			\end{matrix} \right.
		\end{equation}]
		{Théorème de la division Euclidienne dans \Z}
		
		\textit{Unicité} \;
		Soient deux tels entiers $(a,b) \in \Z^2$ et deux couples $((q,r),(q',r')) \in \left(\Z \times \N\right)^2$ tels que
		\begin{equation*}
			\left\{ \begin{matrix}
				a = b q + r \\
				0 \leqslant r \leqslant |b| - 1
			\end{matrix} \right.
			\qquad
			\left\{ \begin{matrix}
				a = b q' + r' \\
				0 \leqslant r' \leqslant |b| - 1
			\end{matrix} \right.
		\end{equation*}
		Directement, 
		\[
		b(q-q') = r'-r,
		\]
		mais comme $-(|b|-1) \leqslant r' - r \leqslant |b| -1$, il vient en divisant par $|b|$ l'inégalité précédente :
		\[
		-1 < q - q' < 1,
		\]
		puisque $q$ et $q'$ sont dans $\Z$ leur différence est obligatoirement $0$, ainsi $q = q'$ ce qui implique $ r= r'$ et donc on a unicité de ladite écriture de $a$.
		\newline
		\\
		\textit{Existence} \; Posons pour $b \geqslant 1$, $\Omega = \{ k\in \Z  \ | \ kb \leqslant a \}$
		\begin{itemize}
			\item $\Omega \subset \Z$
			\item non-vide car $-|a| \in \Omega$ ($\Z$ archimédien suffit \ldots) 
			\item $\Omega$ est majoré par $|a|$ car supposons, par l'absurde, que $\exists k \in \Omega : k > |a|$, alors $kb > |a|b > a$ ce qui contradiction avec la définition d'$\Omega$.
		\end{itemize}
		Donc $\Omega$ admet un plus grand élément, notons-le $q$. \\
		Posons $r = a - bq$. Par construction, $a = bq + r$ et comme $q = \max \Omega$ et $\Omega \subset \Z$, $q \in \Z$ donc $r \in \Z$.
		\\
		Par suite, $q \in \Omega$ donc $bq \leqslant a$ d'où $0 \leqslant r$. Et $q = \max \Omega$ donc $b(q+1) > a$ d'où $b > r$, c'est-à-dire, $r\in [\![ 0, |b| -1 ]\!]$.
		
		Si $b< 1$, il suffit de prendre $q \leftarrow -q$ dans la preuve précédente.C'est donc l'existence de ladite écriture de $a$.
	\end{question_kholle}

	\begin{question_kholle}{Une suite décroissante et minorée de nombres entiers relatifs est stationnaire}
		Soit $u \in \Z^\N$ une suite décroissante et minorée fixée quelconque. \\
		Considérons $A = \{ u_n \;|\; n \in \N \}$ c'est-à-dire l'ensemble des valeurs prises par la suite $u$. \\
		$A$ est : \begin{itemize}[label=\textemdash]
			\item une partie de \Z car $u$ est à valeur dans \Z
			\item non vide car $u_0 \in A$
			\item minoré car $u$ est minorée
		\end{itemize}
		Donc $A$ admet un plus petit élément. Donc $\exists n_0 \in \N: u_{n_0} = min A$. Fixons un tel $n_0$. \\
		Soit $n \in \N$ fq tq $n \geqslant n_0$.
		\begin{equation*}
			\left. \begin{matrix}
				u_n \in A \implies u_n \geqslant min A = u_{n_0} \\
				 u \text{ est décroissante et } n \geqslant n_0 \text{ donc } u_n \leqslant u_{n_0}
			\end{matrix}
			\right\} \implies u_n = u_{n_0}
		\end{equation*}
  		Ainsi, $u$ est stationnaire.
	\end{question_kholle}
\pagebreak\section{Semaine 10}

	\begin{question_kholle}
		[\noindent Soient $(A, B) \in \mathcal{P}(\R)^2$ fq. \\
		\textit{Définition de la densité}
		\begin{align}
			A \text{ est dense dans } B
			\text{ si } \left\{ \begin{array}{ll}
				A \subset B \\
				\mathrm{et} \\
				\forall (u,v) \in \R^2, B \cap {]}u;v{[} \neq \emptyset \implies A \cap  {]}u;v{[} \neq \emptyset
			\end{array} \right.
		\end{align}
		\textit{Caractérisation de la densité par les $\varepsilon$}
		\begin{align}
			A \text{ est dense dans } B
		 	\iff \left\{ \begin{array}{ll}
				A \subset B \\
				\mathrm{et} \\
				\forall b \in B, \forall \varepsilon \in \R_+^*, \exists a \in A: |b-a|< \varepsilon
			\end{array} \right.
		\end{align}
		]
		{Caractérisation de la densité d’une partie $A$ de \R dans une partie $B$ de \R la contenant avec des $\varepsilon$.}

		\textit{Montrons la caractérisation de la densité}\\
		\emph{Sens Direct} Supposons $A$ dense dans $B$
		\begin{itemize}[label=\textemdash]
            \item Par déf $A \subset B$
            \item Soit $b \in B$ et $\varepsilon \in \R_+^*$ fq

            Appliquons le (ii) de la déf de Densité pour $u \leftarrow b - \varepsilon$ et $v \leftarrow b + \varepsilon$
            $$B \cap ]b - \varepsilon, b + \varepsilon[ \neq \emptyset \implies A \cap ]b - \varepsilon,  b + \varepsilon[ \neq \emptyset$$
            Or, $B \cap ]b - \varepsilon, b + \varepsilon[ \neq \emptyset$ est vraie
            donc $A \cap ]b - \varepsilon,  b + \varepsilon[ \neq \emptyset$

            Ce qui permet de choisir $a \in A \cap ]b - \varepsilon,  b + \varepsilon[$.
            Un tel $a$ vérifie $a \in A$ et $a \in ]b - \varepsilon,  b + \varepsilon[ \iff |b-a| < \varepsilon$
		\end{itemize}
		\bigbreak
    	\noindent \emph{Sens réciproque} Supposons $\left\{\begin{array}{ll} A \subset B \\\mathrm{et}\\ \forall b \in B, \forall \varepsilon \in \R_+^*, \exists a \in A: |b-a|< \varepsilon \end{array}\right.$

        \begin{itemize}
            \item On a donc $A \subset B$
            \item Soient $(u, v) \in \R^2$ fq tq $B \cap ]u, v[ \neq \emptyset$

			Soit $b \in B \cap ]u, v[$ fq.
            Appliquons l'hypothèse pour $b\leftarrow b$ et $\varepsilon \leftarrow \min\{v - b, b - u\}$, qui est autorisé $v-b$ et $b-u$ sont positifs

            Donc $\exists a \in A: | b - a| < \varepsilon $

            Fixons un tel a, alors:
            $$
                b-\varepsilon < a < b + \varepsilon
            $$

            Donc $$
            \left\{\begin{array}{ll}
            a < b + \varepsilon = b + \underbrace{\min\{v - b, b - u\}}_{\leqslant v - b} \leqslant b + v - b = v \\ \mathrm{et}\\
            a > b - \varepsilon = b - \underbrace{\min\{v - b, b - u\}}_{\leqslant b - u} \geqslant b - (b - u) = u
            \end{array}\right.
            $$

            Donc $a \in ]u, v[$.
        \end{itemize}
        Donc $A \cap ]u, v[ \neq \emptyset$

	\end{question_kholle}

	\begin{question_kholle}
		[\begin{equation}
			\forall (a, b) \in \R \times \R^*,
			\exists ! (q, r) \in \Z \times \R :
			\left\{ \begin{matrix}
				a = b q + r \\
				r \in [0;|b|[
			\end{matrix} \right.
		\end{equation}]
		{Théorème de la division pseudo-euclidienne dans \R}

		\textit{Unicité} \;
		Soient deux tels entiers $(a,b) \in \R^2$ et deux couples $((q,r),(q',r')) \in \left(\Z \times \R\right)^2$ tels que
		\begin{equation*}
			\left\{ \begin{matrix}
				a = b q + r \\
				r \in [0;|b|[
			\end{matrix} \right.
			\qquad
			\left\{ \begin{matrix}
				a = b q' + r' \\
				r' \in [0;|b|[
			\end{matrix} \right.
		\end{equation*}
		Directement,
		\[
		b(q-q') = r'-r,
		\]
		mais comme $-|b| < r' - r < |b|$, il vient en divisant par $|b|$ l'inégalité précédente :
		\[
		-1 < q - q' < 1,
		\]
		puisque $q$ et $q'$ sont dans $\Z$ leur différence est obligatoirement $0$, ainsi $q = q'$ ce qui implique $ r= r'$ et donc on a unicité de ladite écriture de $a$.
		\newline
		\\
		\textit{Existence} \; Posons pour $b > 0$, $\Omega = \{ k\in \Z  \ | \ kb \leqslant a \}$
		\begin{itemize}
			\item $\Omega \subset \Z$
			\item non-vide car $-|a| \in \Omega$ ($\Z$ archimédien suffit \ldots)
			\item $\Omega$ est majoré par $|a|$ car supposons, par l'absurde, que $\exists k \in \Omega : k > |a|$, alors $kb > |a|b > a$ ce qui contradiction avec la définition d'$\Omega$.
		\end{itemize}
		Donc $\Omega$ admet un plus grand élément, notons-le $q$. \\
		Posons $r = a - bq$. Par construction, $a = bq + r$ et comme $q = \max \Omega$ et $r \in \R$.
		\\
		Par suite, $q \in \Omega$ donc $bq \leqslant a$ d'où $0 \leqslant r$. Et $q = \max \Omega$ donc $b(q+1) > a$ d'où $b > r$, c'est-à-dire, $r \in [ 0, |b| [$.

		Si $b < 0$, il suffit de prendre $q \leftarrow -q$ dans la preuve précédente.C'est donc l'existence de ladite écriture de $a$.
	\end{question_kholle}

	\begin{question_kholle}
		{\Q est dense dans \R et $\R \setminus \Q$ est aussi dense dans \R}

		Soit $x \in \R$ fq.
		Posons $\forall n \in \N, a_n = \frac{\lfloor2^n x\rfloor}{2^n}$. \\
		Soit $n \in \N$ fq. \\
		\begin{itemize}
			\item $a_n \in \Q$ car $\lfloor2^n x\rfloor \in \Z$ et $2^n \in \N$.
			\item \begin{equation*}
					a_n = \frac{\lfloor2^n x\rfloor}{2^n}
					\implies \frac{2^n x - 1}{2^n} \leqslant a_n \leqslant \frac{2^n x}{2^n}
					\implies x - \frac{1}{2^n} \leqslant a_n \leqslant x
				\end{equation*}
				Or $\nicefrac{1}{2^n} \arrowlim{n}{+\infty} 0$ donc d'après le théorème d'existence de limite par encadrement, \\ $a_n \arrowlim{n}{+\infty} x$.
		\end{itemize}
		Donc d'après la caractérisation séquentielle de la densité, \Q est dense dans \R.
		\bigbreak

		\noindent Soit $x \in \R$ fq. \\
		Alors $x + \sqrt{2} \in \R$.
		D'après la démonstration précédente, $\exists b \in \Q^\N : b_n \arrowlim{n}{+\infty} x + \sqrt{2}$. \\
		Fixons un telle suite $b$.
		Considérons $c = b - \sqrt{2}$. \\
		Soit $n \in \N$ fq.
		\begin{itemize}
			\item $c_n \in \R\setminus\Q$ car $b_n \in \Q$ et $\sqrt{2} \in \R \setminus \Q$.
			\item \begin{equation*}
				\left. \begin{matrix}
					b_n \arrowlim{n}{+\infty} x + \sqrt{2} \\
					c_n = b_n - \sqrt{2}
				\end{matrix} \right\}
				\implies c_n \arrowlim{n}{+\infty} x
			\end{equation*}
		\end{itemize}
		Donc d'après la caractérisation séquentielle de la densité, $\R\setminus \Q$ est dense dans \R.
	\end{question_kholle}

	\begin{question_kholle}[
        Soit u $\in \K ^ \N, (\ell_1, \ell_2) \in \K ^2$
        Si u converge vers $\ell_1$ et $\ell_2$, alors $\ell_1 = \ell_2$
    ]{Preuve de l'unicité de la limite d'une suite convergente}
    Par l'absurde, supponsons que $u$ converge vers $\ell_1$ et $\ell_2$, et $\ell_1 \neq \ell_2$.
    On prendra $\varepsilon_0 = \varepsilon_1 = \varepsilon_2$ assez petit pour que les tubes soient disjoints.\\
    Posons donc $\varepsilon_0 = \frac{|\ell_1 - \ell_2|}{3}$
    \begin{itemize}
        \item Appliquons la définition de la convergence de u vers $\ell_1$, pour $\varepsilon \leftarrow \varepsilon_0$, ce qui est autorisé car $\varepsilon_0 \in \R_+^*$
        \begin{equation}\label{eq:1}
            \exists N_1 \in \N : \forall n \in \N, n \geqslant N_1 \implies |u_n - \ell_1| \leqslant \varepsilon_0
        \end{equation}
        \begin{equation}\label{eq:2}
            \exists N_2 \in \N : \forall n \in \N, n \geqslant N_2 \implies |u_n - \ell_2| \leqslant \varepsilon_0
        \end{equation}
        Fixons de tels $N_1$ et $N_2$.
        \item Posons $n_0 = N_1 + N_2$
        \begin{itemize}
            \item $n_0 \geqslant N_1$, donc (\ref{eq:1}) s'applique: $|u_{n_0} - \ell_1| \leqslant \varepsilon_0$
            \item $n_0 \geqslant N_2$, donc (\ref{eq:2}) s'applique: $|u_{n_0} - \ell_2| \leqslant \varepsilon_0$
        \end{itemize}
        \item \begin{align*}
            |\ell_1 - \ell_2| &= |\ell_1 - u_{n_0} + u_{n_0} - \ell_2|\\
            &\leqslant \underbrace{|\ell_1 - u_{n_0}|}_{\leqslant \varepsilon_0} + \underbrace{|u_{n_0} - \ell_2|}_{\leqslant \varepsilon_0}\\
            &\leqslant 2 \frac{|\ell_1 - \ell_2|}{3}\\
            \implies 1 &\leqslant \frac 2 3
        \end{align*}
        Contradiction
    \end{itemize}
	\end{question_kholle}

	\begin{question_kholle}{Une suite convergente est bornée}

        Soit $u \in \mathbb{K}^{\mathbb{N}}$ convergente.
Posons $\ell = \lim u$
Appliquons la définition de la convergence pour $\varepsilon \leftarrow 1$
$$
\exists N_{1}\in \mathbb{N}: \forall n \in \mathbb{N}, n \geqslant N_{1} \implies |u_{n}-\ell| \leqslant 1
$$
Fixons un tel $N_{1}$
Posons alors $M = \max\left\{ |u_{0}|, |u_{1}|, |u_{2}| \dots |u_{N_{1}}|, |\ell|+1 \right\}$, qui est bien défini, car toute partie finie, non vide d'un ensemble totalement ordonné (ici $(\mathbb{R}, \leqslant)$) admet un pgE.

Soit $n \in \mathbb{N}$ fq.
\begin{itemize}
    \item Si $n \in [[0, N_{1}]], |u_{n}| \in \left\{ |u_{0}|, |u_{1}|, |u_{2}| \dots |u_{N_{1}}|, |\ell|+1 \right\}$ donc $|u_{n}| \leqslant M$
	\item Sinon,
\end{itemize}

\begin{align*}
n> N_{1} &\implies |u_{n} - \ell| \leqslant 1 \\
&\implies |u_{n}| - |\ell| \leqslant 1 \\
 & \implies |u_{n}| \leqslant 1+ |\ell| \leqslant M
\end{align*}

Ainsi, $\forall n \in \mathbb{N}, |u_{n}| \leqslant M$.
    \end{question_kholle}
\pagebreak\section{Semaine 11}

	\begin{question_kholle}
		[Soient $(A,B) \in (\mathcal{P}(\R) \setminus \{\varnothing\})^{2}$. Montrons que :
		\\
		$$A \text{ est dense dans } B \iff \left\{ \begin{array}{l}
			A \subset B \\
			\forall b \in B, \exists(a_{n}) \in A^{\N} : (a_{n}) \text{ converge vers }b
		\end{array}\right. $$
		]
		{Caractérisation séquentielle de la densité.}
		
		Sens indirect : supposons $A \subset B$ et $\forall b \in B, \exists(a_{n}) \in A^{\N} : (a_{n}) \text{ converge vers }b$ :\\
		\begin{itemize}
			\item[$\star$] $A \subset B$ par hypothèse.
			\item[$\star$] Montrons que $\forall b \in B, \forall \varepsilon \in \R^{*}_{+}, \exists a \in A : |b - a| < \varepsilon$ (on utilise la caractérisation de la densité avec les $\varepsilon$) \\
			Soient $b \in B$ et $\varepsilon \in \R^{*}_{+}$ fixés quelconques : \\
			Par hypothèse appliquée pour $b \leftarrow b$ : $\exists(a_{n}) \in A^{\N} : a_{n} \underset{n \to +\infty}{\longrightarrow}b$ \\
			Appliquons la définition de la convergence de $(a_{n})$ vers $b$ pour $\varepsilon \leftarrow \frac{\varepsilon}{2}$ : \\
			$$\exists N \in \N : \forall n \in \N, n \geqslant N \Rightarrow |a_{n} - b| \leqslant \frac{\varepsilon}{2}$$
			Fixons un tel N : \\
			En particulier, $a_{N} \in A$ et $|a_{N} - b| \leqslant \frac{\varepsilon}{2} \leqslant \varepsilon$ \\
			Donc $A$ est dense dans $B$.
		\end{itemize}
		
		Sens direct : supposons $A$ dense dans $B$ : \\
		\begin{itemize}
			\item[$\star$] Par définition, $A \subset B$
			\item[$\star$] Soit $b \in B$ fixé quelconque. \\
			Soit $n \in \N$ fixé quelconque :  \\
			Appliquons la caractérisation de la densité par les $\varepsilon$ pour $\varepsilon \leftarrow \frac{1}{2^{n}}$ (autorisé car $\frac{1}{2^{n}} > 0$), et $b \leftarrow b$ : 
			$$\exists a \in A : |a - b| \leqslant \frac{1}{2^{n}}$$
			Notons $a_{n}$ un tel élément. Nous venons de construire $(a_{n})_{n \in \N} \in A^{\N}$ vérifiant : \\
			$\forall n \in \N, |a_n - b| \leqslant \frac{1}{2^{n}}$ \\
			Or : $\underset{n \to +\infty}{\lim} \frac{1}{2^{n}} = 0$ \\
			Ainsi, d'après le théorème sans nom, $(a_{n})_{n \in \N}$ converge vers $b$.
		\end{itemize}
	\end{question_kholle}

	\begin{question_kholle}
		[Soit $u \in \R^\N$ une suite monotone :
		{\begin{enumerate}
			\item Si $u$ est croissante
			\begin{enumerate}[label=($\roman*$)]
				\item Soit $u$ est majorée, et dans ce cas, $\lim u = \sup\{ u_k | k \in \N \}$
				\item Soit $u$ n'est pas bornée, et dans ce cas, $u$ diverge vers $+\infty$.
			\end{enumerate}
			\item Si $u$ est décroissante :
			\begin{enumerate}[label=($\roman*$) Soit, leftmargin=4em]
				\item $u$ est minorée, et dans ce cas, $\lim u = \inf\{ u_k | k \in \N \}$
				\item $u$ n'est pas bornée, et dans ce cas, $u$ diverge vers $-\infty$.
			\end{enumerate}
		\end{enumerate} }]
		{Théorème de la convergence monotone}
		
		Soit $u \in \R^\N$ monotone fq.
		
		\begin{enumerate}
			\item Supposons que $u$ est croissante.
			\begin{enumerate}[label=($\roman*$)]
				\item Supposons que $u$ est majorée. \\
				Alors $\exists M \in \R : \forall n \in \N, u_n \leqslant M$. Fixons un tel M. \\
				$\Omega = \{ u_k | k \in \N \}$ est \begin{itemize}
					\item une partie de \R
					\item non vide car $u_0$ y appartient
					\item majorée par M
				\end{itemize}
				donc elle admet un borne supérieure et notons-la $\sigma$. \\
				Soit $\epsilon \in \R_+^*$ fq. \\
				$\sigma - \epsilon < \sigma$ donc $\sigma - \epsilon$ ne majore pas $\Omega$. Donc $\exists N \in \N : u_N > \sigma - \epsilon$. Fixons un tel N. \\
				Soit $n \in \N$ fq tq $n \geqslant N$. \\
				Alors $u_n \underset{\text{par croissant de u}}{\geqslant} u_N \geqslant \sigma - \epsilon$ et $u_n \underset{\text{par défintion de }\sigma}{\leqslant} \sigma$. \\
				Ainsi,
				\begin{equation*}
					\begin{aligned}
						\sigma - \epsilon \leqslant u_n \leqslant \sigma
						&\implies - \epsilon \leqslant u_n - \sigma \leqslant 0 \\
						&\implies | u_n - \sigma | \leqslant \epsilon
					\end{aligned}
				\end{equation*}
				Donc $u_n \arrowlim{n}{+\infty} \sigma$.

				\item Supposons que $u$ n'est pas bornée. \\
				Soit $A \in \R$ fq. \\
				$u$ n'est pas bornée donc $\exists N \in \N : u_N > A$. \\
				Or $u$ est croissante donc $\forall n \in \N, n \geqslant N \implies u_n \geqslant A$. \\
				Donc $u_n \arrowlim{n}{+\infty} +\infty$.
			\end{enumerate}
		
			\item Supposons que $u$ est décroissante. \\
			Il suffit dans la preuve ci-dessus de remplacer les inégalités inférieures par des inégalités supérieures et inversement et d'utiliser la notion de borne inférieure plutôt que de borne supérieure.
			\begin{enumerate}[label=($\roman*$)]
				\item Si $u$ est minorée, $u_n \arrowlim{n}{+\infty} \inf\{u_k|k\in\N\}$.
				\item Si $u$ n'est pas bornée, $u_n \arrowlim{n}{+\infty} -\infty$.
			\end{enumerate}
		\end{enumerate}
	\end{question_kholle}
	
	\begin{question_kholle}
	    [Soit $u\in \R ^{\N}$ qui converge vers $\ell \in \R$. \\
	    Alors la moyenne arithmérique des $n\in \N$ premiers termes (appelée moyenne de Césarò) converge vers $\ell$.]
	    {Théorème de Césarò}
	
	    Soient $u$ une telle suite, $\varepsilon \in \R ^*_+$ et $\ell \in \R$ ladite limite de $u$. Appliquons la définition de la convergence de $u$ pour $\varepsilon \gets \frac{\varepsilon}{2}$ : 
	    \[
	    \exists N \in \N \ : \ \forall n \in \N , \ n\geq N \ \implies \ |u_n - \ell | \leq \frac{\varepsilon}{2}.
	    \]
	    Fixons un tel $N$. Posons $\omega = \sum_{k=0}^{N-1} |u_k - \ell | \in \R$. Soit $n\in \N$ tel que $n \geq N$. Calculons : 
	    \[
	    \left| \frac{1}{n} \sum_{k=0}^{n-1}u_k - \ell \right| = \left| \frac{1}{n} \left( \sum_{k=0}^{n-1}u_k - n\ell \right) \right|  = \left| \frac{1}{n} \sum_{k=0}^{n-1}(u_k - \ell)  \right| \leq \frac{1}{n} \underset{= \ \omega \in \R}{\underbrace{\sum_{k=0}^{N-1}|u_k - \ell|}} + \frac{1}{n} \underset{\leq \ \frac{\varepsilon}{2}}{\underbrace{\sum_{k=N}^{n}|u_k - \ell|}} \leq \frac{\omega}{n} + \underset{\leq \ \frac{\varepsilon}{2}}{\underbrace{\frac{\varepsilon}{2n}}}.
	    \]
	    Ces majorations sont issues de l'inégalité triangulaire et de la convergence de $u$. De plus, comme la suite $(v_n) _{n\in \N} = \left( \frac{\omega}{n} \right) _{n\in \N}$ converge vers $0$, on écrit sa définition pour $\varepsilon \gets \frac{\varepsilon}{2}$ : 
	    \[
	    \exists N' \in \N \ : \ \forall n \in \N , \ n\geq N' \ \implies \ |v_n| \leq \frac{\varepsilon}{2}.
	    \]
	    On fixe un tel $N'$ et on pose $\Lambda = \max{(N, N')}$ qui a bien un sens car $\{N, \ N'\}$ est une partie finie de $\N$.
	    De la même manière qu'auparavant, pour $n\in \N$ tel que $n \geq \Lambda$, on a : 
	    \[
	     \left| \frac{1}{n} \sum_{k=0}^{n-1}u_k - \ell \right| \leq \underset{\leq \ \frac{\varepsilon}{2}}{\underbrace{\frac{\omega}{n}}} + \frac{\varepsilon}{2} \leq \varepsilon.
	    \] 
	    C'est le théorème souhaité.
	\end{question_kholle}

	\begin{question_kholle}
		[Soient $(u,v) \in \R^{\N}$ : \\
		{\begin{enumerate}[label=($\roman*$)]
			\item Si $\begin{array}{|l}
				\exists N \in \N : \forall n \in \N, n \geqslant N \Rightarrow u_{n} \geqslant 0   \\
				u \text{ converge}
			\end{array}$ \\
			Alors $\lim u \geqslant 0$
			\item Si $\begin{array}{|l}
				\exists N \in \N : \forall n \in \N, n \geqslant N \Rightarrow u_{n} \leqslant v_{n}   \\
				u \text{ et } v \text{ convergent}
			\end{array}$ \\
			Alors $\lim u \leqslant \lim v$
		\end{enumerate}}
		]
		{Théorème de passage à la limite dans une inégalité.}
		~\smallbreak
		\begin{enumerate}[label=($\roman*$)]
			\item L'hypothèse $\exists N \in \N : \forall n \in \N, n \geqslant N \Rightarrow u_{n} \geqslant 0$ permet d'affirmer que $u$ et $|u|$ coïncident à partir d'un certain rang. \\
			Par ailleurs, la convergence de $u$ et la continuité de $|\cdot|$ sur $\R$ donc en $\lim u$ donnent $|u|$ converge vers $|\lim u|$. \\
			Le caractère asymptotique de la limite permet de conclure que $u$ et $|u|$ ont la même limite. \\
			Donc $\lim u = |\lim u| \geqslant 0$
			\item $\exists N \in \N : \forall n \in \N, n \geqslant N \Rightarrow u_{n} \leqslant v_{n} \Rightarrow v_{n} - u_{n} \geqslant 0$ \\
			$u$ et $v$ convergent $\Rightarrow v-u$ converge vers $\lim v - \lim u$. \\
			On applique $(i)$ pour $u \leftarrow v - u$, autorisé car $u \text{ et }v$ convergent. \\
			On obtient $\lim v - \lim u \geqslant 0$ d'où $\lim u \leqslant \lim v$.
		\end{enumerate}
	\end{question_kholle}

	\begin{question_kholle}
	    [Soient $u$ et $v$ deux suites réelles adjacentes. Alors $u$ et $v$ convergent et ont la même limite.]
	    {Théorème des suites adjacentes}
	
	    Soient $u$ et $v$ de telles suites. Quitte à inverser les rôles desdites suites, prenons $u$ croissante et $v$ décroissante. \\
	    On a donc : 
	    \[
	    \forall n \in \N, \ (u_n \leq v_n \leq \underset{\in \R}{\underbrace{v_0}}) \wedge (\underset{\in \R}{\underbrace{u_0}}\leq  u_n \leq v_n),
	    \]
	    car la monotonie des suites induit ces inégalités. D'après le théorème de limite monotone, $u$ étant croissante et majorée elle converge, $v$ étant décroissante et minorée elle converge. \\
	    Il s'en suit que par définition des suites adjacentes : 
	    \[
	    0 \ = \lim_{n \to +\infty} (u_n - v_n) \ \underset{u,v \ \text{ convergent}}{\underbrace{=}} \ \lim_{n \to +\infty} u_n - \lim_{n \to +\infty} v_n.
	    \]
	    Ainsi, $\lim u = \lim v$.
	\end{question_kholle}

	\begin{question_kholle}
		[Toute suite bornée réelle admet une sous-suite convergente. \\
		L'ensemble des valeurs d'adhérence d'une suite réelle bornée est non vide.]
		{*Facultative* Théorème de Bolzano-Weierstrass}

		Soit $u \in \R^\N$ fq bornée. \\
		Alors $\exists M \in \R_+ : \forall n \in \N, |u_n| \leqslant M$.

		Construisons une suite de segments dans $[-M;M]$ de plus en plus petits par dichotomie. \\
		Posons $a_0 = -M$, $b_0 = M$ et définissons les suites $c$ et $I$ pour tout $n$ dans \N par $c_n = \frac{a_n + b_n}{2}$ et $I_n = [a_n;b_n]$. \\
		
		\noindent Soit $n\in \N$ fq.
		Supposons $a_n \text{ et } b_n$ construits et $\{ k \in \N \;|\; u_k \in I_n \}$ infini.
		Construisons les termes d'indices $n+1$. \\
		Posons $\left| \begin{array}{lcr}
			I_n^- &=& \{ k \in \N \;|\; u_k \in [a_n;c_n] \} \\
			I_n^+ &=& \{ k \in \N \;|\; u_k \in [c_n;b_n] \} \\
		\end{array} \right.$ \\
		Nous avons $I_n^- \cup I_n^+ = \{ k \in \N \;|\; u_k \in I_n \}$ donc $I_n^-$ ou $I_n^+$ est infini.

		\begin{itemize}
			\item Si $I_n^-$ est infini, posons $\left| \begin{array}{lcl}
				a_{n+1} &=& a_n \\
				b_{n+1} &=& c_n
			\end{array} \right.$ \\
			Ainsi $\{ k \in \N \;|\; u_k \in I_{n+1} \} = I_n^-$ est infini.
			\item Si $I_n^+$ est infini, posons $\left| \begin{array}{lcl}
				a_{n+1} &=& c_n \\
				b_{n+1} &=& b_n
			\end{array} \right.$ \\
			Ainsi $\{ k \in \N \;|\; u_k \in I_{n+1} \} = I_n^+$ est infini.
		\end{itemize}
		\bigbreak

		\noindent Étudions la suite $\left(I_n\right)_{n\in\N}$.
		\begin{itemize}
			\item Nous avons toujours $a_n \leqslant b_n$ donc $\forall n \in \N, I_n \neq \emptyset$
			\item Par construction, $\forall n \in \N, I_{n+1} \subset I_n$
			\item $ |I_{n+1}| = |a_{n+1}-b_{n+1}| = \frac{1}{2} |a_n-b_n| = \frac{1}{2} |I_n| $
			donc la suite des cardinaux est une suite géométrique de raison $\nicefrac{1}{2}$.
			Donc $|I_n| \arrowlim{n}{+\infty} 0$.
		\end{itemize}
		Donc, d'après le théorème des segments emboîtés, $\exists ! l\ell \in \R : \underset{n\in\N}{\bigcap} I_n = \{\ell\}$. Fixons un tel $\ell$. \\

		Construisons maintenant une extractrice $\varphi$ de $u$. \\
		Posons $\varphi(n) = 0$. \\
		Soit $n \in \N$ fq. Supposons $\varphi(n)$ construite.
		\begin{equation*}
			\varphi(n+1) = \min\{ k \in \N | u_k \in I_{n+1} \wedge k > \varphi(n) \}
		\end{equation*}
		$\varphi(n+1)$ est bien définie car $\{ k \in \N | u_k \in I_{n+1} \}$ est une partie de \N non bornée (car infinie). \\
		
		\noindent Ainsi, nous avons construit $\varphi : \N \rightarrow \N$ strictement croissante. Nous pouvons extraire une sous-suite de $u$. Or $\forall n \in \N, u_{\varphi(n)} \in I_n$ donc
		\begin{equation*}
			\forall n \in \N, \quad
			\underbrace{a_n}_{ \arrowlim{n}{+\infty} \ell } \leqslant u_{\varphi(n)} \leqslant \underbrace{b_n}_{ \arrowlim{n}{+\infty} \ell }
		\end{equation*}
		Donc, d'après le théorème d'existence de limite par encadrement, $u_{\varphi(n)} \arrowlim{n}{+\infty} \ell$. \\
		Ainsi $\ell \in L_u$.
	\end{question_kholle}
	
	\begin{question_kholle}
	    [Soit $u$ une suite bornée. $u$ converge si et seulement si il existe $\ell \in \mathbb{K}$ tel que $L(u)$ est le singleton $\ell$ ]
	    {*Facultative* Caractérisation de la convergence par l'unicité d'une valeur d'adhérence pour une suite bornée.}
	    Traitons le cas réel, celui sur \C est à adapter sans peine.\\
	    Supposons que $u$ converge et posons $\lim u =\ell \in \R  $. Toutes les sous-suites de $u$ convergent vers $\ell$ donc $L(u)=\{\ell \}$. \\
	    Supposons maintenant qu'il existe un unique $\ell \in \R$ tel que $L(u) = \{ \ell \}$. Par l'absurde, supposons que $u$ ne converge pas vers $\ell$, c'est-à-dire : 
	    \[
	    \exists \varepsilon \in \R ^* _+ \ : \ \forall N \in \N, \ \exists n \in \N \ : \ n\geq N \text{ et } |u_n - \ell | > \varepsilon.
	    \]
	    Fixons un tel $\varepsilon$. \\
	    %\textbf{Etape 1} : \textit{Construction d'une sous-suite de $u$ dont les termes sont $\varepsilon$-éloignés de $\ell$.} \\
	    Posons $\varphi (0) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon \} }$, ce qui a du sens car c'est une partie non-vide de $\N$. Posons ensuite $\varphi (1) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon, \ \varphi(0) < k \} } $, ce qui a du sens pour les mêmes raisons. On construit en itérant ce procédé $\varphi (n)$ tel que : 
	    \[
	    \forall n \in \N, \ \varphi(n+1) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon, \ \varphi(n) < k \} }.
	    \]
	    De cette manière, nous venons de construire une extractrice telle que : 
	    \[
	    \forall n \in \N, \ |u_{\varphi(n)} - \ell| > \varepsilon.
	    \]
	    Par hypothèse $u$ est bornée, donc il existe $M\in \R _+$ tel que : 
	    \[
	    \forall n \in \N, \ |u_n| \leq M,
	    \]
	    donc pour tout $n$ dans $\N$, $|u_{\varphi(n)}| \leq M$, donc $(u_{\varphi(n)})_{n\in \N}$ est bornée. \\
	    Par le théorème de Bolzano-Weierstrass, il existe $\psi$ une extractrice et $\ell ' \in \R$, avec $\varphi \circ \psi$ qui est aussi une extractrice par composition d'applications strictement croissantes, donc$(u_{\varphi \circ \psi (n)})_{n\in \N}$ est une sous-suite de $u$ et $\ell ' \in L(u) = \{ \ell \}$.\\
	    Par ailleurs, pour tout $n$ dans $\N$ :
	    \[
	    \underset{\xrightarrow[n\to +\infty]{}|\ell' -\ell|}{\underbrace{|u_{\varphi \circ \psi (n)} - \ell|}} > \varepsilon,
	    \]
	    donc en passant à la limite dans l'inégalité on a pour tout $n$ dans $\N$, $|\ell ' - \ell | \geq \varepsilon > 0$, ce qui n'est pas possible car $\ell$ est la seule valeur d'adhérence possible et ici la différence n'est pas nulle.
	\end{question_kholle}

\pagebreak\section{Semaine 12}

	\begin{question_kholle}
		[Soient $a \in \K$ et $v \in \K^\N$ où \K peut être \C ou \R.
		L'ensemble des solutions de l'équation $\forall n \in \mathbb{N}, u_{n+1} = au_{n} + v_{n}$
		est la droite affine :
		\begin{equation}
		\left\{ w + \lambda \left( a^n \right) _{n \in \mathbb{N}} \mid \lambda \in \mathbb{K} \right\}
		\end{equation}
		]
		{Résolution d'une relation de récurrence linéaire d'ordre 1 à coefficients constants et avec second membre}

		Posons $w$ la suite définie par $$
		\left\{ \begin{array}{ll}
		 w_{0} = 1 \\
		\forall n \in \mathbb{N}, w_{n+1} = aw_{n} + v_{n}
		\end{array}\right.
		$$
		$w$ est "évidemment solution de particulière de l'équation"
		
		Maintenant que nous disposons d'une solution particulière, et ayant observé que l'équation est linéaire, mettons en œuvre l'artillerie classique pour exprimer l'ensemble des solutions par l'habituelle technique.
		
		
		\begin{align*}
			\forall n \in \mathbb{N}, u_{n+1} = au_{n} + v_{n} & \iff \forall n \in \mathbb{N}, u_{n+1} - au_{n} = v_{n} \\
			& \iff \forall n \in \mathbb{N}, u_{n+1} - au_{n} = w_{n+1} - aw_{n} \\
			& \iff \forall n \in \mathbb{N}, (u-w)_{n+1} = a(u-w)_{n} \\
			& \iff u-w \in \text{Vect}\left\{ \left( a^n \right) _{n \in \mathbb{N}} \right\}  \\
			& \iff \exists \lambda \in \mathbb{K} : u-w = \lambda \left( a^{n} \right) _{n \in \mathbb{N}} \\
			& \iff \exists \lambda \in \mathbb{K} : \forall n \in \mathbb{N}, u_{n} = w_{n} + \lambda a^n \\
			& \iff  u \in \left\{ \left( w_{n} + \lambda a^n \right) _{n \in \mathbb{N}} \mid \lambda \in \mathbb{K} \right\}
		\end{align*}

	\end{question_kholle}

	\begin{question_kholle}
		[Soient $(a,b) \in \C^2$.
		L'ensemble des solutions $S_H$ de l'équation d'inconnue $u \in \C^\N$
		\begin{equation}
			\forall n \in \N, u_{n+2} = a u_{n+1} + b u_n
		\end{equation}
		est le plan vectoriel $\text{Vect}\{ \left(r_1^n\right)_{n\in\N}, \left(r_2^n\right)_{n\in\N} \}$ où $r_1$ et $r_2$ sont les racines de l'équation caractéristique ($r^2 = ar + b$) quand $\Delta \neq 0$.]
		{Résolution d'une relation de récurrence linéaire homogène d'ordre 2 à coefficients constants dans \C lorsque l'équation caractéristique possède un discriminant non nul}

		Soient $(a,b) \in \C^2$ fq.

		\underline{Lemme} Soit $r \in \C$. $\left(r^n\right)_{n\in\N}$ est solution de l'équation de récurrence si et seulement si $r^2 = ar + b$.
		\begin{equation*}
			\begin{aligned}
				(r^n)_{n\in\N} \text{ est solution }
				\iff \forall n \in \N, r^{n+2} &= a r^{n+1} + b r^n \\
				\iff \forall n \in \N, r^{n} \left( r^2 - a r - b \right) &= 0 \\
				\underbrace{\iff}_{\text{ En particularisant pour } n \leftarrow 0} r^2 - a r - b &= 0 \\
				\iff r^2 &= a r + b
			\end{aligned}
		\end{equation*}

		Considérons le cas où l'équation $r^2 = ar + b$ admet deux racines distinctes ($\Delta \neq 0$) $r_1$ et $r_2$.
		D'après le lemme, $\left(r_1^n\right)_{n\in\N}$ et $\left(r_2^n\right)_{n\in\N}$ sont solutions. Par linéarité de l'équation, toute combinaison linéaire est solution de l'équation homogène.
		Donc $\text{Vect}\{ \left(r_1^n\right)_{n\in\N}, \left(r_2^n\right)_{n\in\N} \} \subset S_H$.

		Réciproquement, soit $u \in \S_H$ fq.
		Étudions le système à deux inconnues $(\lambda, \mu) \in \C^2$ :
		\begin{equation*}
			\left\{ \begin{matrix}
				\lambda r_1^0 + \mu r_2^0 = u_0 \\
				\lambda r_1^1 + \mu r_2^1 = u_1
			\end{matrix} \right.
			\iff \left\{ \begin{matrix}
				\lambda + \mu = u_0 \\
				\lambda r_1 + \mu r_2 = u_1
			\end{matrix} \right.
		\end{equation*}
		$\begin{vmatrix}
			1 & 1 \\
			r_1 & r_2
		\end{vmatrix}
		= r_2 - r_1 \neq 0$
		Donc d'après les formules de Cramer, ce système admet une unique solution.

		Considérons le prédicat $\mathcal{P}(\cdot)$ défini pour tout $n \in \N$ par :
		\begin{equation*}
			u_n = \lambda r_1^n + \mu r_2^n \text{ et } u_{n+1} = \lambda r_1^{n+1} + \mu r_2^{n+1}
		\end{equation*}
		\begin{itemize}
			\item $\mathcal{P}(0)$ est vrai par construction de $\lambda$ et $\mu$.
			\item Soit $n \in \N$ fq tq $\mathcal{P}(n)$ vrai.
			D'après $\mathcal{P}(n)$, $u_{n+1} = \lambda r_1^{n+1} + \mu r_2^{n+1}$.
			\begin{equation*}
				\begin{aligned}
					u_{n+2} &= a u_{n+1} + b u_n \\
					&= a \left( \lambda r_1^{n+1} + \mu r_2^{n+1} \right) + b \left( \lambda r_1^n + \mu r_2^n  \right) \quad \text{ d'après } \mathcal{P}(n) \\
					&= \lambda r_1^n \left(ar_1 + b\right) + \mu r_2^n \left(ar_2 + b\right) \\
					&= \lambda r_1^{n+2} + \mu r_2^{n+2} \quad \text{ car } r_1 \text{ et } r_2 \text{ sont racine de } r^2 = ar + b
				\end{aligned}
			\end{equation*}
		\end{itemize}
		Ainsi $S_H \subset \text{Vect}\{ \left(r_1^n\right)_{n\in\N}, \left(r_2^n\right)_{n\in\N} \}$.

		Par double inclusion, $S_H = \text{Vect}\{ \left(r_1^n\right)_{n\in\N}, \left(r_2^n\right)_{n\in\N} \}$.
	\end{question_kholle}

	\begin{question_kholle}
		[Soit $u$ une suite bornée. $u$ converge si et seulement si il existe $\ell \in \mathbb{K}$ tel que $L(u)$ est le singleton $\ell$ ]
		{Caractérisation de la convergence par l'unicité d'une valeur d'adhérence pour une suite bornée.}

		Traitons le cas réel, celui sur \C est à adapter sans peine.\\
		Supposons que $u$ converge et posons $\lim u =\ell \in \R  $. Toutes les sous-suites de $u$ convergent vers $\ell$ donc $L(u)=\{\ell \}$. \\
		Supposons maintenant qu'il existe un unique $\ell \in \R$ tel que $L(u) = \{ \ell \}$. Par l'absurde, supposons que $u$ ne converge pas vers $\ell$, c'est-à-dire :
		\[
			\exists \varepsilon \in \R ^* _+ \ : \ \forall N \in \N, \ \exists n \in \N \ : \ n\geq N \text{ et } |u_n - \ell | > \varepsilon.
		\]
		Fixons un tel $\varepsilon$. \\
		%\textbf{Etape 1} : \textit{Construction d'une sous-suite de $u$ dont les termes sont $\varepsilon$-éloignés de $\ell$.} \\
		Posons $\varphi (0) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon \} }$, ce qui a du sens car c'est une partie non-vide de $\N$. Posons ensuite $\varphi (1) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon, \ \varphi(0) < k \} } $, ce qui a du sens pour les mêmes raisons. On construit en itérant ce procédé $\varphi (n)$ tel que :
		\[
			\forall n \in \N, \ \varphi(n+1) = \min{ \{ k\in \N \ | \ |u_k - \ell| > \varepsilon, \ \varphi(n) < k \} }.
		\]
		De cette manière, nous venons de construire une extractrice telle que :
		\[
			\forall n \in \N, \ |u_{\varphi(n)} - \ell| > \varepsilon.
		\]
		Par hypothèse $u$ est bornée, donc il existe $M\in \R _+$ tel que :
		\[
			\forall n \in \N, \ |u_n| \leq M,
		\]
		donc pour tout $n$ dans $\N$, $|u_{\varphi(n)}| \leq M$, donc $(u_{\varphi(n)})_{n\in \N}$ est bornée. \\
		Par le théorème de Bolzano-Weierstrass, il existe $\psi$ une extractrice et $\ell ' \in \R$, avec $\varphi \circ \psi$ qui est aussi une extractrice par composition d'applications strictement croissantes, donc$(u_{\varphi \circ \psi (n)})_{n\in \N}$ est une sous-suite de $u$ et $\ell ' \in L(u) = \{ \ell \}$.\\
		Par ailleurs, pour tout $n$ dans $\N$ :
		\[
			\underset{\xrightarrow[n\to +\infty]{}|\ell' -\ell|}{\underbrace{|u_{\varphi \circ \psi (n)} - \ell|}} > \varepsilon,
		\]
		donc en passant à la limite dans l'inégalité on a pour tout $n$ dans $\N$, $|\ell ' - \ell | \geq \varepsilon > 0$, ce qui n'est pas possible car $\ell$ est la seule valeur d'adhérence possible et ici la différence n'est pas nulle.
	\end{question_kholle}

	\begin{question_kholle}
		[Soient $f : \mathcal{D} \rightarrow \R$ et $I \subset \mathcal{D}_f$ une intervalle $f$-stable. \\
		Soit $\left(u_n\right)_{n\in\N} \in \R^\N$ la suite récurrente associée à la fonction $f$ c'est-à-dire $\forall n \in \N, u_{n+1} = f(u_n)$.
		\begin{itemize}
			\item Si $f$ est croissante sur $I$.
			\subitem Si $u_1 \geqslant u_0$ alors $u$ est croissante.
			\subitem Si $u_1 \leqslant u_0$ alors $u$ est décroissante.
			\item Si $f$ est décroissante sur $I$.
			\subitem Les sous-suites $\left(u_{2n}\right))_{n\in\N}$ et $\left(u_{2n+1}\right))_{n\in\N}$ sont monotone et ont une monotonie opposée (utiliser les premiers termes pour trouver leur monotonie respectives).
		\end{itemize}]
		{Monotonie de $u$ et des sous-suites des termes pairs et impairs de la suite$u_{n+1} = f(u_n)$ selon la monotonie de $f$}

		Soient de tels $f, I$ et $u$.
		\begin{itemize}
			\item Supposons que $f$ est croissante sur $I$. \\
			Supposons $u_1 \geqslant u_0$. Considérons le prédicat $\mathcal{P}(\cdot)$ défini pour tout $n \in \N$ par
			\begin{equation*}
				\mathcal{P}(n) : " u_{n+1} \geqslant u_n "
			\end{equation*}
			\subitem Par hypothèse, $u_1 \geqslant u_0$ donc $\mathcal{P}(0)$ est vrai.
			\subitem Soit $n \in \N$ fq tq $\mathcal{P}(n)$ vrai. \\
			\begin{equation*}
				u_{n+1} \geqslant u_n
				\underbrace{\implies}_{f \text{ est croissante sur } I} f(u_{n+1}) \geqslant f(u_n)
				\implies u_{n+2} \geqslant u_{n+1}
			\end{equation*}
			Donc $\mathcal{P}(n+1)$ est vrai. \\
			Si $u_1 \leqslant u_0$, il suffit de changer $\geqslant$ par $\leqslant$ dans la récurrence ci-dessus.
			\item Supposons que $f$ est décroissante sur $I$. \\
			Donc $\forall n \in \N, u_{2(n+1)} = f \circ f(u_{2n}) \text{ et } u_{2(n+1)+1} = f \circ f(u_{2n+1})$. Or $f \circ f$ est croissante, donc $\left(u_{2n}\right)_{n\in\N}$ et $\left(u_{2n+1}\right)_{n\in\N}$ sont monotones. \\
			Supposons que $\left(u_{2n}\right)_{n\in\N}$ est croissante.
			Soit $n \in \N$ fq. Alors
			\begin{equation*}
				u_{2n} \leqslant u_{2(n+1)}
				\underbrace{\implies}_{f \text{ est décroissante sur } I} f(u_{2n}) \geqslant f(u_{2(n+1)})
				\implies u_{2n+1} \geqslant u_{2(n+1)+1}
			\end{equation*}
			Donc $\left(u_{2n+1}\right)_{n\in\N}$ est décroissante. \\
			De même, si $\left(u_{2n}\right)_{n\in\N}$ est décroissante alors $\left(u_{2n+1}\right)_{n\in\N}$ est croissante.
		\end{itemize}
	\end{question_kholle}

	\begin{question_kholle}
	    [Montrons que : $ \overset{\circ}{\Q} = \emptyset $]
	    {L'intérieur de l'ensemble des rationnels est vide.}
	    Par l'absurde, supposons que $\Q$ possède au moins un point intérieur. \\ Fixons $r_0 \in \overset{\circ}{\Q}$. Par définition d'un point intérieur, il existe $\varepsilon \in \R _+ ^* $ : $]r_0 - \varepsilon , \ r_0 + \varepsilon[ \subset \Q$. Or, par densité des irrationnels dans $\R$, il existe $\alpha \in \R \backslash \Q$ : $r_0 - \varepsilon < \alpha < r_0 + \varepsilon$. On en déduit que $\alpha \in ]r_0 - \varepsilon , \ r_0 + \varepsilon[$, or $]r_0 - \varepsilon , \ r_0 + \varepsilon[ \subset \Q$ donc $\alpha \in \Q$ ce qui contredit le choix de $\alpha \in \R \backslash \Q$. Ainsi, $\overset{\circ}{\Q} = \emptyset$
	\end{question_kholle}

	\begin{question_kholle}
	    [Soient $f,g \ : \ \mathcal{D} \to \R$, $\ell \in \R$ et $a \in \overline{\mathcal{D}}$ tels que $|f(x) - \ell| \leq g(x)$ au voisinage de $a$ et $g$ tend vers $0$ en $a$. Alors $f$ tend vers $\ell$ en $a$.]
	    {Théorème sans nom version continue au voisinage de $a$}

	    On traite le cas $a\in \R$. Par définition de $|f(x) - \ell| \leq g(x)$ au voisinage de $a$,
	    \[
	    	\exists \eta \in \R _+ ^* \ : \ \forall x \in \mathcal{D}, \ |x-a| \leq \eta \ \implies \ |f(x) - \ell| \leq g(x).
	    \]
	    Fixons un tel $\eta$. \\
	    Soit $\omega \in \R_+ ^*$. Appliquons la définition de $\lim_{x \to a} g(x) = 0$ pour $\varepsilon \gets \omega$ :
	    \[
	   		\exists \eta' \in \R_+ ^* \ : \ \forall x \in \mathcal{D}, \ |x-a| \leq \eta' \ \implies \ |g(x)| \leq \omega.
	    \]
	    Fixons un tel $\eta'$. \\
	    Posons $\Omega = \min{ \{\eta,  \eta' \} }$. \\
	    Soit $x\in \mathcal{D}$ tel que $|x-a| \leq \Omega$.
	    \[
		    |f(x) - \ell | \leq g(x) \leq \omega,
	    \]
	    car la définition de $\Omega$ permet de remplir les conditions des deux propriétés.
	\end{question_kholle}
\pagebreak\section{Semaine 13}
	
\begin{question_kholle}
	[Soient $g$ une fonction définie sur $\mathcal{D}_g \subset \R$ et $f$ une fonction définie sur $\mathcal{D}_f \subset \R$ telle que $f(\mathcal{D}_f) \subset \mathcal{D}_g$.
		Si $\left. \begin{array}{cc}
		g \text{ admet une limite } \ell \in \overline{\R} \text{ en } b \in \overline{\mathcal{D}_g} \\
		f \text{ admet } b \text{ comme limite en } a \in \overline{\mathcal{D}_f}
		\end{array} \right\}$
	alors $g \circ f$ admet $\ell$ comme limite en $a$.]
	{Théorème de composition des limites}
			
	Traitons le cas où $\ell \in \R$, $a \in \R$ et $b \in \R$. \\
	Soit $\varepsilon \in \R_+^*$ fq. \\
	Appliquons la définition de $g(y) \arrowlim{y}{b} \ell$ pour cet $\varepsilon$ :
	\begin{equation*}
		\exists \eta_g \in \R_+^* : \forall y \in \mathcal{D}_g, | y - b | \leqslant \eta_g \implies | g(y) - \ell | \leqslant \varepsilon
	\end{equation*}
	Appliquons la définition de $f(x) \arrowlim{x}{a} b$ pour cet $\eta_g$ :
	\begin{equation*}
		\exists \eta_f \in \R_+^* : \forall x \in \mathcal{D}_f, | x - a | \leqslant \eta_f \implies | f(x) - b | \leqslant \eta_g
	\end{equation*}
	Posons $\eta = \eta_f$.
			
	Soit $x \in \mathcal{D}_{g \circ f}$ fq tq $ | x - a | \leqslant \eta $. Or $f(\mathcal{D}_f) \subset \mathcal{D}_g$ donc $\mathcal{D}_{g \circ f} = \mathcal{D}_f$. \\
	Ainsi, $x \in \mathcal{D}_f$ et $ | x - a | \leqslant \eta_f $ d'où $ | f(x) - b | \leqslant \eta_g $ d'où $ | g(f(x)) - \ell | \leqslant \varepsilon $. Donc
	\begin{equation*}
		g \circ f \arrowlim{x}{a} \ell
	\end{equation*}
\end{question_kholle}
	
\begin{question_kholle}
	[{ Soit une fonction continue $f : [a;b] \rightarrow \R$ avec $(a,b) \in \R^2$ et $a < b$. \\
			Si $f(a)f(b) \leqslant 0$ alors $\exists c \in [a;b] : f(c) = 0$. \\
			On rencontre aussi : \textit{Si $\mathit{f(a)f(b) < 0}$ alors $\mathit{\exists c \in ]a;b[ : f(c) = 0}$.} }]
				{Théorème des valeurs intermédiaires}
						
				La démonstration repose sur la technique de la dichotomie.
						
				\begin{figure}[!h]
%					\centering
					\tikzmath{ \labTVI = 12; } % la longueur du segment [a;b] dans la démonstration du TVI
					\begin{tikzpicture}
						\draw (0,0) node[anchor=north] {a} -- (\labTVI,0) node[anchor=north] {b};
						\foreach \x in {0,...,\labTVI} {
							\draw (\x,0.1) -- (\x,-0.1);
						};
						\draw[red] (0,0) to[out angle=80, in angle=240, curve through={(\labTVI/5,2) (\labTVI/3,-1) (\labTVI*3/5,0.5)}] (\labTVI,0);
								
						\draw[green] (\labTVI/2,0.1) -- (\labTVI/2,-0.1);
						\draw (\labTVI/2,0) node[green, anchor=north] {$b_1$};
						\draw[green] (\labTVI/4,0.1) -- (\labTVI/4,-0.1);
						\draw (\labTVI/4,0) node[green, anchor=north] {$a_2$};
						\draw[green] (\labTVI*3/8,0.1) -- (\labTVI*3/8,-0.1);
						\draw (\labTVI*3/8,0) node[green, anchor=north] {$b_3$};
						\draw[green] (\labTVI*5/16,0.1) -- (\labTVI*5/16,-0.1);
						\draw (\labTVI*5/16,0) node[green, anchor=north] {$b_4$};
					\end{tikzpicture}
				\end{figure}
					
				\noindent Soient $a,b,f$ de tels objets. Procédons à la construction des suites $(a_n)_{n\in\N}, (b_n)_{n\in\N}, (c_n)_{n\in\N}$.
				
				Posons $a_0 = a$, $b_0 = b$ et $c_0 = \frac{a+b}{2}$ (le milieu du segment $[a;b]$). Nous avons, par hypothèse $f(a_0)f(b_0) \leqslant 0$.
				
				Soit $n \in \N$ fq. Supposons les trois suites construites au rang $n$ telles que $f(a_n)f(b_n) \leqslant 0$ et $c_n = \frac{a_n+b_n}{2}$ (milieu de $[a_n;b_n]$).
				\begin{itemize}
					\item Si $f(a_n)f(b_n) \leqslant 0$, posons $\left| \begin{array}{lcl}
					      a_{n+1} &=& a_n \\
					      b_{n+1} &=& c_n \\
					      c_{n+1} &=& \frac{a_{n+1}+b_{n+1}}{2}
					\end{array} \right.$
					\item Sinon $f(a_n)f(b_n) > 0$. Or $f(a_n)f(b_n) \leqslant 0$, donc $f(a_n)^2 f(b_n) f(c_n) \leqslant 0$. Donc $f(b_n)f(c_n) \leqslant 0$. Posons $\left| \begin{array}{lcl}
					      a_{n+1} &=& c_n \\
					      b_{n+1} &=& b_n \\
					      c_{n+1} &=& \frac{a_{n+1}+b_{n+1}}{2}
					\end{array} \right.$
				\end{itemize}
				Ainsi, nous avons bien construits $a_{n+1}, b_{n+1}, c_{n+1}$ telles que $f(a_{n+1})f(b_{n+1}) \leqslant 0$ et ${ c_{n+1} = \frac{a_{n+1}+b_{n+1}}{2} }$ (milieu de $[a_{n+1};b_{n+1}]$).
						
				Par récurrence immédiate, $(a_n)_{n\in\N}$ est croissante, $(b_n)_{n\in\N}$ est décroissante et ${ \forall n \in \N, b_n - a_n = \frac{b-a}{2^n} }$ d'où $b_n - a_n \arrowlim{n}{+\infty} 0$.
				Donc les suites $a$ et $b$ sont adjacentes.
				D'après le théorème des suites adjacentes, elles convergent vers la même limite. Notons la $c$.
				
				D'après le bonus de ce même théorème, $\forall n \in \N, a_n \leqslant c \leqslant b_n$ donc pour $n = 0$, $a \leqslant c \leqslant b$. Ainsi,
				\begin{equation*}
					c \in [a;b]
				\end{equation*}
						
				Par ailleurs, $\forall n \in \N, f(a_n)f(b_n) \leqslant 0$. Par continuité de $f$ sur $[a;b]$ donc en $c$, $f(a_n) \arrowlim{n}{+\infty} f(c)$ et $f(b_n) \arrowlim{n}{+\infty} f(c)$. Par passage à limite dans l'inégalité,
				\begin{equation*}
					f(c) \times f(c) \leqslant 0
				\end{equation*}
				Or $f(c)^2 \geqslant 0$, d'où $f(c)^2 = 0$. Ainsi,
				\begin{equation*}
					f(c) = 0
				\end{equation*}
				Donc $c$ est un point fixe.
						
				\end{question_kholle}
				 
				\begin{question_kholle}[{L'image d'un segment par une fonction continue sur ce segment est un segment : soient $(a, b) \in \mathbb{R}^2$ tels que $a < b$ et $f: [a, b] \to \mathbb{R}$. Si $f \in \mathcal{C}^0([a, b], \mathbb{R})$ alors $\exists (x_{1}, x_{2}) \in \mathbb{R}^2 : f([a, b]) = [f(x_{1}), f(x_{2})]$}]{Théorème de Weierstraß}
                    \begin{itemize}
    
					\item \emph{Étape 1} Montrons que $f([a, b])$ est majoré.
					     
					Par l'absurde, supposons que $f([a, b])$ n'est pas majoré
					     
					Alors \begin{equation}\label{eq:1}
					         \forall A \in \mathbb{R}, \exists x \in [a, b] : f(x) > A
					\end{equation}
					
					Soit $n \in \mathbb{N}$ fq.
					Appliquons (\ref{eq:1}) pour $A \leftarrow n$:
					$\exists x \in [a, b] : f(x) > n$, et fixons un tel $x$ que l'on note $x_{n}$
					Nous venons de créer la suite $(x_{n})_{n \in \mathbb{N}} \in [a, b]^{\mathbb{N}}$ qui vérifie:
					
					
					$$
					\left. 
					\begin{array}{ll}
						\forall n \in \mathbb{N}, f(x_{n}) \geqslant n \\
						\lim_{ n \to \infty } n =  +\infty         
					\end{array}
					\right\} \underbrace{ \implies }_{ \text{théorème de divergence par minoration} } f(x_{n}) \xrightarrow[n \to +\infty]{} + \infty
					$$
					
					
					$(x_{n})_{n \in \mathbb{N}}$ est bornée (à valeurs dans $[a, b]$) donc, selon le théorème de Bolzanno-Weierstraß:
					$$
					\exists \ell \in \mathbb{R} : \exists \varphi : \mathbb{N} \to \mathbb{N} : \text{strict. croissante tel que } (x_{\varphi(n)})_{n \in \mathbb{N}} \text{ tend vers } \ell
					$$
					Donc, en passant à la limite : $\forall n \in \mathbb{N}, a \leqslant x_{\varphi(n)} \leqslant b \implies a \leqslant \ell \leqslant b \implies \ell \in [a, b]$
					
					Par continuité de $f$ sur $[a, b]$, donc en $\ell$, $(f(x_{\varphi(n)}))_{n \in \mathbb{N}}$ converge vers $f(\ell)$.
					
					Or $$
					\left\{ \begin{array}{ll}
					(f(x_{\varphi(n)}))_{n \in \mathbb{N}} \text{ est une sous suite de } (f(x_{n}))_{n \in \mathbb{N}} \\
					f(x_{n}) \xrightarrow[n \to + \infty]{} + \infty
					\end{array}\right.$$
					
					donc $(f(x_{\varphi(n)}))_{n \in \mathbb{N}}$, tend vers $+ \infty$, ce qui est absurde, donc $f$ est majorée.
					
					On fait de même pour la minoration.
					
					\item  \emph{Étape 2:} Montrons que $f([a, b])$ admet un pge et un ppe.
					
					Montrons donc que $f([a, b])$ admet une borne sup, qui, puisque c'est une valeur atteinte, deviendra un max.
					
					$$
					f([a, b]) \text{ est } \left\{ \begin{array}{ll}
					\text{ une partie de } \mathbb{R} \\
					\text{ non vide car contient } f(a) \\
					\text{majorée d'après l'étape 1}
					\end{array}\right.
					$$
					
					$f([a, b])$ admet donc une borne supérieure $\sigma$.
					
					Appliquons la caractérisation séquentielle de la borne supérieure:
					$$
					\exists (y_{n})_{n \in \mathbb{N}}, \in f([a, b])^{\mathbb{N}} : (y_{n}) \text{ converge vers } \sigma
					$$
					$$
					\forall n \in \mathbb{N}, y_{n} \in f([a, b]) \implies \exists x_{n} \in [a, b] : f(x_{n} ) = y_{n}
					$$
					Fixons un tel $x_{n}$ pour tout $y_{n}$.
					On a donc construit $(x_{n})_{n \in \mathbb{N}} \in [a, b]^{\mathbb{N}} : f(x_{n}) \xrightarrow[n \to +\infty]{} \sigma$
					
					De plus, $(x_{n})$ est bornée (à valeurs dans $[a, b]$) donc, selon le théorème de Bolzanno-Weierstraß:
					$$
					\exists \ell \in \mathbb{R} : \exists \varphi : \mathbb{N} \to \mathbb{N} : \text{strict. croissante tel que } (x_{\varphi(n)})_{n \in \mathbb{N}} \text{ tend vers } \ell
					$$
					Donc, en passant à la limite : $\forall n \in \mathbb{N}, a \leqslant x_{\varphi(n)} \leqslant b \implies a \leqslant \ell \leqslant b \implies \ell \in [a, b]$

     
					Par continuité de $f$ sur $[a, b]$, donc en $\ell$, $(f(x_{\varphi(n)}))_{n \in \mathbb{N}}$ converge vers $f(\ell)$.
					
					Or,
					$$
					\left\{ \begin{array}{ll}
					(f(x_{\varphi(n)}))_{n \in \mathbb{N}} \text{ est une sous suite de } (f(x_{n}))_{n \in \mathbb{N}} \\
					f(x_{n}) \xrightarrow[n \to + \infty]{} \sigma
					\end{array}\right.$$
					
					Par unicité de la limite, $\sigma = f(\ell)$.
					
					On montre de même qu'il existe $\ell' \in [a, b]: f(\ell') = \inf f([a, b])$
					
					Ainsi, $f(\ell) = \max f([a, b])$ et $f(\ell') = \min f([a, b])$


     
					\item \emph{Étape 3:}
					Montrons que $f([a, b]) = [f(\ell'), f(\ell)]$.
					
					Par la construction précédente, $\forall y \in f([a, b]), y \in [f(\ell'), f(\ell)]$.
					
					Ainsi, $f([a, b]) \subset [f(\ell'), f(\ell)]$.
					
					Réciproquement, l'image par la fonction continue $f$ du segment $[a, b]$ qui est un intervalle est un intervalle:
					
					$$
					\left. 
					\begin{array}{ll}
						f([a,b]) \text{ est un intevalle} \\
						f(\ell) \in f([a, b])             \\
						f(\ell') \in f([a, b])            
					\end{array}
					\right\} 
					\implies
					[f(\ell'), f(\ell)] \subset f([a,b])
					$$
					
					D'où $[f(\ell'), f(\ell)] = f([a,b])$
					    
                    \end{itemize}
				\end{question_kholle}
\pagebreak\section{Semaine 14}

	\begin{question_kholle}
	    [Soit $f \left| \begin{matrix}
	    	\R_+^* \rightarrow \R \\
	    	x \mapsto \frac{\ln x}{x}
	    \end{matrix} \right. $. \\
	    Exprimer $f^{(n)}$ pour tout $n \in \N$.]
	    {Expression de dérivées successives}
	    Soit $x\in \mathcal{D}_f$. \\
	    Considérons le prédicat $P(\cdot)$ définit pour $n\in \N$ par :
	    $$ P(n) \ : \ \text{\textquotedblleft} \ f^{(n)}(x) = \frac{(-1)^n n!}{x^{n+1}}\left[ \ln (x) - \sum_{k=1}^n \frac{1}{k} \right] \ " $$
	    Initialisation : \\
	    Pour $n = 0$, $$f^{(0)}(x) = f(x) = \frac{\ln (x)}{x} = \frac{(-1)^0 0!}{x^{0+1}}\left[ \ln (x) - \sum_{k=1}^0 \frac{1}{k} \right],$$ donc $P(0)$ est vrai. \\
	    Hérédité :
	    \\
	    Soit $n\in \N$ tel que $P(n)$. On a,
	    $$f^{(n+1)}(x) = (f^{(n)}(x))' = \left( \frac{(-1)^n n!}{x^{n+1}}\left[ \ln (x) - \sum_{k=1}^n \frac{1}{k} \right] \right)'$$
	    par véracité de $P(n)$. Ainsi,
		$$\begin{array}{rcl}
		f^{(n+1)}(x) & = & \frac{(-1)^nn!x^n - (-1)^n(n+1)!x^n\left[ \ln (x) - \sum_{k=1}^n \frac{1}{k} \right]}{x^{2(n+1)}} \\ [1ex]
		 & = & \frac{(-1)^{n+1}(n+1)!\ln (x) - (-1)^{n+1}(n+1)!\sum_{k=1}^{n+1} \frac{1}{k} }{x^{n+2}} \\ [1ex]
		 & = & \frac{(-1)^{n+1} (n+1)!}{x^{n+2}}\left[ \ln (x) - \sum_{k=1}^{n+1} \frac{1}{k} \right]
		\end{array}$$
	    c'est l'expression recherchée, donc $P(n+1)$ est vrai. \\
	    Par théorème de récurrence sur $\N$, $P(n)$ est vraie pour tout $n\in \N$.
	\end{question_kholle}

	\begin{question_kholle}
		[Soit $f : I \rightarrow f(I) \subset \R$ continue, strictement monotone sur $I$ et dérivable en $a \in I$.
		Si $f'(a) \neq 0$ alors $f$ est bijective, $f^{-1}$ est dérivable en $f(a)$ et $f^{-1}(f(a)) = \frac{1}{f'(a)}$.]
		{Dérivé d'une bijection réciproque}
		Soient de tels objets. \\
		Rappelons le lemme inattendu. Soit $g : J \rightarrow \R$ monotone (où $J$ est un intervalle). Nous avons l'équivalence suivante :
		\begin{equation*}
			f(J) \text{ est un intervalle } \iff f \text{ est continue sur } J
		\end{equation*}
		Par définition, $f$ est surjective. Comme elle est strictement monotone, $f$ est injective. Ainsi $f$ est bijective. \\
		D'après le lemme inattendu, $f(I)$ est un intervalle. Nous avons $f^{-1} : f(I) \rightarrow I$ avec $f(I)$ et $I$ des intervalles donc $f^{-1}$ est continue sur $f(I)$. \\
		Calculons la limite du taux d'accroissement de $f^{-1}$ en $f(a)$ :
		\begin{equation*}
			\forall x \in f(I), \tau_{f^{-1},f(a)} = \frac{f^{-1}(x) - f^{-1}(f(a))}{x - f(a)}
		\end{equation*}
		Posons $u = f^{-1}(x)$. D'où :
		\begin{equation*}
			\tau_{f^{-1},f(a)} = \frac{u - a}{f(u) - f(a)}
		\end{equation*}
		De plus, par continuité de $f^{-1}$, $u \arrowlim{x}{f(a)} f^{-1}(f(a)) = a$.
		Par dérivabilité en a et par continuité de $x \mapsto x^{-1}$ en $f(a) \neq 0$, $\frac{u - a}{f(u) - f(a)} \arrowlim{u}{a} \frac{1}{f('(a)}$. \\
		Ainsi, $f^{-1}$ est dérivable en $f(a)$ et $f^{-1}(f(a)) = \frac{1}{f'(a)}$.
	\end{question_kholle}

	\begin{question_kholle}
		[Soit $f : I \rightarrow \R$. Si $f$ admet un extremum local en $a \in \overset{\circ}{I}$ et si $f$ est dérivable en $a$ alors $f'(a) = 0$
		{\begin{figure}[!h]
				\centering
				\tikzmath{ integer \m; real \fm; \m = 3; \fm = 0.8; }
				\begin{tikzpicture}
					\draw[-stealth] (0,0) -- (6,0) node[anchor=west] {$x$};
					\draw[-stealth] (0,0) -- (0,3) node[anchor=south] {$y$};
					
					\draw[red] plot [smooth] coordinates {(0,2.5) (\m,\fm) (6,1.7)};
					\draw[blue, dashed] (\m,\fm) -- (\m,0) node[anchor=north] {minimum local};
					
					\draw[stealth-stealth, teal] (\m-1,\fm) -- (\m+1,\fm);
					\draw (\m,\fm) node[anchor=north east, teal] {$m$} node[anchor=south, teal] {$f'(m)=0$};
				\end{tikzpicture}
		\end{figure}}]
		{Dérivée d'un extremum local intérieur au domaine de définition}
		Soient de tels objets. \\
		$a \in \overset{\circ}{I} \implies \exists \eta_1 \in \R_+^* : [a-\eta_1;a+\eta_1] \subset I$ Fixons un tel $\eta_1$. \\
		Calculons le taux d'accroissement en $a$.
		\begin{equation*}
			\forall x \in [a-\eta_1;a+\eta_1], \tau_{f,a}(x) = \frac{f(x) - f(a)}{x - a}`
		\end{equation*}
		Or $f$ est dérivable en $a$ donc $\tau_{f,a}(x)$ admet une limite lorsque $x \rightarrow a$.
		Traitons le cas où $a$ est maximum local. Par définition :
		\begin{equation*}
			\exists \eta_2 \in \R_+^* : \forall x \in [a-\eta_2;a+\eta_2], f(x) \leqslant f(a)
		\end{equation*}
		Fixons un tel $\eta_2$. Soit $x \in [a-\eta_2;a+\eta_2] \setminus \{a\}$ fq. \\
		Alors $f(x) - f(a) \leqslant 0$. \\
		Si $x > a$, $x - a > 0$. Alors $\frac{f(x) - f(a)}{x - a} \leqslant 0$. Donc $\textlim{x}{a} \tau_{f,a}(x) \leqslant 0$. \\
		Sinon $x < a$, $x - a < 0$. Alors $\frac{f(x) - f(a)}{x - a} \geqslant 0$. Donc $\textlim{x}{a} \tau_{f,a}(x) \geqslant 0$. \\
		Ainsi $0 \leqslant \textlim{x}{a} \tau_{f,a}(x) \leqslant 0$. Donc $f'a) = 0$.
	\end{question_kholle}

	\begin{question_kholle}
	    [Soient $(a,b)\in \R ^2$ tels que $a<b$. Soit $I$ le segment $a,b$.
	    \\
	    Soit $f \ : \ I \ \to \ \R $ continue sur ledit segment et dérivable sur l'ouvert associé.\\
	    {\begin{enumerate}[label=($\roman*$)]
	    	\item Théroème de Rolle : \\
	    	Si $f(a) = f(b)$, alors $\exists \ c \in \overset{\circ}{I}$ tel que $f'(c) =0$
	    	\begin{figure}[!h]
	    		\centering
	    		\tikzmath{ integer \a \b \f \c \fc; \a = 1; \b = 9; \f = 2; \c = \a + 3; \fc = \f + 2; }
	    		\begin{tikzpicture}
	    			\draw[-stealth] (0,0) -- (10,0) node[anchor=west] {$x$};
	    			\draw[-stealth] (0,0) -- (0,5) node[anchor=south] {$y$};

	    			\coordinate (A) at (\a,\f);
	    			\coordinate (B) at (\b,\f);
	    			\coordinate (C) at (\c,\fc);

	    			%\draw[red] (A) to[out angle=80, in angle=240, curve through={(C) (6,1.5)}] (B);
	    			\draw [red] plot [smooth] coordinates {(A) (C) (6,1.5) (B)};
	    			\draw[blue, thick] (A) -- (B);
	    			\draw[blue, dashed] (A) -- (\a,0) node[anchor=north] {$a$};
	    			\draw[blue, dashed] (B) -- (\b,0) node[anchor=north] {$b$};
	    			\draw[blue, dashed] (A) -- (0,\f) node[anchor=east] {$f(a)=f(b)$};

	    			\draw[stealth-stealth, teal] (\c-2,\fc) -- (\c+2,\fc);
	    			\draw (C) node[anchor=north, teal] {$c$} node[anchor=south, teal] {$f'(c)=0$};
	    		\end{tikzpicture}
    			\caption{Théorème de Rolle}
	    	\end{figure}

	    	\item Formule des accroissements finis : \\
	    	$\exists \ c \in \overset{\circ}{I} \ : \ f'(c) = \frac{f(b)-f(a)}{b-a}.$
	    	\begin{figure}[!h]
	    		\centering
	    		\tikzmath{integer \a \fa \b \fb \c \fc; \a = 1; \fa = 1; let \b = 9; \fb = 5; \c = \a + 5; \fc = \fa + 1; }
	    		\begin{tikzpicture}
	    			\draw[-stealth] (0,0) -- (10,0) node[anchor=west] {$x$};
	    			\draw[-stealth] (0,0) -- (0,6) node[anchor=south] {$y$};

	    			\coordinate (A) at (\a,\fa);
	    			\coordinate (B) at (\b,\fb);
	    			\coordinate (C) at (\c,\fc);

	    			%\draw[red] (A) to[out angle=80, in angle=240, curve through={(C) (6,1.5)}] (B);
	    			\draw [red] plot [smooth] coordinates {(A) (3,4) (C) (7,4.5) (B)};
	    			\draw[blue, thick] (A) -- (B);
	    			\draw[blue, dashed] (A) -- (\a,0) node[anchor=north] {$a$};
	    			\draw[blue, dashed] (A) -- (0,\fa) node[anchor=east] {$f(a)$};
	    			\draw[blue, dashed] (B) -- (\b,0) node[anchor=north] {$b$};
	    			\draw[blue, dashed] (B) -- (0,\fb) node[anchor=east] {$f(b)$};

	    			\draw[stealth-stealth, teal] (\c-2,\fc-1) -- (\c+2,\fc+1);
	    			\draw (C) node[anchor=south, teal] {$c$} node[anchor=north west, teal] {$f'(c)=\frac{f(b)-f(a)}{b-a}$};
	    		\end{tikzpicture}
    			\caption{Formule des accroissements finis}
	    	\end{figure}
	    \end{enumerate}}
	    ]
	    {Théorème de Rolle et formule des accroissements finis}
	    Soient de tels objets. \\
	    Prouvons $(i)$, donc supposons $f(a) = f(b)$. \\
	    $f$ est continue sur $I$ donc par le théorème de Weierstraß, elle est bornée et atteint ses bornes sur ce segment :
	    \\
	    $$\exists \ (x_m, x_M)\in I^2 \ : \ (f(x_m) = \min f(I)) \wedge (f(x_M) = \max f(I))$$
	    donc, si $(x_m, x_M)\in \{a,b\}^2$, alors,
	    $$\forall x \in I, \ f(a)=f(x_m) \leq f(x) \leq f(x_M)=f(a)$$
	    donc $\forall x \in I, f(x) = f(a)$ c'est-à-dire que $f$ est constante et donc tous les points intermédiaires à $I$ sont des $c$ valides.\\
	    Sinon, $(x_m \notin \{a,b\}) \vee (x_M \notin \{a,b\}) $, quitte à prendre l'autre valeur, supposons que $x_M \notin \{a,b\}$, ainsi, $x_M \in \overset{\circ}{I}$ et $f(x_M)$ est un maximum global donc, $f$ étant dérivable sur $\overset{\circ}{I}$ elle est dérivable en $x_M$ donc $f'(x_M)=0$, on pose $c = x_M$, ce qui conclut. \\ \\
	    Prouvons $(ii)$.\\
	    Posons $d \ :\ I \ \to \ \R, \ x \ \mapsto \ f(x) - \left( \frac{f(b)-f(a)}{b-a}(x-a) +f(a) \right) $. $d$ est continue sur $I$ et dérivable sur $\overset{\circ}{I}$ comme combinaison linéaire de telles fonctions. On a $d(a) = 0$ et $d(b) = 0$ donc $d(a) = 0 = d(b)$. On peut alors appliquer le Théorème de Rolle pour $f \gets d, a \gets a $ et $ b \gets b$ : il existe $c\in \overset{\circ}{I}$ tel que $d'(c) = 0$, c'est le résultat.
	\end{question_kholle}

	\begin{question_kholle}
	    [Soit $f\in \mathcal{C}^0(I, \R) \cap \mathcal{D}^1(\overset{\circ}{I}, \R)$ et $x_0 \in I$, posons {$X_- = ]-\infty;x_0]$} la demi-droite fermée en $x_0$ et vers $-\infty$, de même {$X_+ = [x_0;+\infty[$} la demi-droite fermée en $x_0$ et vers $+ \infty$. \\ \\
	    {\begin{enumerate}[label=$(\roman*)$]
	    	\item \begin{itemize}[label=$\star$, leftmargin=0.4cm]
	    		\item Si $\exists \ m \in \R \ : \ \forall x \in \overset{\circ}{I}, \ m\leq f'(x)$, alors, $$\forall x \in I \cap X_+, \ f(x_0) + m(x-x_0) \leq f(x)$$ et $$\forall x \in I \cap X_-, \ f(x) \leq f(x_0) + m(x-x_0)$$
	    		\item Si $\exists \ M \in \R \ : \ \forall x \in \overset{\circ}{I}, \ f'(x) \leq M $, alors, $$\forall x \in I \cap X_+, \ f(x) \leq f(x_0) + M(x-x_0)$$ et $$\forall x \in I \cap X_-, \ f(x_0) + M(x-x_0) \leq f(x) $$
	    		\item Si $\exists \ (m,M) \in \R^2 \ : \ \forall x \in \overset{\circ}{I}, \ m\leq f'(x) \leq M$, alors, $$\forall x \in I \cap X_+, \ f(x_0) + m(x-x_0) \leq f(x) \leq f(x_0) +M(x-x_0)$$ et $$\forall x \in I \cap X_-, \ f(x_0) + M(x-x_0) \leq f(x) \leq f(x_0) +m(x-x_0)$$
	    	\end{itemize}
    		\item Si $\exists M \in \R \ : \ \forall x \in \overset{\circ}{I}, \ |f'(x)|\leq M$, alors, $$\forall (x,y) \in I^2, \ |f(y) -f(x)| \leq M|y-x|$$
	    \end{enumerate}}

		{\begin{figure}[!h]
			\centering
			\tikzmath{ integer \x0 \fx0 \m \M; \x0 = 5;\fx0 = 2.5; \m = 0.2; \M = 0.7; }
			\begin{tikzpicture}
				\draw[-stealth] (0,0) -- (10,0) node[anchor=west] {$x$};
				\draw[-stealth] (0,0) -- (0,5) node[anchor=south] {$y$};

				\coordinate (A) at (1,\fx0-\m*\x0+\m*1);
				\coordinate (B) at (9,\fx0-\m*\x0+\m*9);
				\coordinate (C) at (1,\fx0-\M*\x0+\M*1);
				\coordinate (D) at (9,\fx0-\M*\x0+\M*9);
				\draw[ultra thick, black] (A) -- (B) node[anchor=north west] {$y = f(x_0) + m(x -x_0)$};
				\draw[ultra thick, black] (C) -- (D) node[anchor=south east] {$y = f(x_0) + M(x -x_0)$};
				\filldraw[magenta!30] (A) -- (B) -- (D) -- (C) -- cycle;

				\draw (\x0,\fx0) node[cross out, minimum size=8*\pgflinewidth, inner sep=0pt, outer sep=0pt, draw=blue, rotate=45, thick] {};
				\draw[blue, dashed] (\x0,\fx0) -- (0,\fx0) node[anchor=east] {$f(x_0)$};
				\draw[blue, dashed] (\x0,\fx0) -- (\x0,0) node[anchor=north] {$x_0$};
			\end{tikzpicture}
			\caption{Interprétation géométrique des accroissements finis}
		\end{figure}}]
	    {Inégalité des accroissements finis}
	    $(i)$ Soit $x\in I$ et posons $S$ le segment d'extrémités $x$ et $x_0$. \\
	    $\star$ Si $x\neq x_0$, $f$ est continue sur $S$ et dérivable sur $\overset{\circ}{S}$, la formule des accroissements finis donne alors l'existence d'un $c$ appartenant à $\overset{\circ}{S}$ tel que $$f(x) - f(x_0) = (x-x_0)f'(c)$$ Si $x> x_0, \ x-x_0 > 0$, or $m \leq f'(c) \leq M$ donc $$m(x-x_0) \leq (x-x_0)f'(c) \leq M(x-x_0)$$ si bien que $$m(x-x_0) \leq f(x) - f(x_0) \leq M(x-x_0) $$ d'où $$f(x_0) + m(x-x_0) \leq f(x) \leq f(x_0) + M(x-x_0). $$ Si $x<x_0$, il suffit de retourner l'inégalité lors de la première multiplication et $(i)$ est prouvé.\\ \\
	    $(ii)$ Soit $y \in I.$\\
	    L'hypothèse $\forall x\in \overset{\circ}{I}, \ |f'(x)|\leq M$ équivaut à $\forall x \in \overset{\circ}{I}, \ -M \leq f'(x) \leq M$, donc on peut appliquer $(i)$ pour $x_0 \gets y, \ M \gets M$ et $m\gets -M$ : $$\forall x \in I\cap [y, +\infty [,  \ f(y) -M(x-y) \leq f(x) \leq f(y) + M(x-y)$$
	    Or $x-y >0$ donc $|f(x) -f(y) | \leq M|x-y|$.
	    Et $$\forall x \in I\cap ]-\infty, y ],  \ f(y) +M(x-y) \leq f(x) \leq f(y) - M(x-y)$$
	    Or $x-y < 0$ donc $|f(x) -f(y) | \leq M|x-y|$. \\
	    Par conséquent, $\forall (x,y)\in I^2, \ |f(y) -f(x)| \leq M|y-x|.$
	\end{question_kholle}

	\begin{question_kholle}
	    [Soit $f\in \mathcal{C}^1(I,\R)$, $I$ le segment $a,b$. Alors $f$ est $||f'||_{\infty,I}$-lipschitzienne sur I.]
	    {Caractère lipschitzien d'une fonction $\mathcal{C}^1$ sur un segment}
	    Soient de tels objets. \\
	    $\star$ $f\in \mathcal{C}^1(I, \R)$ donc $f\in \mathcal{C}^0(I, \R)$. \\
	    $\star$ $f\in \mathcal{C}^1(I,\R)$ donc $f\in \mathcal{D}^1(\overset{\circ}{I}, \R)$.\\
	    $\star$ $f\in \mathcal{C}^1(I,\R)$ donc $f'$ est continue sur $I$ donc le réel $||f'||_{\infty,I}$ est bien défini et $$\forall  x \in \overset{\circ}{I}, \ |f'(x)| \leq ||f'||_{\infty,I}.$$ Ces propriétés permettent d'appliquer le corollaire du TAF qui conclut que $f$ est $||f'||_{\infty,I}$-lipschitzienne.
	\end{question_kholle}

	\begin{question_kholle}
	    [Soit $f\in \mathcal{F}(I, \R)$ et $a\in I$.\\
	    \newline
	    \textit{Lemme} : \\
	    Si
	        $\left\{ \begin{array}{cl}
	        f \text{ est dérivable sur } I\backslash \{a\}  \\
	        f \text{ est continue en }a \\
	        f'_{|I\backslash \{a\}} \text{ admet une limite $\ell \in \overline{\R}$ en }a
	        \end{array}
	        \right.$, alors $\lim_{x \to a} \frac{f(x) -f(a)}{x-a} = \ell$\\
	    \newline
	    \textit{Théorème} : \\
	    Si
	        $\left\{ \begin{array}{cl}
	        f \text{ est dérivable sur } I\backslash \{a\}  \\
	        f \text{ est continue en }a \\
	        f'_{|I\backslash \{a\}} \text{ admet une limite \textbf{finie} $\ell \in \R$ en }a
	        \end{array}
	        \right.$, alors $\left\{ \begin{array}{cl}
	        f \text{ est dérivable en } a  \\
	        f'(a) = \ell \ (\textbf{donc } f' \textbf{ est continue en } a)
	        \end{array}
	        \right.$ ]
	    {Théorème du prolongement de la propriété de la dérivabilité}
	    Prouvons le lemme pour $\ell\in \R$, c'est le cas qui nous intéresse. \\
	    Soient de tels objets. Soit $\varepsilon\in \R_+^*$. Appliquons la définition de $\lim_{\substack{x\to a \\ x\neq a}}  f'_{|I\backslash \{a\}}(x) =\ell $ pour $\varepsilon \gets \varepsilon$ :
	    $$\exists \ \eta \in \R_+^* \ : \ \forall x\in I\backslash \{a\}, \ |x-a| \leq \eta \ \implies \ | f'_{|I\backslash \{a\}}(x) - \ell |\leq \varepsilon.$$ Fixons un tel $\eta$.\\
	    Soit $x\in I\backslash \{a\}$ tel que $|x-a|\leq \eta$.\\ La fonction $f$ est continue sur $I$ donc $f$ est continue sur le segment d'extrémités $a$ et $x$ qui est par ailleurs inclus dans $I$ par convexité d'un intervalle.\\ La fonction $f$ est dérivable sur $I$ donc $f$ est dérivable sur l'intervalle ouvert $a$, $x$ qui est aussi inclus dans $\overset{\circ}{I}$ par convexité.\\ L'égalité des accroissements finis s'applique à $f$ sur l'intervalle $a$ et $x$ : $$\exists \ c_x \in ]a,x[ \cup ]x,a[ \ : \ \frac{f(x) -f(a)}{x-a} = f'(c_x)$$
	    Or $|c_x-a| \leq |x-a| \leq \eta $ donc ladite définition de la limite s'applique pour $x\gets c_x$ : $|f'(c_x) - \ell|\leq \varepsilon $ si bien que $$|\frac{f(x)-f(a)}{x-a}- \ell |\leq \varepsilon.$$ D'où le lemme. \\
	    \newline
	    Prouvons alors le théorème.\\
	    Sous ces hypothèses, le lemme s'applique donc $\lim_{x\to a} \frac{f(x) -f(a)}{x-a} = \ell$, or $\ell \in \R$, donc le taux d'accroissement de $f$ en $a$ admet une limite finie en $a$ ce qui prouve la dérivabilité de $f$ en $a$ et $f'(a) = \ell$. Ce qui suffit.
	\end{question_kholle}

	\begin{question_kholle}
		[Posons $\zeta \left| \begin{matrix}
			\R \longrightarrow \R \\
			x \mapsto \left\{ \begin{array}{cc}
				0 &\text{si } x \leqslant 0\\
				\e^{-\frac{1}{x}} &\text{si } x > 0
			\end{array} \right.
		\end{matrix} \right.$.
		Montrons que $\zeta \in \Cont{\infty}{\R}{\R}$.
		{\begin{figure}[!h]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					axis lines = center,
					xlabel = $x$,
					ylabel = {$f(x)$},
					width=15cm,
					height=5cm,
					ymax=1.5
					]
					\addplot[
						domain=0.01:20,
						samples=200,
						color=red,
						]
						{exp(-1/x)};
					\addplot[
						domain=-10:0,
						samples=100,
						color=red,
						]
						{0};
					\addlegendentry{$\zeta$}

					\addplot[
						domain=0:20,
						samples=100,
						color=blue,
						dashed
						]
						{1};
				\end{axis}
			\end{tikzpicture}
		\end{figure}}]
		{La fonction $\zeta$ (pas celle-là une autre) est de classe \Cont{\infty}{}{} sur \R}
		~ \\

		\begin{itemize}[label=$\star$]
			\item $\zeta_{]-\infty;0[}$ est constante donc $\zeta \in \Cont{\infty}{]-\infty;0[}{}$.
			\item $x \mapsto - \frac{1}{x} \in \mathcal{C}^\infty(]0;+\infty[,]-\infty;0[)$ et $\exp \in \Cont{\infty}{]-\infty;0[}{}$ donc, par stabilité de \Cont{\infty}{}{} par composition, $\zeta \in \Cont{\infty}{]0;+\infty[}{}$.
		\end{itemize}

		Considérons le prédicat $\mathcal{P}(\cdot)$ défini pour tout $n \in \N$ :
		\begin{equation}
			\mathcal{P} : \text{\textquotedblleft} \ \exists P_n \in \R[x] : \forall x \in \R^*, \ \zeta^{(n)} = \left\{ \begin{array}{lc}
				0 &\text{si } x < 0 \\
				\frac{P_n(x)}{x^{2n}} \e^{-\frac{1}{x}} &\text{si } x > 0
			\end{array} \right. \ \text{\textquotedblright}
		\end{equation}
		\begin{itemize}[label=$\star$]
			\item $\mathcal{P}(0)$ est vrai par définition de $\zeta$ en posant $P_0(x) = 1$
			\item Soit $n \in \N^*$ \fq tel que $\mathcal{P}$ est vrai.
			D'une part, $\forall x \in ]-\infty;0[, \zeta^{(n)}(x) = 0$ donc
			\begin{equation*}
				\forall x \in ]-\infty;0[, \zeta^{(n+1)}(x) = 0
			\end{equation*}
			D'autre part, $\forall x \in ]0;+\infty[, \zeta^{(n)}(x) = \frac{P_n(x)}{x^{2n}} \e^{-\frac{1}{x}}$ ce qui est un produit de trois expressions dérivables. D'où :
			\begin{equation*}
				\begin{aligned}
					\forall x \in ]-\infty;0[,
					\zeta^{(n+1)}(x)
					&= \left( P_n'(x) \frac{1}{x^{2n}} + P_n(x) \frac{-2n}{x^{2n+1}} + \frac{P_n(x)}{x^{2n}} \frac{1}{x^2} \right) \e^{-\frac{1}{x}} \\
					&= \frac{x^2 P_n'(x) - 2nxP_n(x) + P_n(x)}{x^{2(n+1)}} \e^{-\frac{1}{x}}
				\end{aligned}
			\end{equation*}
			Si bien qu'en posant $P_{n+1}(x) = x^2 P_n'(x) - 2 n x P_n(x) + P_n(x) \in \R[x]$, on obtient :
			\begin{equation*}
				\forall x \in ]0;+\infty[, \zeta^{(n+1)}(x) = \frac{P_{n+1}(x)}{x^{2(n+1)}} \e^{-\frac{1}{x}}
			\end{equation*}
			Par conséquent, $\mathcal{P}(x)$ est vrai.

			Appliquons maintenant le théorème de prolongement du caractère \Cont{\infty}{}{}.
			\begin{itemize}[label=$\star$]
				\item Nous avons montré que $\zeta \in  \Cont{\infty}{\R \!\setminus\! \{0\}}{}$.
				\item Calculons les limites à gauche et à droite de 0. Soit $k \in \N$ \fq.
				\begin{itemize}[label=$\star\star$]
					\item $\zeta^{(k)}$ est nulle sur $]-\infty;0[$, $\zeta^{(k)} \arrowlim{x}{0^-} 0$.
					\item De plus, $\exists P_n \in \R[x] : \ \forall x \in ]0;+\infty[, \zeta^{(k)}(x) = \frac{P_k(x)}{x^{2k}} \e^{-\frac{1}{x}}$. Posons $u = \frac{1}{x}$, ainsi $\zeta^{(k)}(x) = u^{2k} P_k(\frac{1}{u}) \e^{-\frac{1}{x}}$ et $u \arrowlim{x}{0^+} +\infty$. \\
					Le théorème des croissances comparées donne $u^{2k} P_k(\frac{1}{u}) \e^{-u} \arrowlim{u}{+\infty} 0$ donc $\zeta^{(k)}(x) \arrowlim{x}{0^+} 0$.
				\end{itemize}
			\end{itemize}
			Donc $\zeta \in \Cont{\infty}{\R}{\R}$.
		\end{itemize}
	\end{question_kholle}

\pagebreak\section{Semaine 15}
	
	\begin{question_kholle}
		[Soit $f : I \rightarrow \R$ convexe sur $I$. \\
		Soit $n \in \N^*$. Soient $x \in I^n$, $\lambda \in {[0;1]}^n$ telle que $\displaystyle \sum_{k=1}^{n} \lambda_k = 1$. \\
		\begin{equation}
			\sum_{k=1}^{n} \lambda_k x_k \in I \wedge
			f\left( \sum_{k=1}^{n} \lambda_k x_k \right)
			\leqslant \sum_{k=1}^{n} \lambda_k f\left( x_k \right)
		\end{equation}]
		{Inégalité de Jensen}
		Considérons le prédicat $\mathcal{P}(\cdot)$ défini pour tout $n \in \N^*$ par :
		\begin{equation*}
			\mathcal{P}(n) : \text{\textquotedblleft}
			\forall x \in I^n,
			\forall \lambda \in [0;1]^n,
			\sum_{k=1}^{n} \lambda_k = 1 \implies
			\sum_{k=1}^{n} \lambda_k x_k \in I \wedge
			f\left( \sum_{k=1}^{n} \lambda_k x_k \right)
			\leqslant \sum_{k=1}^{n} \lambda_k f\left( x_k \right)
			\text{\textquotedblright}
		\end{equation*}
	
		\begin{itemize}[label=*, leftmargin=0.5cm]
			\item Soient $x \in I^1$ et $\lambda \in [0;1]^1$ tel que $\sum_{k=1}^{1} \lambda_k = 1$. \\
			Alors $\lambda_1 = 1$. Trivialement, $\sum_{k=1}^{1} \lambda_k x_k = \lambda_1 x_1 = x_1 \in I$. \\
			De plus, $f\left( \sum_{k=1}^{1} \lambda_k x_k \right)
				= f\left( \lambda_1 x_1 \right)
				= f\left( x_1 \right)
				= \lambda_1 f\left( x_1 \right)
				= \sum_{k=1}^{1} \lambda_k f\left( x_k \right)$. \\
			Donc $\mathcal{P}(1)$ vrai.

			\item  Soit $n \in \N^*$  tel que $\mathcal{P}(n)$ vrai. \\
			Soient $x \in I^{n+1}$ et $\lambda \in [0;1]^{n+1}$ tel que $\sum_{k=1}^{n+1} \lambda_k = 1$. \\
			$\{ x_k \;|_; k \in [\![1;n+1]\!] \}$ est une partie non vide ($n \geqslant 1$) d'un ensemble totalement ordonnée $\left(\R,\leqslant\right)$.
			Posons $a = \min\{ x_k \;|_; k \in [\![1;n+1]\!] \}$ et $b = \max\{ x_k \;|_; k \in [\![1;n+1]\!] \}$. D'où
			\begin{equation*}
				a
				\underbrace{=}_{\displaystyle \sum_{k=1}^{n+1} \lambda_k = 1} \sum_{k=1}^{n+1} \lambda_k a
				\underbrace{\leqslant}_{a \leqslant x_k} \sum_{k=1}^{n+1} \lambda_k x_k
				\underbrace{\leqslant}_{x_k \leqslant b} \sum_{k=1}^{n+1} \lambda_k b
				\underbrace{=}_{\displaystyle \sum_{k=1}^{n+1} \lambda_k = 1} b
			\end{equation*}
			Or $\{ x_k \;|_; k \in [\![1;n]\!] \} \subset I$ (car $x \in I^n$) donc $a \in I \wedge b \in I$. Donc
			\begin{equation*}
				\sum_{k=1}^{n+1} \lambda_k x_k
				\in [a;b]
				\underbrace{\subset}_{\begin{array}{c} \text{par convexité} \\ \text{de l'intervalle } I \end{array}} I
			\end{equation*}
			
			$\sum_{k=1}^{n+1} \lambda_k = 1$ donc $\exists i_0 \in [\![1;n+1]\!] : \lambda_{i_0} \neq 1$ (sinon $\sum_{k=1}^{n+1} \lambda_k = n+1 \neq 1$ car $n \neq 0$). \\
			Fixons un tel $i_0$.
			\begin{equation*}
				\begin{aligned}
					f\left( \sum_{k=1}^{n+1} \lambda_k x_k \right)
					&= f\left( \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \lambda_k x_k + \lambda_{i_0} x_{i_0} \right) \\
					&= f\left( \lambda_{i_0} x_{i_0} + \left( 1 - \lambda_{i_0} \right) \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \frac{\lambda_k}{1 - \lambda_{i_0}} x_k \right) \\
					\underbrace{\leqslant}_{\begin{array}{c} \text{Par convexité} \\ \text{de } f \end{array}}& \lambda_{i_0} f(x_{i_0}) + \left( 1 - \lambda_{i_0} \right) f\left( \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \frac{\lambda_k}{1 - \lambda_{i_0}} x_k \right)
				\end{aligned}
			\end{equation*}
			Or $\displaystyle \forall i \in [\![1;n+1]\!] \lambda_i \leqslant \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \lambda_k = 1 - \lambda_{i_0}$ Donc $\displaystyle \frac{\lambda_i}{1 - \lambda_{i_0}} \in [0;1]$ et $\displaystyle \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \frac{\lambda_k}{1 - \lambda_{i_0}} = 1$. Nous pouvons appliquer $\mathcal{P}(n)$ pour $\lambda_i \rightarrow \frac{\lambda_i}{1 - \lambda_{i_0}}$ :
			\begin{equation*}
				\begin{aligned}
					f\left( \sum_{k=1}^{n+1} \lambda_k x_k \right)
					&\leqslant \lambda_{i_0} f(x_{i_0}) + \left( 1 - \lambda_{i_0} \right) \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \frac{\lambda_k}{1 - \lambda_{i_0}} f\left( x_k \right) \\
					&\leqslant \lambda_{i_0} f(x_{i_0}) + \sum_{\begin{array}{c} k = 1 \\ k \neq i_0 \end{array}}^{n+1} \lambda_k f\left( x_k \right) \\
					&\leqslant \sum_{k = 1}^{n+1} \lambda_k f\left( x_k \right) \\
				\end{aligned}
			\end{equation*}
			Donc $\mathcal{P}(n+1)$ vrai.
		\end{itemize}
	\end{question_kholle}
	
	\begin{question_kholle}
		[Soit $n \in \N^*$. Soit $x \in \R_+^{*n}$.
		\begin{equation}
				\left( \prod_{k=1}^{n} x_k \right)^{\nicefrac{1}{n}}
				\leqslant \frac{1}{n} \sum_{k=1}^{n} x_k
		\end{equation}]
		{Inégalité arithmético-géométrique}
		Soit de tels objets. Posons $\forall k \in [\![1;n]\!], \lambda_k = \nicefrac{1}{n}$. \\
		Sachant que l'exponentielle est convexe, appliquons l'inégalité de Jensen pour $x_k \leftarrow ln(x_k)$ (autorisé car $x_k \in \R_+^*$) :
		\begin{equation*}
			\exp \left( \sum_{k=1}^{n} \frac{1}{n} \ln \left( x_k \right) \right)
			\leqslant \sum_{k=1}^{n} \frac{1}{n} \exp \left( \ln \left( x_k \right) \right)
		\end{equation*}
		L'exponentielle est la bijection réciproque du logarithme népérien et est un morphisme additif. Nous obtenons ainsi l'inégalité recherchée.
	\end{question_kholle}
\pagebreak\section{Semaine 16}
	
	\begin{question_kholle}
		{Deux fonctions équivalentes au voisinage de $a$ ont le même signe sur un voisinage de $a$}
		
		Soient $f : \mathcal{D} \rightarrow \R$ et $g : \mathcal{D} \rightarrow \R$ telles que $f(x) \underset{x \rightarrow a}{\sim} g(x)$ avec $a \in \mathcal{D}$. \\
		Appliquons la définition de l'équivalence pour $\epsilon \leftarrow \frac{1}{2}$, il existe un voisinage $V$ de $a$ tel que :
		\begin{equation*}
			\forall x \in V \cap \mathcal{D},
			| f(x) - g(x) | \leqslant \frac{1}{2} | g(x) |
		\end{equation*}
	
		Fixons un tel voisinage $V$.
		Nous obtenons :
		\begin{equation*}
			\forall x \in V \cap \mathcal{D},
			\underbrace{g(x) - \frac{1}{2} | g(x) |}_{\text{du signe de }g(x)}
			\leqslant f(x) \leqslant
			\underbrace{g(x) + \frac{1}{2} | g(x) |}_{\text{du signe de }g(x)}
		\end{equation*}
	
		Ainsi $f(x)$ et $g(x)$ ont le même signe sur $V \cap \mathcal{D}$.
	\end{question_kholle}

	\begin{question_kholle}
		[ Soient $f \in \Cont{\infty}{\mathcal{D}}{}$ et $a \in \overset{\circ}{\mathcal{D}}$. Supposons que $E_0 = \left\{ p \in \N^* \setminus \{1\} \;|\; f^{(p)}(a) \neq 0 \right\}$ est non vide. \\
		Posons $p_0 = \min E_0$. \\
		$f$ admet un extremum local en $a$ si et seulement si $f'(a) = 0$ et $p_0$ est pair. \\
		$f$ admet un point d'inflexion en $a$ si et seulement si $p_0$ est impair. ]
		{Condition nécessaire et suffisante pour qu'une fonction \Cont{\infty}{}{} admette un extremum local ou un point d'inflexion}
		
		Soient de tels objets. Traitons le cas de l'extremum local.
		
		\noindent $f \in \Cont{\infty}{}{}$ donc, la formule Taylor-Young donne un $DL_{p_0}(a)$ de $f$ :
		\begin{equation*}
			f(x) \underset{x \rightarrow a}{=}
			\sum_{k=0}^{p_0} \frac{f^{(k)}(a)}{k!} (x-a)^k + o \left( (x-a)^{p_0} \right)
		\end{equation*}
		
		En développant :
		\begin{equation*}
			f(x) \underset{x \rightarrow a}{=}
			f(a) + \underbrace{f'(a)(x-a)}_{= 0} + \underbrace{\ldots + \frac{f^{(p_0-1)}(a)}{(p_0-1)!} (x-a)^{p_0-1}}_{= 0 \text{ par défintion de }p_0} + \frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0} + o \left( (x-a)^{p_0} \right)
		\end{equation*}
		
		Ainsi (car $f^{(p_0)}(a) \neq 0$)
		\begin{equation}
			f(x) - f(a) \underset{x \rightarrow a}{\sim} \frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}
		\end{equation}
		Au voisinage de $a$, $f(x) - f(a)$ et $\frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}$ ont le même signe.
		\\
		
		Supposons que $f$ admette un extremum local en $a$.
		Or $a \in \overset{\circ}{\mathcal{D}}$ et $f$ est dérivable en 0, donc $f'(a) = 0$.
		Comme $f$ admette un extremum local en $a$, $f(x) - f(a)$ est de signe constant au voisinage de $a$.
		Donc $\frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}$ est de signe constant au voisinage de $a$.
		Par conséquent, $p_0$ est pair.
		\\
		
		Réciproquement, supposons que $f'(a) = 0$ et que $p_0$ est pair. $\frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}$ est de signe constant au voisinage de $a$. Donc $f(x) - f(a)$ est de signe constant au voisinage de $a$. Ainsi, $a$ est un extremum local de $f$.
		\\
		
		Traitons le cas du point d'inflexion. La formule de Taylor-Young donne :
		\begin{equation}
			f(x) - \underbrace{\left( f(a) + (x-a)f'(a) \right)}_{\text{tangente en } (a,f(a))}
			\underset{x \rightarrow a}{\sim} \frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}
		\end{equation}
		Le signe de l'écart courbe/tangente en $a$ est donc celui de $\frac{f^{(p_0)}(a)}{p_0!} (x-a)^{p_0}$. Ce qui conclut de la même manière que l'extremum local.
	\end{question_kholle}
	
\pagebreak\section{Semaine 17}

	 \begin{question_kholle}
	    [Soient $a,b\in \N ^*$ et $c\in \Z$. Il existe des entiers $x,y\in \Z$ tels que $ax + yb = c$ si et seulement si $c$ est multiple du pgcd de $a$ et $b$.]
	    {Théorème de Bézout}
	    Soient $a,b\in \N^*$. On suppose l'algorithme d'Euclide réalisé pour $a,b$, ainsi à la fin de ce dernier on a un entier naturel $r_n$ tel que $r_n = a\wedge b$. Comme l'algorithme est terminé, on peut remonter chaque ligne de proche en proche, on aurait, à titre d'exemple, pour une première itération, $r_n =r_{n-2} - q_{n} \cdot r_{n-1}$. En réalisant toutes les étapes nécessaires, on obtient une relation entre $r_n$ et $a,b$, cette relation s'écrit : $$\exists \ (x_0, y_0)\in (\Z ^*)^2 \ : \ a\wedge b = r_n = ax_0 + y_0b.$$
	    Si $c$ est un multiple de $a\wedge b $, alors il existe $k\in \Z^*$ tel que $c = k(a\wedge b)$, donc en multipliant le résultat montré au dessus par $k$, on a le sens indirect. Si pour $c\in \Z$, il existe des entiers $x,y\in \Z$ tels que $ax + yb = c$, alors le pgcd de $a$ et $b$ divise le membre de gauche et donc par égalite le membre de droite aussi donc $c$ est multiple de $a\wedge b$, ce qui suffit. 
	\end{question_kholle}
	\begin{question_kholle}
	    [Soient $a,b,c$ trois entiers naturels non nuls. Si $c$ est premier avec $a$ et divise le produit $ab$, alors il divise $b$.]
	    {Théorème de Gauss}
	    Soient $a,b,c$ des entiers naturels vérifiant les hypothèses. \\
	    Comme $c$ est premier avec $a$ on écrit une relation de Bézout pour $1$, leur pgcd et on multiplie le tout par $b$ : 
	    $$\exists \ (u,v) \in (\N ^*)^2 \ : \ au + vc = 1 \ \implies \ abu + vbc = b, $$
	    or $c$ divise $ab$ et lui-même donc aussi le membre de gauche donc par égalité, le membre droite, c'est le théorème.
	\end{question_kholle}
	\begin{question_kholle}
	    [Soient $a,b,c\in \Z$. Résoudre l'équation $$ax + yb = c,$$ d'inconnues $x$ et $y$ dans $\Z$.]
	    {Résoudre une équation du type $ax + yb = c$}
	    Soient $a,b,c\in \Z$ et une telle équation, notée $(i)$, en lesdites inconnues. \\
	    Si $a\wedge b \not| \ c$, alors le théorème de Bézout, affirme que l'équation n'a pas de solution. \\
	    Supposons le contraire. Posons $d = a\wedge b$. Le lemme technique affirme l'existence de $a'$ et $b'$ dans $\Z$, tels que $a'd= a$, $b'd =b$ et $a' \wedge b' = 1$. Donc, comme $d$ divise $c$, il existe $c'$ tel que $c = c'd$. On réécrit l'équation, notée $(ii)$ : $$ a'x +yb'  = c'.$$ On sait d'après le théorème de Bézout qu'il existe des solutions, en particulier grâce à l'algorithme d'Euclide on construit $(x_0,y_0)$, une solution de la nouvelle équation, puis on l'injecte et on raisonne par équivalence, on note $\omega$ l'ensemble des solutions de $(ii)$ et $\Omega$ celui de $(i)$ :
	    \begin{center}
	    $
	    \begin{array}{ccc}
	      (x,y) \in \Omega  & \iff &  (x,y)\in \omega \\
	         &\iff & a'x +yb' = c' \\
	         &\iff & a'x + yb' = a'x_0 + y_0b' \\
	         &\iff & a'(x-x_0) = b'(y_0 -y) \\[1ex]
	         &\iff & \exists \ k \in \Z \ :\left\{  \begin{array}{ccc}
	                                                a'(x-x_0) & = & b'(y_0 -y)  \\
	                                                y_0 - y & = & a'k 
	                                                \end{array} \right. \\[2ex]
	         &\iff &  \exists \ k \in \Z \ :\left\{  \begin{array}{ccc}
	                                                a'(x-x_0) & = & b'(y_0 -y)  \\
	                                                 y & = & y_0 - a'k 
	                                                \end{array} \right. \\[2ex]
	         &\iff &  \exists \ k \in \Z \ :\left\{  \begin{array}{ccc}
	                                                 x & = & x_0 + b'k  \\
	                                                 y & = & y_0 - a'k 
	                                                \end{array} \right. \\[2ex]
	         &\iff & (x,y) \in \{ (x_0 + b'k,\  y_0 - a'k) \ | \ k\in \Z \}
	    \end{array}
	    $ \\
	    \end{center}
	    La première ligne découle de la divisibilité des coefficients par $d$, la deuxième est la définition d'appartenance à $\omega$, la troisième est une réécriture du fait que $(x_0,y_0)$ soit solution de $(ii)$, la quatrième est une factorisation banale, la cinquième une utilisation du théorème de Gauss pour le sens direct et le sens indirect ne pose pas de problème, la sixième est une réécriture de la deuxième relation, la septième découle de l'expression de $y$ pour le sens direct et le sens indirect s'obtient en multipliant avec parcimonie l'équation, la huitième est une réécriture de la septième qui ne pose pas de problème. C'est $\Omega$, par équivalence.
	    
	\end{question_kholle}
\pagebreak\section{Semaine 18}

	\begin{question_kholle}
		{L'ensemble des nombres premiers est infini}

		Notons l'ensemble des nombres premiers $\PRIME = \left\{ n \in \N \;|\; \left| \mathcal{D}(n) \cup \N \right| = 2 \right\}$
		Par l'absurde, supposons que \PRIME est fini. \\
		Posons $\displaystyle m = 1 + \prod_{p \in \PRIME} p \in \N$. \\
		Comme $2 \in \PRIME$, $m \geqslant 2$. Donc $m$ admet un diviseur premier, $\exists q \in \PRIME : q \;|\; m$. Donc $q \wedge m = q$. \\
		Par ailleurs, $\displaystyle m = 1 + q \left( \prod_{\tiny \begin{matrix} p \in \PRIME \\ p \neq q \end{matrix}} p \right)$. Donc $\displaystyle m - q \left( \prod_{\tiny \begin{matrix} p \in \PRIME \\ p \neq q \end{matrix}} p \right) = 1$. D'après le théorème de Bézout, $q \wedge m = 1$. \\
		Donc $q = 1$ ce qui est une contradiction avec $q \in \PRIME$.
	\end{question_kholle}

	\begin{question_kholle}
		[Soit $n \in \N^*, p \in \PRIME, k_0 \in \N$.
		\begin{equation}
			\nu_p(n) = k_0 \iff
			\exists m \in \Z : \left\{ \begin{matrix}
				n = p^{k_0} m \\
				m \wedge p = 1
			\end{matrix} \right.
		\end{equation}
		]
		{Caractérisation de la valuation \textit{p}-adique}

		$\implies$ Supposons que $\nu_p(n) = k_0$. \\
		Par définition de la valuation \textit{p}-adique, $p^{\nu_p(n)} \;|\; n$ donc $p^{k_0} \;|\; n$.
		Notons $m \in \Z$ le quotient de la division euclidienne de $n$ par $p^{k_0}$. Nous avons $n = p^{k_0} m$. \\
		Comme $m \wedge p \in \mathcal{D}(p) \cap \N$, $m \wedge p \in \left\{1,p\right\}$.
		Par l'absurde, supposons que $m \wedge p = p$.
		\begin{equation*}
			\begin{aligned}
				p \;|\; m
				&\implies \exists m' \in \Z : m = p m' \\
				&\implies \exists m' \in \Z : n = p p^{k_0} m' = p^{k_0+1} m' \\
				&\implies k_0 + 1 \in \left\{ k \in \N \;|\; p^k | n \right\} \\
				&\implies k_0 + 1 \leqslant \max \left\{ k \in \N \;|\; p^k | n \right\} = \nu_p(n) = k_0
			\end{aligned}
		\end{equation*}
		Ce qui est une contradiction donc $m \wedge p = 1$.

		$\impliedby$ Supposons $\exists m \in \Z : \left\{ \begin{matrix}
			n = p^{k_0} m \\
			m \wedge p = 1
		\end{matrix} \right.$ \\
		Par définition de la valuation \textit{p}-adique, $p^{\nu_p(n)} \;|\; n$ donc $p^{\nu_p(n)} \;|\; p^{k_0} m$. Or $m \wedge p = 1$ donc $m \wedge p^{\nu_p(n)} = 1$.
		D'après le théorème de Gauss, $p_{\nu_p(n)} \;|\; p^{k_0}$. Donc $\exists \alpha \in \Z : \alpha p_{\nu_p(n)} = p^{k_0}$
		\begin{equation*}
			\begin{aligned}
				\alpha p_{\nu_p(n)} = p^{k_0}
				&\implies p^{k_0} - \alpha p_{\nu_p(n)} = 0 \\
				&\implies p^{k_0} \left( 1 - \alpha p^{\nu_p(n) - k_0} \right) = 0 \text{ car } k_0 \leqslant \nu_p(n) \\
				&\implies \alpha p^{\nu_p(n) - k_0} = 1 \text{ car \Z est intègre} \\
				&\implies p^{\nu_p(n) - k_0} \in \mathcal{D}(1) \cap \N \\
				&\implies p^{\nu_p(n) - k_0} = 1 \\
				&\implies \nu_p(n) - k_0 = 0 \\
				&\implies \nu_p(n) = k_0 \\
			\end{aligned}
		\end{equation*}
	\end{question_kholle}

    \begin{question_kholle}
    	[\begin{equation}
    		\forall (a, b) \in \Z^2, \
    		a|b \ \iff \ \forall p \in \PRIME, \ \nu _p (a) \leq \nu _p (b)
    	\end{equation}]
        {Caractérisation de $a | b$ par les valuations $p$-adiques et preuve de leur propriété de morphisme.}
        Premièrement, montrons que la valuation $p$-adique est un morphisme de $(\Z ^* , \times)$ dans $(\N ,+)$. \\
        Soient de tels entiers relatifs $a,b$. \\
        \[
            \exists \ m,n \in (\Z ^*)^2 \ : \ \left(\left(a = p^{\nu _p (a)}m\right) \ \wedge \ (m\wedge p = 1)\right) \ \wedge \ \left(\left(b = p^{\nu _p (b)}n\right) \ \wedge \ (n\wedge p = 1)\right),
        \]
        donc $ab = p^{\nu _p (a) + \nu _p (b)}mn$ et $mn \wedge p = 1$, par la réciproque de la caractérisation des valuations $p$-adiques :
        \[
            \nu _p (ab) = \nu _p (a) + \nu _p (b).
        \]
        Prouvons le sens réciproque de la susdite caractérisation.  Supposons le membre de droite. \\
        D'après le théorème de décomposition en facteurs premiers,
        \[
            |b| = \prod_{p\in \PRIME} p^{\nu _p (b)} = \prod_{p\in \PRIME} p^{\nu _p (a)}(p^{\nu _p (b) - \nu _p (a)}) = \prod_{p\in \PRIME}  p^{\nu _p (a)} \prod_{p\in \PRIME} p^{\nu _p (b) - \nu _p (a)}= |a|\prod_{p\in \PRIME} p^{\nu _p (b) - \nu _p (a)},
        \]
        la première manipulation se justifie par hypothèse et la seconde peut se justifier par le calcul.\\
        Ainsi, $|a| | |b|$ donc $a|b$. \\
        Prouvons le sens direct. Supposons le membre de gauche.  \\
        Soit $p \in \PRIME$. Il existe $k\in \Z$ tel que $ak = b $ car $a |b$. Ainsi,
        \[
            \nu _p (b) = \nu _p (ak) = \nu _p (a) + \nu _p (k) \geq \nu _p (a).
        \]
        Ce qui suffit.
    \end{question_kholle}

    \begin{question_kholle}
        [Le pgcd comme produit des $p$ à la puissance du minimum des $\nu _p$ et le ppcm comme le produit des  $p$ à la puissance du maximum des $\nu _p$.
        \begin{equation}
        	\begin{aligned}
        		a \wedge b &= \prod_{p\in \PRIME} p^{\min (\nu _p (a),\nu_p (b))} \\
        		a \vee b &= \prod_{p\in \PRIME} p^{\max (\nu _p (a),\nu_p (b))}
        	\end{aligned}
        \end{equation}]
        {Expression du pgcd et du ppcm à partir des décomposition en facteurs premiers de $a$ et $b$.}
        Prouvons la formule du pgcd et déduisons-en la formule du ppcm. \\
        Soient $(a,b)\in (\Z ^*)^2$. Soit $p \in \PRIME $. Il faut et il suffit de montrer que $\nu_p (a \wedge b) = \min (\nu_p(a), \nu_p(b))$ pour obtenir le résultat. On a $a\wedge b | a$ et $a \wedge b | b$ donc d'après la caractérisation de la divisibilité par les valuations $p$-adiques, $\nu_p (a \wedge b) \leq \nu _p (a)$ et $\nu _p (a\wedge b) \leq \nu _p (b)$ donc $\nu _p (a\wedge b) \leq \min (\nu _p(a), \nu_p (b)).$ \\
        Posons $m = \min (\nu _p(a), \nu_p (b))$. On a
        \[
            |a| = \prod_{q \in \PRIME} q ^{\nu _q (a)} = p^m \left( (p^{\nu_p (a)- m})\prod_{q \in \PRIME \backslash \{p\}} q ^{\nu _q (a)} \right),
        \]
        car par définition, $m \leq \nu _p (a)$, donc $p^m | a$, on montrerait de même que $p^m |b$, donc par définition, $p^m | a\wedge b$, donc une nouvelle fois en appliquant la caractérisation de la divisibilité par les valuations $p$-adiques, $m \leq \nu_p ( a\wedge b)$. Finalement, $\nu_p (a\wedge b) = m$. \\
        On en déduit la formule du ppcm :
        \[
            |a||b| = (a \wedge b) (a \vee b) \ \implies \ a\vee b = \prod_{p\in \PRIME} p^{\nu _p(a) + \nu _p(b) - \min (\nu _p (a),\nu_p (b))} =  \prod_{p\in \PRIME} p^{\max (\nu _p (a),\nu_p (b))}
        \]

    \end{question_kholle}

    \begin{question_kholle}
        [Petit Th. de Fermat :
        {\begin{enumerate}[label=($\roman*$)]
        	\item $\forall a \in \Z , \ a^p \equiv a \mod p$ \\
	        $\ \forall x \in \Z / p\Z, \ x^p = x $
	        \item $\forall a \in \Z, \ p\not | a, \ \implies \ a^{p-1} \equiv 1 \mod p$ \\
        	$\ \forall x \in \Z / p\Z, \ x^{p-1} = 1 $
        \end{enumerate}}]
        {Pour $p$ premier, $(a+b)^p \equiv a^p + b^p \mod p$, en déduire le petit Th. de Fermat (2 versions), expression du résultat dans $\Z / p\Z$.}
        Soient $a,b$ de tels entiers relatifs et soit $p$ un nombre premier. Calculons,
        \[
            (a + b )^p  = \sum_{k = 0}^p \binom{p}{k}a^{p-k}b^k  = a^p + b^p + \sum_{k = 1}^{p-1} \binom{p}{k}a^{p-k}b^k \equiv a^p + b^p \mod p,
        \]
        car $\forall k \in [\![1,p-1 ]\!], \ p | \binom{p}{k}$ (élémentaire), d'où le résultat. \\
        Dans $\Z /p\Z$, ce résultat s'énonce comme suit :
        \[
            \forall (x,y) \in \Z /p\Z ^2, \ (x+y)^p = x^p + y^p.
        \]
        En guise d'application, démontrons le petit Th. de Fermat énoncé plus haut. \\
        Démonstration du $(i)$. Considérons le prédicat $\PRIME ( \cdot)$ défini sur $\N$  par :
        \[
            \PRIME (a) : "a^p \equiv a \mod p".
        \]
        Initialisation : Pour $a = 0$, rien à faire, donc $\PRIME (0)$ est vrai. \\
        Hérédité : Soit $a\in \N$ \tq $\ \PRIME (a)$. Calculons,
        \[
            (a+1)^p  \equiv a^p + 1 \mod p \overset{\PRIME (a)}{\equiv} a + 1 \mod p,
        \]
        donc $\PRIME (a+1)$ vrai. \\
        Par Th. de récurrence sur $\N$, $\PRIME(a)$ est vrai pour tout $a\in \N$. \\
        Il faut maintenant étendre le résultat à $\Z$. Soit $p\in \PRIME \backslash \{2\}$, ainsi $p$ est impair. Soit $a\in \Z \backslash \N$. Calculons,
        \[
            a^p\equiv (-|a|)^p \mod p \equiv - |a|^p \mod p \overset{\underset{\text{pour }a \gets |a|}{\text{Th. de Fermat}}}{\equiv} - |a| \mod p \equiv a \mod p  .
        \]
        Si $p =2$, $\ a^2 \equiv |a|^2 \mod 2 \equiv |a| \mod 2 \equiv -|a| \mod 2 \equiv a \mod 2$. \\
        Le $(ii)$, soit $a\in \Z$ tel que $p \not | a$.
        \[
            (p\not | a)\wedge (p\in \PRIME) \implies p\wedge a = 1,
        \]
        d'après le $(i)$, $\ p | a^p -a \ \implies \ p| a(a^{p-1} -1) \ \overset{\text{Th. de Gauss}}{\implies}  \ p| a^{p-1} -1 \ \implies \ a^{p-1} \equiv 1 \mod p$. \\
        Les écritures dans $\Z /p \Z$ ne posent pas de problème.s, ce qui conclut.
    \end{question_kholle}

    \begin{question_kholle}
        []
        {$\Z /n\Z$ est un corps si et seulement si $n$ est premier.}
        Montrons le sens réciproque, supposons $n\in \PRIME$. \\
        Soit $x\in \Z/n\Z$ tel que $x \neq \overline{0}$. \\
        $\exists \ a \in [\![0,p-1]\!]\ : \ c = \overline{a}$, $\ I =[\![0, p-1]\!]$ étant un système de représentant des classes. \\
        Comme $a\in I, \ n\not | a$, or $n \in \PRIME$, donc $n \wedge a = 1$. Par Bezout, il existe $u,v \in \Z^2$ tels que $au +nv =1$, donc $u$ est l'inverse de $a$ modulo $n$ donc $a\in \Z/n\Z ^\times$, dès lors, tout élément non nul de $\Z/n\Z$ est inversible, or c'est un anneau commutatif, donc c'est un corps. \\ \\
        Montrons le sens direct en raisonnant par contraposition, supposons $n\not \in \PRIME$. \\
        Comme $n$ n'est pas premier et est plus grand que $2$, il admet un diviseur, $d$, dans $I\backslash \{0,1\} = J$. Notons $d'$ le quotient de la division euclidienne de $n$ par $d$, on a alors $a = dd'$ et $d'\in J$. Donc $\overline{d}\overline{d'}=\overline{0}$ et comme $d,d' \in J$, on a $d,d' \neq 0$, donc $\overline{d}$ est un diviseur de zéro de $\Z/n\Z$, donc $\overline{d}$ est un élément non nul de $\Z/n\Z$ non inversible, donc $\Z/n\Z$ n'est pas un corps. En contraposant ce que nous venons de démontrer on a le résulat. Ce qui conclut.
    \end{question_kholle}

	\begin{question_kholle}
		{Les éléments inversibles d'un anneau $A$ forment un groupe multiplicatif noté $\left( A^\times, \times \right)$}

		Soit $(A, +, \times)$ un anneau. \\
		Un élément inversible (ou unité) est un élément de $A$ symétrisable pour la loi $\times$. Posons l'ensemble des éléments inversibles $A^\times = \left\{ a \in A \;|\; \exists b \in A : a \times b = b \times a = 1_A \right\}$.

		\begin{itemize}[label=$\star$, leftmargin=.5cm]
			\item Montrons que la LCI $\times$ se restreint bien à $A^\times$ en un LCI $\times_{A^\times}$. \\
			Soient $(a_1, a_2) \in {A^\times}^2$.
			Par défintion de $A^\times$, $\exists (b_1, b_2) \in A^2 : a_1 \times b_1 = b_1 \times a_1 = 1_A \text{ et } a_2 \times b_2 = b_2 \times a_2 = 1_A$.
			\begin{equation*}
				\left( a_1 \times a_2 \right) \times \left( b_2 \times b_1 \right)
				\underbrace{=}_{\text{loi associative}} a_1 \times \underbrace{a_2 \times b_2}_{= ~ 1_A} \times b_1
				= a_1 \times b_1
				= 1_A
			\end{equation*}
			\begin{equation*}
				\left( b_2 \times b_1 \right) \times \left( a_1 \times a_2 \right)
				\underbrace{=}_{\text{loi associative}} b_2 \times \underbrace{b_1 \times a_1}_{= ~ 1_A} \times a_2
				= b_2 \times a_2
				= 1_A
			\end{equation*}
			Donc $\left( a_1 \times a_2 \right) \in A^\times$.

			\item La loi $\times$ est associative donc la loi $\times_{A^\times}$ l'est aussi.

			\item $1_A$ vérifie $1_A \times 1_A = 1_A$ donc $1_A \in A^\times$. \\
			De plus, $\forall a \in A^\times, 1_A \times_{A^\times} a = a \times_{A^\times} 1_A = a$ donc $\times_{A^\times}$ admet $1_A$ comme élément neutre.

			\item Soit $a \in A^\times$. Par définition de $A^\times$, $\exists b \in A : a \times b = b \times a = 1_A$. \\
			D'où $b \in A^\times$. En pensant les égalités ci-dessus dans $A^\times$,
			\begin{equation*}
				a \times_{A^\times} b = b \times_{A^\times} a = 1_A
			\end{equation*}
			Donc $a$ est inversible dans $A^\times$.
		\end{itemize}

		Ainsi, $\left( A^\times, \times_{A^\times} \right)$ est un groupe.
	\end{question_kholle}

	\begin{question_kholle}
		{L'image directe par un morphisme d'anneau d'un sous-anneau de l'anneau de départ est un sous anneau de l'anneau d'arrivée. De même pour l'image réciproque.}

		Soient $\left(A,+,\times\right)$ et $\left(B,+,\times\right)$ deux anneaux et $f : A \rightarrow B$ un morphisme d'anneau.

		\noindent Soit $A'$ un sous-anneau de $A$. Montrons que $f(A')$ est un sous-anneau de $B$.
		\begin{itemize}[label=$\star$, leftmargin=.5cm]
			\item Par définition de $f$, $f(A') \subset B$ et $(B,+,\times)$ est un anneau.
			\item Soient $(u,v) \in f(A')^2$. Alors $\exists (a,b) \in A'^2 : f(a) = u \text{ et } f(b) = v$. $f$ est un morphisme d'anneau donc un morphisme de groupe de $(A,+)$ dans $(B,+)$ donc
			\begin{equation*}
				u - v = f(a) - f(b) = f(a - b)
			\end{equation*}
			Comme $A'$ est un sous-anneau, $a - b \in A'$. Donc $u - v \in f(A')$. \\
			De même, $f$ est un morphisme d'anneau donc un morphisme de monoïde de $(A,\times)$ dans $(B,\times)$ donc
			\begin{equation*}
				u \times v = f(a) \times f(b) = f(a \times b)
			\end{equation*}
			Comme $A'$ est un sous-anneau, $a \times b \in A'$. Donc $u \times v \in f(A')$.
			\item $f$ est un morphisme d'anneau donc $1_B = f(1_A)$. Or $A'$ est un sous-anneau donc $1_A \in A'$. D'où $1_B \in f(A')$.
		\end{itemize}

		\noindent Soit $B'$ un sous-anneau de $B$. Montrons que $f^{-1}(B')$ est un sous-anneau de $A$.
		\begin{itemize}[label=$\star$, leftmargin=.5cm]
			\item Par définition de $f$, $f^{-1}(B') \subset A$ et $(A,+,\times)$ est un anneau.
			\item Soient $(a,b) \in f^{-1}(B')^2$. $f$ est un morphisme d'anneau donc un morphisme de groupe de $(A,+)$ dans $(B,+)$ donc
			\begin{equation*}
				f(a - b) = \underbrace{f(a)}_{\in B'} - \underbrace{f(b)}_{\in B'} \in B'
			\end{equation*}
			Donc $a - b \in f^{-1}(B')$. \\
			De même, $f$ est un morphisme d'anneau donc un morphisme de monoïde de $(A,\times)$ dans $(B,\times)$ donc
			\begin{equation*}
				f(a b) = \underbrace{f(a)}_{\in B'} \underbrace{f(b)}_{\in B'} \in B'
			\end{equation*}
			Donc $a b \in f^{-1}(B')$.
			\item $f$ est un morphisme d'anneau donc $1_B = f(1_A)$. Or $B'$ est un sous-anneau donc $1_B \in B'$. D'où $1_A \in f^{-1}(B')$.
		\end{itemize}
	\end{question_kholle}
\pagebreak\section{Semaine 19}
\begin{question_kholle}
		[Pour une matrice $A \in \mathcal{M}_{(n,p)}(\K)$, la matrice transposée est définit :
		{\begin{equation*}
			\forall (k, l) \in [\![1,p]\!] \!\times\! [\![1,n]\!], \ \left[A^T\right]_{kl} = A_{lk}
		\end{equation*}}
		Formellement, la transposition est une application de $\mathcal{M}_{(n,p)}(\K)$ dans $\mathcal{M}_{(p,n)}(\K)$.]
		{$\left(A \times B\right)^T = B^T \times A^T$}
		
		Soit $(A, B) \in \mathcal{M}_{(n,p)}(\K) \times \mathcal{M}_{(p,q)}(\K)$. \\
		$\left(A \times B\right)^T \in \mathcal{M}_{(q,n)}(\K)$. Soit $(i, j) \in [\![1,q]\!] \!\times\! [\![1,n]\!]$.
		\begin{equation*}
			\begin{aligned}
				\left[ \left(A \times B\right)^T \right]_{i,j}
				&= \left[A \times B\right]_{j,i} \\
				&= \sum_{k=1}^{p} A_{j,k} \times_\K B_{k,i} \\
				&= \sum_{k=1}^{p} B_{k,i} \times_\K A_{j,k} \\
				&= \sum_{k=1}^{p} \left[B^T\right]_{i,k} \times_\K \left[A^T\right]_{k,j} \\
				&= \left(B^T\right) \times \left(A^T\right)
			\end{aligned}
		\end{equation*}
	\end{question_kholle}
	
	\begin{question_kholle}
		[Le symbole de Kronecker est définit de la manière suivante :
		\begin{equation*}
			\forall (x, y) \in \R^2, \delta_{xy} = \left\{ \begin{matrix}
				0 \text{ si } x \neq y \\
				1 \text{ si } x = y
			\end{matrix} \right.
		\end{equation*}
		La matrice $E^{i,j} \in \mathcal{M}(n, p)(\K)$ avec {$(i, j) \in [\![ 1, n ]\!] \!\times\! [\![ 1, p ]\!]$} ne possède que des coefficients nuls sauf le coefficient de la $i^{e}$ ligne et $j^{e}$ colonne qui vaut 1. Formellement :
		{\begin{equation*}
			\forall (r, s) \in [\![ 1, n ]\!] \times [\![ 1, p ]\!], \
			\left[E^{i,j}\right]_{rs} = \delta_{ir} \delta_{js}
		\end{equation*}}]
		{Calculer $E^{i,j} \times E^{k,l}$ en fonction de $i$, $j$, $k$, $l$ et des symboles de Kronecker}
				
		Calculons $E^{i,j}(n,p) \times E^{k,l}(p,q)$.
	 
		Soient $(r, s) \in [ \! [ 1, n] \!] \times [ \! [ 1, q ] \!]$ fq
		
		\begin{align*}
			\left[ E^{i,j} \times E^{k,l} \right] _{rs}
			& = \sum_{t = 1}^{n}E^{i,j}_{r,t} E^{k,l}_{t,s} \\
		 	& =\sum_{t = 1}^{n} \delta_{ir} \delta_{jt} \delta_{kt} \delta_{ls} \\
		 	& = \delta_{jk} \delta_{ir} \delta_{ls} \\
		 	& = \delta_{jk} \left[ E^{i,l} \right] _{rs}
		\end{align*}
		
		Donc $E^{i,j} \times E^{k,l} = \delta_{jk} E^{i,l}$.
		
		
		Ainsi, pour le calcul de $(E^{i,j})^{2}$, $q \leftarrow n$, $k \leftarrow i$, $l \leftarrow j$.
		
		\begin{align*}
			(E^{i,j})^{2} = \delta_{ji} E^{i,j} = \left\{ 
			\begin{array}{ll}
			  E^{i,j} \text{ si } i = j  \\ 
			  0_{n,p} \text{ si } i \neq j 
			\end{array}
			\right.
		\end{align*}
	
	\end{question_kholle}
	
	\begin{question_kholle}
		{Les matrices triangulaires supérieures forment un sous-anneau de $\mathcal{M}_n(\K)$}
		
		$\mathcal{T}_n^+(\K) \subset \mathcal(M)_n(\K)$ et $(\mathcal{M}_n(\K), +, \times)$ est un anneau. \\
		$\mathcal{T}_n^+(\K) \neq \emptyset$ car $I_n \in \mathcal{T}_n^+(\K)$ ($I_n$ est le neutre multiplicatif de $\mathcal{M}_n(\K)$). \\
		Soient $(A, B) \in \mathcal{T}_n^+(\K)^2$ . \\
		Soient $(i, j) \in [\![1,n]\!]^2$ $\text{ tels que }$ $i > j$.
		\begin{equation*}
			(A - B)_{i,j}
			= \underbrace{A_{i,j}}_{=0 \text{ car } A \in \mathcal{T}_n^+(\K)} - \underbrace{B_{i,j}}_{=0 \text{ car } B \in \mathcal{T}_n^+(\K)}
			= 0
		\end{equation*}
		Donc, $A - B \in \mathcal{T}_n^+(\K)$.
		
		\begin{equation*}
			\begin{aligned}
				(A \times B)_{i,j}
				&= \sum_{k=1}^{n} A_{i,k} \times_\K B_{k,j} \\
				&= \sum_{k=1}^{j} \underbrace{A_{i,k}}_{=0 \text{ car } i > j \geqslant k \text{ et } A \in \mathcal{T}_n^+(\K)} \times_\K B_{k,j}
				+ \sum_{k=j+1}^{n} A_{i,k} \times_\K \underbrace{B_{k,j}}_{=0 \text{ car } k > j \text{ et } B \in \mathcal{T}_n^+(\K)} \\
				&= 0
			\end{aligned}
		\end{equation*}
		Donc, $A \times B \in \mathcal{T}_n^+(\K)$.
	\end{question_kholle}
 
 \begin{question_kholle}
    []
    {Si $A$ est une matrice d'ordre $n$ et $\lambda$ un scalaire non nul d'un corps, alors la transposée de $A$ et $\lambda A$ sont inversibles aussi.}
    Soient $A,\lambda \in \mathcal{GL}_n(\mathbb{K})\times \mathbb{K}^*$, avec $\mathbb{K}$ un corps. \\
    Par définition, il existe $B\in \mathcal{GL}_n(\mathbb{K})$ tel que $AB=BA=I_n$. Ainsi : 
    \[
    (AB)^T = I_n^T \ \iff \ B^TA^T = I_n,
    \]
    donc $A^T$ admet un inverse à gauche, $B^T$, donc un inverse tout court et donc $A^T$ est inversible (on notera que $A^T$ reste dans les matrices d'ordre $n$). De même, 
    \[
    \lambda AB = \lambda I_n \ \iff \ (\lambda A)B = \lambda I_n \ \iff \ (\lambda A) \left(\frac{1}{\lambda}B \right) = I_n, 
    \]
    car les scalaires commutent avec toutes les matrices. Ainsi, $\lambda A$ admet un inverse à droite, donc un inverse tout court, donc est inversible, d'inverse $\frac{1}{\lambda}B$. Concluant la preuve.    
 \end{question_kholle}

 \begin{question_kholle}
    []
    {Si $N$ est une matrice d'ordre $n$ nilpotente, alors $I_n + \lambda N$ est inversible pour tout $\lambda$, scalaire d'un corps.}
    Soient $N$ une matrice d'ordre $n$ à coefficient dans $\mathbb{K}$, un corps, nilpotente, d'indice de nilpotence $k$ (un entier naturel donc) et $\lambda \in \mathbb{K}$. Calculons : 
    \[
    I_n^{2k+1} + (\lambda N)^{2k+1} = I_n^{2k+1} - (- \lambda N)^{2k+1} = (I_n + \lambda N)\sum_{i=0}^{2k}(-\lambda N)^i =  (I_n + \lambda N)\sum_{i=0}^{k-1}(-\lambda N)^i,
    \]
    car $\lambda N$ commute avec $I_n$, or le membre de gauche est égal à $I_n$ car $2k+1 > k$, donc $I_n + \lambda N$ est inversible à droite, donc inversible tout court, d'inverse $\sum_{i=0}^{k-1}(-\lambda N)^i$. Ce qui conclut la preuve.
 \end{question_kholle}
\end{document}
