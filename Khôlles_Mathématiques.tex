% Ceci est un fichier généré automatiquement.
% Ne pas le modifier directement. Exécuter $ make pour le générer.
% Il rassemble les questions de khôlles de toutes les semaines.

\documentclass{article}

\usepackage{kholles}

\begin{document}
\maketitle

\tableofcontents

\pagebreak

\begin{abstract}
Ce pdf sera vraisemblablement sujet à de nombreuses maj. Je vais essayer à partir de maintenant de faire un pdf contenant toutes les khôlles de la 6-ième semaine à la dernière (j'espère avoir le temps). De plus, il peut arriver que je propose une solution originale à une question, seulement ladite solution n'aura sans doute été vérifiée par personne, si vous constatez une ou plusieurs erreur.s tachez de m'en faire part, d'ailleurs si vous relevez une erreur quelconque dans ce document je vous prie de faire de même. Enfin, les semaines $3$ et $5$ resteront hors de ce document car leur insertion est \textbf{BEAUCOUP TROP} compliquée pour moi donc j'ai laissé tombé... Si vous les voulez, faîtes moi signe. Aussi, si plusieurs démonstrations sont présentes dans le cours et que nous avons la possiblité de choisir celle.s que nous voulons, je prendrai toujours celle.s qui me paraît.ssent la.es plus naturelle.s et "facile.s" car je n'aime pas apprendre des choses inutilement compliquées, tout comme je prendrai parfois la liberté de laisser certaines choses au lecteur car certains passages sont trop évidents pour être traités. Finalement, si vous avez des questions sur ce que j'ai écrit ou si vous voulez des informations sur le code \LaTeX   , (ou Tikz), n'hésitez pas. Bonne lecture.
\end{abstract}

%-------------------------------------------------------------

\tableofcontents

\newpage
%-------------------------------------------------------------

\section{Semaine 6} 
\label{sec:S6}

%----------------------------------------------------
\subsection{Montrer que si $f$ est impaire et bijective, alors $f^{-1}$ est aussi impaire. Donnez un/des exemples.} 

\

Soit $f: I \to F$, avec $I,F$ deux parties non-vides de $\mathbb{R}$, une telle fonction et notons $f^{-1}$ sa bijection réciproque. Si $f$ est impaire sur $I$, alors pour tout $x\in I$, $-x\in I$, ainsi $I$ est centré en $0$ et on a : 

\begin{equation*}
    \forall x \in I, \ f(-x) = -f(x).
\end{equation*}

\

Ainsi, prenons $y\in F$, alors $-y \in F$ par imparité et bijectivité de $f$. On a donc : 

\begin{eqnarray*}
f^{-1}(-y) & = & f^{-1}(-f(f^{-1}(y))) \\
           & = & f^{-1}(f(-f^{-1}(y))) \\
           & = & -f^{-1}(y).
\end{eqnarray*}

\

D'où l'imparité de $f^{-1}$.

\

Pour ce qui est de l'exemple, prenons notre fonction bijective impaire préférée, la fonction $\textstyle \sin |_{\left[ -\frac{\pi}{2}, \frac{\pi}{2}\right] }^{[-1,1]}$ que l'on notera $\widetilde{\sin}$. Sa bijection réciproque est bien entendu $\textstyle \arcsin : [-1,1] \to \left[ -\frac{\pi}{2}, \frac{\pi}{2}\right]$.

De la même manière que dans la démonstration du cas général, prenons $y\in [-1, 1]$, comme $[-1,1]$ est centré en $0$, $-y\in [-1,1]$, on a dès lors : 

\begin{eqnarray*}
\arcsin(-y) & = & \arcsin(-\widetilde{\sin}(\arcsin(y))) \\
           & = & \arcsin(\widetilde{\sin}(-\arcsin(y))) \\
           & = & -\arcsin(y).
\end{eqnarray*}

Ce qui suffit.

\

%------------------------------------------------

\subsection{Limite (et preuve) lorsque $x$ tend vers $+\infty$ de $\frac{(\ln x)^{\alpha}}{x^{\beta}}$ pour $\alpha ,\beta \in \left( \mathbb{R}_+^*\right) ^2$.} 

\

Premièrement, posons : 

\begin{equation*}
    \forall  (x,\alpha,\beta)\in [1,+\infty[ \times \left( \mathbb{R}_+^*\right) ^2, \quad  f_{\alpha,\beta}(x)=\frac{(\ln x)^{\alpha}}{x^{\beta}}.
\end{equation*}

Deuxièmement, montrons que : 
\[ \frac{\ln (x)}{x^2}\xrightarrow[n \to +\infty ]{} 0. \]

Soit $x \in [1,+\infty[ \ = \mathcal{A}$. Nous savons que la fonction $\ln$ est concave sur $\mathbb{R}_+^*$, donc en particulier sur $\mathcal{A}$. Ainsi, $\ln$ est en dessous de toutes ses tangentes, d'où : 
\[ 
\forall x \in \mathcal{A}, \quad 0 \; \leq \; \ln (x) \; \leq \; x-1.
\]

\newpage

Illustration de l'inégalité : 

\

\begin{center}
\definecolor{ttttff}{rgb}{0.2,0.2,1}
\definecolor{ffttww}{rgb}{1,0.2,0.4}
\definecolor{cqcqcq}{rgb}{0.75,0.75,0.75}
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
\draw [color=cqcqcq,dash pattern=on 1pt off 1pt, xstep=1.0cm,ystep=1.0cm] (-1,-2) grid (3,2);
\draw[->,color=black] (-1,0) -- (3,0);
\foreach \x in {-1,1,2}
\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
\draw[->,color=black] (0,-2) -- (0,2);
\foreach \y in {-2,-1,1}
\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
\clip(-1,-2) rectangle (3,2);
\draw[color=ffttww, smooth,samples=100,domain=3.244085366007135E-3:3.0] plot(\x,{ln(\x)});
\draw[color=ttttff, smooth,samples=100,domain=-1.0:3.0] plot(\x,{\x-1});
\draw (12.46,5.36) node[anchor=north west] {y = x-1};
\draw (9.62,5.22) node[anchor=north west] {y = ln(x)};
\end{tikzpicture}

\

\textbf{Figure 1.} $\ln$ en rouge et la première bissectrice en bleu. 
\end{center}

\

On peut alors diviser par $x^2$ (car $x \neq 0$): 

\

\[
\forall x \in \mathcal{A},\quad 0 \; \leq \; \underset{f_{1,2}(x)}{\underbrace{\frac{\ln (x)}{x^2}}} \; \leq \; \underset{\xrightarrow[x\to+\infty]{} \ 0}{\underbrace{\frac{1}{x}}} - \underset{\xrightarrow[x\to+\infty]{} \ 0}{\underbrace{\frac{1}{x^2}}}.
\]

\

Donc par théorème d'encadrement $f_{1,2}(x)\xrightarrow[x\to+\infty]{} 0$.

\

Dernièrement, le cas général. Soit $x\in \mathcal{A}$ et soient $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2$. On fait une preuve directe. 

\begin{eqnarray*}
    \frac{(\ln (x))^\alpha}{x^\beta} & = & \left( \frac{\ln (x)}{x^{\frac{\beta}{\alpha}}} \right)^\alpha \\[1.5ex]
    & = & \underset{\underset{\text{par produit}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{\underset{c^{\underline{te}} \ \text{(définie!)}}{\underbrace{\left( \frac{2\alpha}{\beta} \right)^\alpha}} \cdot \underset{\underset{\text{par composition des limites}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{\left[ \underset{\underset{\text{d'après le dernier point}}{\xrightarrow[x\to+\infty]{} \ 0}}{\underbrace{ \frac{\ln \left( x^{\frac{\beta}{2 \alpha}} \right) }{\left( x^{\frac{\beta}{2\alpha}} \right)^2} }}\right]^\alpha}}}}.
\end{eqnarray*}

\

Ce qui conclut.

\

%-------------------------------------------------------------

\subsection{Limite en $0$ de $\frac{1-\cos (x)}{x^2}$ et limite en $+\infty$ suivant $n$ de $\frac{\left(q^n \right)^\alpha}{(n!)^\beta}$ pour $q\in \mathbb{R}$ et $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2.$} 

\

Montrons que $\frac{1-\cos (x)}{x^2} \xrightarrow[x\to 0]{} \frac{1}{2}$.

\

On fait toujours une preuve directe. 
\begin{eqnarray*}
    \lim_{x\to0} \ \frac{1-\cos (x)}{x^2} & = & \lim_{x\to0} \ \frac{1-\cos \left( \frac{2x}{2}\right) }{x^2} \\[1ex]
    & = & \lim_{x\to0} \ \frac{1-\left( 1-2\sin ^2 \left( \frac{x}{2}\right) \right) }{x^2} \\[1ex]
    & = &  \lim_{x\to0} \ \frac{2\sin ^2 \left( \frac{x}{2}\right) }{4 \left( \frac{x}{2}\right) ^2} \\[1ex]
    & = & \lim_{x\to0} \ \underset{\underset{\text{par produit}}{\xrightarrow[x\to 0]{} \ \frac{1}{2}}}{\underbrace{\underset{c^{\underline{te}}}{\underbrace{\frac{1}{2}}} \cdot \underset{\underset{\text{par composition}}{\xrightarrow[x\to 0]{} \ 1}}{\underbrace{\left[\underset{\underset{\text{limite usuelle}}{\xrightarrow[x\to 0]{} \ 1}}{\underbrace{\frac{\sin \left( \frac{x}{2}\right) }{\left( \frac{x}{2}\right)} }} \right] ^2}}}} \\[1ex]
    & = & \frac{1}{2}
\end{eqnarray*}

\



\

Trouvons la limite, sous réserve d'existence, de $\frac{\left(q^n \right)^\alpha}{(n!)^\beta}$ pour $q\in \mathbb{R}$ et $(\alpha,\beta)\in \left( \mathbb{R}_+^* \right)^2$ suivant $n$ en $+\infty$.

\

Remarquons que si $q\leq0$, il est \textbf{\textit{nécessaire}} d'avoir $\alpha\in\mathbb{Z}^*$ sinon l'expression n'a tout simplement \textbf{\textit{aucun sens}}. De fait, on supposera $q>0$ tout le long, les cas $q<0$ se font naturellement (convergence pour $q\in \mathbb{R_-}$).

\

Soit donc $0<q<1$, ce cas est immédiat, $\left( \left(q^n \right)^\alpha\right)_{n\in\mathbb{N}}=\left( \left(q^\alpha \right)^n\right)_{n\in\mathbb{N}}$, donc il s'agit de la suite géométrique de raison $q^\alpha \in ]0,1[$ et de premier terme $q^{\min_{I}(n)\alpha}$ ($\min_{I}(n)$, avec $I$ une partie non vide de $\mathbb{N}$, car la suite ne démarre pas forcément à $0$), donc elle converge vers $0$.

\

Si $q\geq 1$, on montre le cas trivial $\alpha = \beta =1$ : 
\[
\forall n\in [\![ \lfloor q \rfloor +1,+\infty [\![, \quad 0 \leq \frac{q^n}{n!} = \underset{=\ \lambda \text{ (une constante)}}{\underbrace{\frac{q}{1} \times \frac{q}{2} \times \dots \times \frac{q}{\lfloor q \rfloor} }}\times \underset{\leq 1}{\underbrace{\frac{q}{\lfloor q\rfloor +1}}} \times \dots \times \underset{\leq1}{\underbrace{\frac{q}{n-1}}} \times \frac{q}{n} \leq \underset{\xrightarrow[n\to +\infty]{} \ 0}{\underbrace{\frac{\lambda q}{n}}}
\]

\

Par théorème d'existence de limite par encadrement, $\left( \frac{q^n}{n!} \right)_{n\in \mathbb{N}}$ converge et sa limite est $0$.

\

Soient $(\alpha,\beta)\in \mathbb{R}^*_+$, montrons le cas général pour $q\geq 1$.

\[
\forall n \in \mathbb{N}, \quad \frac{(q^n)^\alpha}{(n!)\beta} = \left( \frac{\left(q^{\frac{\alpha}{\beta}}\right)^n}{n!} \right)^\beta = \underset{\underset{\text{par composition des limites }(\beta>0)}{\xrightarrow[n\to +\infty]{} 0}}{\underbrace{\left( \underset{\underset{\text{c'est le cas trivial}}{\xrightarrow[n\to +\infty]{} 0}}{\underbrace{\frac{\left(q^{\frac{\alpha}{\beta}}\right)^n}{n!}}} \right)^\beta}}
\]

\

Ce qui termine la preuve.

\

%-------------------------------------------------------------
\subsection{Présentation exhaustive de la fonction $\arcsin$.} 

\

Premièrement, ladite fonction est la bijection réciproque de la fonction $\widetilde{\sin}$ (voir \textbf{1}.). D'où : 
\begin{center}

$\arcsin = \left\{  
\begin{array}{c c c}
[-1,1] & \to & [-\frac{\pi}{2} , \frac{\pi}{2}] \\ [1ex]
x & \mapsto & \left( \widetilde{\sin} \right)^{-1}(x)
\end{array} 
\right.
$
\end{center}

\

Ainsi, pour $x\in [-1,1]$, $\arcsin (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle \left[-\frac{\pi}{2} , \frac{\pi}{2}\right]$, $\sin(\theta) = x$. 

\

Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\sin}$ : 

\begin{enumerate}
    \item $\arcsin$ est impaire.
    \item $\arcsin$ est strictement croissante sur $[-1,1]$.
    \item $\arcsin \in \mathcal{C}^0\left([-1,1],[-\frac{\pi}{2} , \frac{\pi}{2}] \right)$.
    \item $\arcsin \in \mathcal{D}^1\left(]-1,1[,\left]-\frac{\pi}{2} , \frac{\pi}{2}\right[ \right)$.
    \item $\arcsin'(x) = \frac{1}{\sqrt{1-x^2}}$ pour tout $x\in]-1,1[$.
    \item $\arcsin$ admet deux demi-tangentes verticales en $-1$ et $1$.
\end{enumerate}

\

Graphe de $\arcsin$ : 
\begin{center}
\definecolor{ffttww}{rgb}{1,0.2,0.4}
\definecolor{ttzzff}{rgb}{0.2,0.6,1}
\definecolor{zzffzz}{rgb}{0.6,1,0.6}
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.910828025477707cm,y=1.910828025477707cm]
\draw[->,color=black] (-1.57,0) -- (1.57,0);
\foreach \x in {-1.5,-1,-0.5,0.5,1,1.5}
\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
\draw[->,color=black] (0,-1.57) -- (0,1.57);
\foreach \y in {-1.5,-1,-0.5,0.5,1,1.5}
\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
\clip(-1.57,-1.57) rectangle (1.57,1.57);
\draw[color=zzffzz] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.57:1.57]; plot sin(x)};
\draw[color=ttzzff] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-1.57:1.57]; plot asin(x)};
\draw[color=ffttww] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-1.57:1.57]; plot x};
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(--1.57-0*\x)/1});
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (1,-1.57) -- (1,1.57);
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (1.57,-1.57) -- (1.57,1.57);
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(--1-0*\x)/1});
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (-1.57,-1.57) -- (-1.57,1.57);
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt] (-1,-1.57) -- (-1,1.57);
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(-1-0*\x)/1});
\draw [line width=0.4pt,dash pattern=on 1pt off 1pt,domain=-1.57:1.57] plot(\x,{(-1.57-0*\x)/1});
\draw [->] (-1.57,-1) -- (-1.18,-1);
\draw [->] (-1,-1.57) -- (-1,-1.16);
\draw [->] (1,1.57) -- (1,1.16);
\draw [->] (1.57,1) -- (1.12,1);
\end{tikzpicture}

\

\textbf{Figure 2.} $\arcsin$ en bleu, $\widetilde{\sin}$ en vert et la première bissectrice en rouge.
\end{center}

\

On a aussi, grâce au taux d'accroissement en 0 d'$\arcsin$ : 
\[
\lim_{x\to0} \frac{\arcsin(x)}{x} \ = \ 1.
\]

\

Puis finalement (visible sur le graphe) : 
\[
\forall x \in [0,1], \quad \arcsin(x) \geq x.
\]
%-------------------------------------------------------------
\subsection{Présentation exhaustive de la fonction $\arccos$.} 

\

Premièrement, ladite fonction est la bijection réciproque de la fonction $\cos |_{[0,\pi]}^{[-1,1]} := \widetilde{\cos}$. D'où : 
\begin{center}

$\arccos = \left\{  
\begin{array}{c c c}
[-1,1] & \to & [0 , \pi] \\ [1ex]
x & \mapsto & \left( \widetilde{\cos} \right)^{-1}(x)

\end{array} 
\right.
$
\end{center}

\

Ainsi, pour $x\in [-1,1]$, $\arccos (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle [0 ,\pi]$, $\cos(\theta) = x$. 

\newpage

Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\cos}$ : 

\begin{enumerate}
    \item $\arccos$ est strictement décroissante sur $[-1,1]$.
    \item $\arccos \in \mathcal{C}^0\left([-1,1],[0 , \pi] \right)$.
    \item $\arccos \in \mathcal{D}^1\left(]-1,1[,]0 ,\pi [ \right)$.
    \item $\arccos'(x) = -\frac{1}{\sqrt{1-x^2}}$ pour tout $x\in]-1,1[$.
    \item $\arccos$ admet deux demi-tangentes verticales en $-1$ et $1$.
\end{enumerate}

\

Graphe de $\arccos$ : 
\begin{center}
\definecolor{cczzff}{rgb}{0.8,0.6,1.0}
\definecolor{qqffqq}{rgb}{0.0,1.0,0.0}
\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
\definecolor{xfqqff}{rgb}{0.4980392156862745,0.0,1.0}
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.3636363636363635cm,y=1.3636363636363635cm]
\draw[->,color=black] (-1.2,0.0) -- (3.2,0.0);
\foreach \x in {-1.0,-0.5,0.5,1.0,1.5,2.0,2.5,3.0}
\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
\draw[->,color=black] (0.0,-1.2) -- (0.0,3.2);
\foreach \y in {-1.0,-0.5,0.5,1.0,1.5,2.0,2.5,3.0}
\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
\clip(-1.2,-1.2) rectangle (3.2,3.2);
\draw[color=xfqqff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [0:3.14]; plot cos(x)};
\draw[color=ffqqqq] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-1.2:3.2]; plot x};
\draw[color=qqffqq] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-1:1]; plot acos(x)};
\draw[dotted,color=cczzff] plot[raw gnuplot, id=func3] function{set samples 100; set xrange [-1.2:3.2]; plot 3.1415926535/2.0-x};
\draw [dotted] (-1.0,0.0)-- (-1.0,3.141592653589793);
\draw [dotted] (-1.0,3.141592653589793)-- (0.0,3.141592653589793);
\draw [dotted] (0.0,1.0)-- (1.0,1.0);
\draw [dotted] (1.0,0.0)-- (1.0,1.0);
\draw [dotted] (0.0,-1.0)-- (3.141592653589793,-1.0);
\draw [dotted] (3.141592653589793,0.0)-- (3.141592653589793,-1.0);
\draw [->] (-1.0,3.141592653589793) -- (-1.0,2.6982051899765422);
\draw [->] (0.0,1.0) -- (0.41398424427733616,1.0);
\draw [->] (1.0,0.0) -- (1.0,0.41498464079523883);
\draw [->] (3.141592653589793,-1.0) -- (2.697204793458636,-1.0);
\end{tikzpicture}

\

\textbf{Figure 3.} $\arccos$ en vert, $\widetilde{\cos}$ en violet, la première bissectrice en rouge et $y = \frac{\pi}{2} - x$ en rose.
\end{center}

\

%-------------------------------------------------------------
\subsection{Présentation exhaustive de la fonction $\arctan$.} 

\

Premièrement, ladite fonction est la bijection réciproque de la fonction $\tan |_{\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ }:=\widetilde{\tan}$. D'où : 
\begin{center}

$\arctan = \left\{  
\begin{array}{c c c}
\mathbb{R} & \to & \left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \\ [1ex]
x & \mapsto & \left( \widetilde{\tan} \right)^{-1}(x)
\end{array} 
\right.
$
\end{center}

\

Ainsi, pour $x\in \mathbb{R}$, $\arctan (x)$ est l'unique solution de l'équation d'inconnue $\theta \in \textstyle \left] -\frac{\pi}{2}, \frac{\pi}{2}\right[$, $\tan(\theta) = x$. 

\

Il découle alors naturellement des propriétés héréditairement acquises de $\widetilde{\tan}$ : 

\begin{enumerate}
    \item $\arctan$ est impaire.
    \item $\arctan \in \mathcal{C}^0\left(\mathbb{R},\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \right)$.
    \item $\arctan \in \mathcal{D}^1\left(\mathbb{R},\left] -\frac{\pi}{2}, \frac{\pi}{2}\right[ \right)$.
    \item $\arctan'(x) = \frac{1}{1+x^2}$ pour tout $x\in\mathbb{R}$.
\end{enumerate}

\newpage

Graphe de $\arctan$ : 
\begin{center}
\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
\definecolor{qqffqq}{rgb}{0.0,1.0,0.0}
\definecolor{qqffff}{rgb}{0.0,1.0,1.0}
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
\draw[->,color=black] (-3.0,0.0) -- (3.0,0.0);
\foreach \x in {-3.0,-2.5,-2.0,-1.5,-1.0,-0.5,0.5,1.0,1.5,2.0,2.5}
\draw[shift={(\x,0)},color=black] (0pt,2pt) -- (0pt,-2pt) node[below] {\footnotesize $\x$};
\draw[->,color=black] (0.0,-3.0) -- (0.0,3.0);
\foreach \y in {-3.0,-2.5,-2.0,-1.5,-1.0,-0.5,0.5,1.0,1.5,2.0,2.5}
\draw[shift={(0,\y)},color=black] (2pt,0pt) -- (-2pt,0pt) node[left] {\footnotesize $\y$};
\draw[color=black] (0pt,-10pt) node[right] {\footnotesize $0$};
\clip(-3.0,-3.0) rectangle (3.0,3.0);
\draw[color=qqffff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.56:1.56]; plot tan(x)};
\draw[color=qqffqq] plot[raw gnuplot, id=func1] function{set samples 100; set xrange [-3:3]; plot atan(x)};
\draw[color=ffqqqq] plot[raw gnuplot, id=func2] function{set samples 100; set xrange [-3:3]; plot x};
\draw [domain=-3.0:3.0] plot(\x,{(--1.5707963267948966-0.0*\x)/1.0});
\draw (1.5707963267948966,-3.0) -- (1.5707963267948966,3.0);
\draw [domain=-3.0:3.0] plot(\x,{(-1.5707963267948966-0.0*\x)/1.0});
\draw (-1.5707963267948966,-3.0) -- (-1.5707963267948966,3.0);
\draw [dotted] (0.7853981633974483,1.0)-- (0.7853981633974483,0.0);
\draw [dotted] (0.0,0.7853981633974483)-- (1.0,0.7853981633974483);
\draw [dotted] (0.0,1.0)-- (1.0,1.0);
\draw [dotted] (1.0,0.0)-- (1.0,1.0);
\draw [dotted] (-1.0,0.0)-- (-1.0,-1.0);
\draw [dotted] (0.0,-1.0)-- (-1.0,-1.0);
\draw [dotted] (-0.7853981633974483,0.0)-- (-0.7853981633974483,-1.0);
\draw [dotted] (0.0,-0.7853981633974483)-- (-1.0,-0.7853981633974483);
\begin{scriptsize}
\draw[color=qqffff] (-3.1177254400173355,-0.014744648606977613) node {$f$};
\draw[color=qqffqq] (-3.1177254400173355,-1.3072326284088318) node {};
\draw[color=ffqqqq] (-1.8026940652189338,-1.8332451783281911) node {};
\draw[color=black] (-3.1177254400173355,1.5106917461591645) node {$a$};
\draw[color=black] (1.4660982092799508,2.322253966034747) node {};
\draw[color=black] (-3.1177254400173355,-1.4500074633869435) node {$c$};
\draw[color=black] (-1.4946010002661654,2.322253966034747) node {};
\end{scriptsize}
\end{tikzpicture}

\

\textbf{Figure 4.} $\arctan$ en vert, $\widetilde{\tan}$ en bleu, la première bissectrice en rouge, et les fonctions $y = \pm \frac{\pi}{2}$ et $x = \pm \frac{\pi}{2}$ en noir.
\end{center}

\

On a aussi (visible sur le graphe) : 
\[
\forall x \in \mathbb{R}_+, \quad \arctan(x) \leq x.
\]

Et enfin : 
\[
\forall x \in \mathbb{R}^*, \quad \arctan(x) + \arctan \left( \frac{1}{x} \right) = 
\left\{ \begin{array}{cl}
\frac{\pi}{2} & \text{si } x \ > \ 0 \\
-\frac{\pi}{2} & \text{si } x \ < \ 0.
\end{array} \right.
\]

\

Ce qui conclut les présentations exhaustives.

\

%-------------------------------------------------------------
\subsection{$2$ preuves de $\arcsin(x) + \arccos(x) =\frac{\pi}{2}$ sur $[-1,1]$, dont une basée sur une interprétation géométrique du cercle trigonométrique.} 

\

L'interprétation géométrique sur $[0,1]$, celle sur $[-1,0]$ est laissée au lecteur car il s'agit du même principe modulo des détails : 

\begin{center}
\definecolor{eqbqff}{rgb}{0.8784313725490196,0.6901960784313725,1.0}
\definecolor{xfqqff}{rgb}{0.4980392156862745,0.0,1.0}
\definecolor{uuuuuu}{rgb}{0.26666666666666666,0.26666666666666666,0.26666666666666666}
\definecolor{ffqqqq}{rgb}{1.0,0.0,0.0}
\definecolor{qqffff}{rgb}{0.0,1.0,1.0}
\definecolor{cqcqcq}{rgb}{0.7529411764705882,0.7529411764705882,0.7529411764705882}
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=2.5cm,y=2.5cm]
\clip(-1.2,-1.2) rectangle (1.2,1.2);
\fill[fill=black,fill opacity=1.0] (0.08956860342780414,0.20707624336357297) -- (0.08145277478981197,0.18983010750783963) -- (0.0742401101509475,0.2039730262575521) -- cycle;
\fill[fill=black,fill opacity=1.0] (0.3604343842207928,0.11272973544691409) -- (0.3441578360574464,0.12526320821437803) -- (0.33811585546631434,0.10562838538867093) -- cycle;
\draw [color=cqcqcq] (0.0,0.0) circle (2.5cm);
\draw [shift={(0.0,0.0)},line width=1.2000000000000002pt,color=qqffff]  plot[domain=0.0:3.141592653589793,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
\draw [shift={(3.061616997868383E-17,0.0)},line width=1.2000000000000002pt,color=ffqqqq]  plot[domain=-1.5707963267948966:1.5707963267948963,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
\draw [shift={(0.0,-0.0)},line width=1.2000000000000002pt,color=xfqqff]  plot[domain=0.0:1.5707963267948966,variable=\t]({1.0*1.0*cos(\t r)+-0.0*1.0*sin(\t r)},{0.0*1.0*cos(\t r)+1.0*1.0*sin(\t r)});
\draw [line width=1.2000000000000002pt,color=qqffff] (-1.0589461703485412,0.0)-- (-0.9410538296514588,0.0);
\draw [line width=1.2000000000000002pt,color=qqffff] (1.0589461703485412,0.0)-- (0.9410538296514588,0.0);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,1.0589461703485412)-- (5.762292801540088E-17,0.9410538296514588);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (-1.945252556980033E-16,-1.0589461703485412)-- (-1.7286878404620264E-16,-0.9410538296514588);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,1.0589461703485412)-- (0.05398708109469719,1.0589461703485412);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (5.762292801540088E-17,0.9410538296514588)-- (0.05398708109469719,0.9410538296514588);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (6.484175189933444E-17,-1.0589461703485412)-- (0.05398708109469719,-1.0589461703485412);
\draw [line width=1.2000000000000002pt,color=ffqqqq] (5.762292801540088E-17,-0.9410538296514588)-- (0.05398708109469719,-0.9410538296514588);
\draw [line width=1.2000000000000002pt,color=qqffff] (-1.0589461703485412,1.2968350379866888E-16)-- (-1.0589461703485412,0.05398708109469725);
\draw [line width=1.2000000000000002pt,color=qqffff] (-0.9410538296514588,1.1524585603080177E-16)-- (-0.9410538296514588,0.05398708109469724);
\draw [line width=1.2000000000000002pt,color=qqffff] (0.9410538296514588,1.1524585603080177E-16)-- (0.9410538296514588,0.05398708109469724);
\draw [line width=1.2000000000000002pt,color=qqffff] (1.0589461703485412,1.2968350379866888E-16)-- (1.0589461703485412,0.05398708109469725);
\draw [dash pattern=on 1pt off 1pt on 3pt off 4pt] (6.123233995736766E-17,1.0)-- (0.0,-1.0);
\draw [dash pattern=on 1pt off 1pt on 3pt off 4pt] (-1.0,0.0)-- (1.0,-0.0);
\draw[color=eqbqff] plot[raw gnuplot, id=func0] function{set samples 100; set xrange [-1.0999999999999999:1.0999999999999999]; plot x};
\draw (0.3420201433256688,0.9396926207859083)-- (0.0,-0.0);
\draw (0.0,-0.0)-- (0.9396926207859084,0.3420201433256687);
\draw [shift={(0.0,-0.0)}] plot[domain=0.0:0.3490658503988659,variable=\t]({1.0*0.36624511935574344*cos(\t r)+-0.0*0.36624511935574344*sin(\t r)},{0.0*0.36624511935574344*cos(\t r)+1.0*0.36624511935574344*sin(\t r)});
\draw [shift={(0.0,-0.0)}] plot[domain=0.0:1.2217304763960306,variable=\t]({1.0*0.21706356072793254*cos(\t r)+-0.0*0.21706356072793254*sin(\t r)},{0.0*0.21706356072793254*cos(\t r)+1.0*0.21706356072793254*sin(\t r)});
\draw (0.08956860342780414,0.20707624336357297)-- (0.08145277478981197,0.18983010750783963);
\draw (0.08145277478981197,0.18983010750783963)-- (0.0742401101509475,0.2039730262575521);
\draw (0.0742401101509475,0.2039730262575521)-- (0.08956860342780414,0.20707624336357297);
\draw (0.3604343842207928,0.11272973544691409)-- (0.3441578360574464,0.12526320821437803);
\draw (0.3441578360574464,0.12526320821437803)-- (0.33811585546631434,0.10562838538867093);
\draw (0.33811585546631434,0.10562838538867093)-- (0.3604343842207928,0.11272973544691409);
\draw [dash pattern=on 3pt off 3pt] (5.938595898438009E-17,0.9396926207859083)-- (0.3420201433256688,0.9396926207859083);
\draw [dash pattern=on 3pt off 3pt] (4.108751682287631E-17,0.34202014332566877)-- (0.9396926207859084,0.3420201433256687);
\draw [dash pattern=on 3pt off 3pt] (0.3420201433256688,0.9396926207859083)-- (0.3420201433256688,-0.0);
\draw [dash pattern=on 3pt off 3pt] (0.9396926207859084,0.3420201433256687)-- (0.9396926207859084,-0.0);
\draw (0.3106196735830377,0.20690669566269085) node[anchor=north west] {arccos(x)};
\draw (0.06201603682796799,0.3536235960427321) node[anchor=north west] {arcsin(x)};
\draw (-0.18658759992710172,0.9853213615679096) node[anchor=north west] {x};
\draw (0.8241288249131816,0.0031332229126335774) node[anchor=north west] {x};
\begin{scriptsize}
\draw [fill=uuuuuu] (0.0,-0.0) circle (1.5pt);
\draw[color=uuuuuu] (-0.011342413362052578,0.09279355092265877) node {$\Omega$};
\draw [fill=uuuuuu] (5.938595898438009E-17,0.9396926207859083) circle (1.5pt);
\draw [fill=uuuuuu] (0.9396926207859084,-0.0) circle (1.5pt);
\end{scriptsize}
\end{tikzpicture}

\

\textbf{Figure 5.}
\end{center}

\

Preuve formelle : 

\

Soit $x\in [-1,1]$. Posons  $\varphi \ = \ \arcsin(x) \in \left[-\frac{\pi}{2},\frac{\pi}{2}\right]$. Ainsi : 

\[
\arcsin(x) + \arccos(x) \ = \ \varphi + \arccos(\sin(\varphi)) \ = \ \varphi + \arccos \left( \cos \left( \frac{\pi}{2}- \varphi \right) \right),
\]

\

or $\varphi \in \left[-\frac{\pi}{2},\frac{\pi}{2}\right]$ donc
$\frac{\pi}{2}- \varphi \in [0,\pi]$ d'où $\arccos \left( \cos \left( \frac{\pi}{2}- \varphi \right) \right) = \frac{\pi}{2}- \varphi$ si bien que : 
\[
\arcsin(x) + \arccos(x) \ = \  \varphi +\frac{\pi}{2} - \varphi \ = \ \frac{\pi}{2}.
\]

\

%------------------------------------------------------------
\subsection{Présentation analytique rapide des fonctions \(\cosh\) et \(\sinh \).} 

\

$\bullet$ Domaine de définition et symétries.
\newline
$\sinh$ et $\cosh$ sont définies sur $\mathbb{R}$. 
\newline
De plus, 
\newline
$(i)$ $\forall x \in \mathbb{R}$, $-x\in \mathbb{R}$, 
\newline
$(ii)$ $\forall x \in \mathbb{R}$, 
$
\left\{ \begin{array}{c c c c c c c}
\sinh (-x) & = & \frac{e^{-x} - e^{x}}{2} & = & - \frac{e^x - e^{-x}}{2} & = & -\sinh(x) \\
\text{et} & & & & & & \\ 
\cosh (-x) & = & \frac{e^{-x} + e^{-(-x)}}{2} & = &  \frac{e^x + e^{-x}}{2} & = & \cosh(x).
\end{array} 
\right.
$
\newline
Donc $\sinh$ et $\cosh$ sont respectivement impaire et paire.
\newline
Nous les étudierons sur $\mathbb{R}_+$ et pour les obtenir les graphes $(\mathcal{C}_{\sinh} \text{ et } \mathcal{C}_{\cosh})$ de ces fonctions sur $\mathbb{R}$ à partir de ceux $(\mathcal{C}_{\sinh}^+ \text{ et } \mathcal{C}_{\cosh}^+)$ obtenus sur $\mathbb{R}_+$, nous le complèterons en traçant les images de ces graphes par la symétrie centrale $s$ de centre $O$ et par la réflexion $r$ d'axe $\left( O, \overrightarrow{\jmath} \right)$ : 
\[
\mathcal{C}_{\sinh} = \mathcal{C}_{\sinh}^+ \cup s \left( \mathcal{C}_{\sinh}^+ \right) \qquad \text{ et } \qquad \mathcal{C}_{\cosh} = \mathcal{C}_{\cosh}^+ \cup r \left( \mathcal{C}_{\cosh}^+ \right)
\]

\

$\bullet$ Variations : triviales.

\

$\bullet$ Branches infinies en $+\infty$ et position relative de $\mathcal{C}_{\sinh}$ et $\mathcal{C}_{\cosh}$.

\[
\frac{\cosh(x)}{x} = \underset{\xrightarrow[x\to +\infty]{} \ +\infty}{\underbrace{\frac{e^{x}}{x}}} + \underset{\xrightarrow[x\to +\infty]{} \ 0}{\underbrace{\frac{e^{-x}}{x}}} \xrightarrow[x\to +\infty]{} \ +\infty
\]
Donc le graphe de $\cosh$ admet une branche parabolique de direction asymptotique $\left( O, \overrightarrow{\jmath}\right)$.
\newline
On a : 
\[
\forall x \in \mathbb{R}, \quad \cosh(x) - \sinh(x) = e^{-x} \xrightarrow[x\to +\infty]{} 0^+
\]
Donc les graphes des deux fonctions se rapprochent l'un de l'autre arbitrairement près lorsque $x \to +\infty$, et le graphe de $\cosh$ est au-dessus de celui de $\sinh$.

\

$\bullet$ Tangente au graphe de $\sinh$ à l'origine et position relative.
\newline
Cette étude est aussi triviale, il s'agira d'étudier $g : x\in \mathbb{R}_+ \mapsto \sinh(x) -x$, de remarquer sa dérivabilité d'en étudier les variations puis de conclure, en précisant que cette étude révèle l'inflexion du graphe de $\sinh$ en 0.
%-------------------------------------------------------------

\section{Semaine 7} 
\label{sec:S7}

%----------------------------------------------------------------

\section{Semaine 8} 
\label{sec:S8}

%----------------------------------------------------------------

\section{Semaine 9} 
\label{sec:S9}

%-----------------------------------------------------------------

\section{Semaine 10} 
\label{sec:S10}

%---------------------------------------------------------------

\section{Semaine 11} 
\label{sec:S11}

%-------------------------------------------------------------

\section{Semaine 12} 
\label{sec:S12}

%-------------------------------------------------------------

\section{Semaine 13} 
\label{sec:S13}

%----------------------------------------------------------------

\section{Semaine 14} 
\label{sec:S14}

%----------------------------------------------------------------

\section{Semaine 15} 
\label{sec:S15}

%----------------------------------------------------------------

\section{Semaine 16} 
\label{sec:S16}



Aucune démo de ce document n'apparait au programme de Khôlle \verb|T_T|

\section{Calcul de $\int_0^{2\pi}e^{imt}dt$ en fonction de $m \in \Z$. En Déduire qu'une fonction polynomiale nulle sur un cercle centré en l'origine a tous ses coefficients nuls.}

\begin{proof}
	Soit $m \in \Z$ fq. Calculons:
	$$\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt$$
	Si $m \neq 0$:
	\begin{align*}
		\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt &= \frac{1}{2 \pi} \Big[ \frac{e^{mt}}{im} \Big]_0^{2\pi}\\
		&= \frac{1}{2 \pi} \Big( \frac{1}{im} - \frac{1}{im} \Big) = 0
	\end{align*}
	Si $m = 0$:
	$$
		\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt = \frac{1}{2 \pi} \int_0^{2\pi}dt = \frac{2 \pi}{2 \pi} = 1
	$$
	\\
	Donc $$\frac{1}{2 \pi} \int_0^{2\pi}e^{imt}dt = 
	\begin{cases}
		1 \text{ si } m=0\\
		0 \text{ si } m \neq 0
	\end{cases}
	$$
	\\
	Soit $n\in \N$ fq
	
	Soient $(a_0, ..., a_n) \in \C^{n+1}$ les coefficients de $P(z) = \sum_{k=0}^n a_k z^k$, et $s\in \Z$, et $r \in \R_+^*$ fq. tels que P soit nulle lorsqu'elle est évaluée sur $\mathscr C(0,r)$
	\begin{align*}
		\frac{1}{2 \pi} \int_0^{2\pi} P(re^{it}) e^{-imt}dt &= \frac{1}{2 \pi} \int_0^{2\pi} \bigg (\sum_{k=0}^n a_k (re^{it})^k \bigg) e^{-imt}dt\\
		&= \sum_{k=0}^n a_k r^k \underbrace{\int_0^{2\pi} \frac{e^{it(k-s)}}{2 \pi} dt}_{I_k}
	\end{align*}
	On remarque que:
	\begin{itemize}
	\item Si $s \notin [[0, n]], \{k \in [[0, n]] \text{ }| \text{ } k = s\}$ = $\emptyset$, Donc $$\sum_{k \in [[0, n]]} a_k s^k I_k  = \sum_{\substack{k \in [[0, n]] \\ k = s}} a_k r^k  = 0$$
	\item Si $s \in [[0, n]], \{k \in [[0, n]] \text{ }| \text{ } k = s\}$ = ${s}$, Donc $$\sum_{k \in [[0, n]]} a_k s^k I_k = \sum_{\substack{k \in [[0, n]] \\ k = s}} a_k s^k = a_s r^s \label{1}$$
	\end{itemize}
	Or, puisque $P$ s'annule sur le cercle de rayon $r$ et de centre $0$,  $\mathscr C(0,r)$, ces sommes sont aussi nulles. On en déduit, en particularisant pour un $s \in [[0, n]]$ fixé quelconque que:
	$$
	\sum_{k \in [[0, n]]} a_k s^k I_k = a_sr^s = 0 \implies a_s = 0
	$$
	
	Donc $$
	(\exists r \in \R_+^* : \forall \theta \in \R, P(re^{i\theta})=0) \implies \forall s \in [[0, n]]
	$$
	\\
	Pour la preuve réciproque,  soit $n \in \N$ fq. Soient $(a_0,...,a_n) \in \{ 0 \} ^{n+1}$ les coefficients nuls de la fonction polynomiale $P \in \C[z]$ définie pour tout $z \in \C$.
	
	En remarquant que $\forall z \in \C , P(z) = 0$, puisque n'importe quel cercle centré en 0 est un sous ensemble de $\C$,  $\exists r \in \R_+^*: \forall z \in \mathscr C(0, r), P(z) = 0$.
\end{proof}

\section{Preuve de la Linéarité de la dérivation d'une fonction complexe}
\begin{proof}
	
Définissons les fonctions $f_r$ etc. comme les parties réelles et imaginaires de $f$ 

Soient $(f, g) \in \mathcal{F}(I, \C)^2$, $(\alpha, \beta) \in \C^2$ fixés quelconques.
\begin{align*}
	f_r = \Re(f) &, f_i = \Im(f) &g_r = \Re(f) &, g_i = \Im(g)\\
	\alpha_r = \Re(\alpha) &, \alpha_i = \Im(f) &\beta_r = \Re(f) &, \beta_i = \Im(g)
\end{align*}

\begin{align*}
	\Re( \alpha f + \beta g) &= \Re((\alpha_r + i \alpha_i)(f_r + i f_i) + (\beta_r+ i\beta_i)(g_r+ i g_i)) \\
	&= \underbrace{\alpha_r f_r + \beta_r g_r - \alpha_i f_i - \beta_i g_i}_{\text{Combinaison linéaire de } \underbrace{(f_r, f_i, g_r, g_i) \in \mathcal D^1(I, \R)^4}_{car (f,g) \in D^1(I, \R)^2}}
\end{align*}
Donc, selon le théorème de stabilité par combinaison linéaire des fonctions à valeurs réelles, $\Re(\alpha f + \beta g) \in \mathcal D^1(I, \R)$ et $\big(\Re(\alpha f + \beta g)\big)' = \alpha_r f_r' + \beta_r g_r' - \alpha_i f_i' - \beta_i g_i'$
\\
On montre de même que $\Im(\alpha f + \beta g) \in \mathcal D^1(I, \R)$ et $\big(\alpha f + \beta g\big)' = \alpha_r f_i' +\alpha f_r' +\beta_r g_i' +\beta_i g_r'$

Ainsi,
\begin{align*}
	\big( \alpha f + \beta g \big)' &= (\alpha_r f_r' + \beta_r g_r' - \alpha_i f_i' - \beta_i g_i') + i (\alpha_r f_i' +\alpha f_r' +\beta_r g_i' +\beta_i g_r') \\
	&= \alpha_r(f_r' + if_i') + \beta_r(g_r' + ig_i') + \alpha_i \underbrace{(-f_i' + if_r')}_{i(f_r' + if_i')} + \beta_i \underbrace{( -g_i' + ig_r')}_{i(g_r' + ig_i')} \\
	&=\alpha f' + \beta g'
\end{align*}

\end{proof}
\section{Dérivée composée d'une fonction à valeurs complexes}
\begin{proof}
Soient $f \in \mathcal D ^1(J, \C) $ et $h \in \mathcal D^1(I, J)$ (I et J sont deux intervalles réels) fixés quelconques. Notons $f_r$ et $f_i$ respectivement la partie réelle et imaginaire de $f$.

\begin{align*}
	\left .
	\begin{array}{ll}
		h \in \mathcal D^1(I, J) \\
		f_r \in \mathcal D^1(J, \R) \text{, car } f \in \mathcal D^1(J, \C)
	\end{array}
	\right \}
	\implies f_r \circ h \in \mathcal D^1(I, \R)
\end{align*}

On montre de même que $f_i \circ h \in \mathcal D^1(I, \mathbb  R)$ donc $f \circ h \in \mathcal D^1(I, \C)$.

De plus,

\begin{align*}
	(f \circ h)' &= (f_r \circ h)' + i (f_i \circ h)' \\
	&= (f_r' \circ h ) \times h' + i((f_i' \circ h) \times h')\\
	&=(f_r' \circ h + if_i' \circ h) \times h' = (f' \circ h) \times h'
\end{align*}
\end{proof}
\section{Caractérisation des fonctions dérivables de dérivée nulle sur un intervalle}
\begin{proof}
Soit $f \in \mathcal D ^1 (I, \C)$ où $I$ est un intervalle réel;
Posons $f_r = \Re (f)$ et $f_i = \Im(f)$.

\begin{align*}
\forall t \in I, f'(t) = 0 &\iff \forall t \in I, f_r'(t) + i f_i'(t) = 0 \\
&\iff \begin{cases}
	\forall t \in I, f_r'(t) = 0 \\
	\forall t \in I, f_i'(t) = 0
\end{cases} \\
&\iff \begin{cases}
	\exists \lambda_r \in \R : \forall t \in I,  f_r(t) = \lambda_r \\
		\exists \lambda_i \in \R : \forall t \in I,  f_i(t) = \lambda_i
\end{cases} \\
&\iff \exists \lambda \in \C : \forall t \in I,  f(t) = \lambda
\end{align*}
\end{proof}

\begin{equation}
\int_{-\infty }^{+\infty} e^{-x^2}dx = \sqrt{\pi}.
\end{equation}


\flushleft

\begin{question_kholle}{Preuve de l’expression des solutions réelles des EDL homogènes d’ordre 2 à coefficients constants réels dans le cas $\Delta < 0$ (en admettant la connaissance de l’expression des solutions à valeurs complexes des EDLH2 à coeff. constants).}
	Notons $\Sol_{H, \C}$ et $\Sol_{H, \R}$ les ensembles des solutions complexes et réelles de l'équation différentielle, puisque nous nous plaçons dans le cas $\Delta = 0$ et $\alpha \pm i \beta$ les deux racines complexes conjuguées.
	$$
	\Sol_{H, \C} = 
	\left\{ 
	\begin{array}{l}
    \R \to \C  \\
    t \mapsto \lambda e^{(\alpha + i \beta) t}  + \mu e^{(\alpha - i \beta)t}
  \end{array}
	\middle\vert  (\lambda, \mu) \in \C ^2 \right\}	
	$$
	
	Montrons que $\forall f \in \Sol_{H ,\C}, \Re(f) \in  \Sol_{H ,\R}$\\
	Soit $f \in \Sol_{H ,\C}$ fq.
	$$f \in \mathcal D^2(\R, \C) \implies \Re(f) \in \mathcal D^2(\R, \R)$$
	Et, de plus, par morphisme additif de \Re
	$$
	a_2\Re(f)'' + a_1\Re(f)' + a_0\Re(f) = \Re( a_2 f'' + a_1 f' + a_0 f) = 0
	$$
	D'où, avec $f:t \mapsto e^{(\alpha + i \beta)t}$; $\Re(f(t)) = \Re(e^{(\alpha + i \beta)t}) = e^{\alpha t } \cos (\beta t)$. Qui appartient donc à $\Sol_{H, \R}$\\
	En suivant le même raisonnement pour $\Im(f)$, $(t \mapsto e^\alpha \sin(\beta t)) \in \Sol_{H, \R}$
	
	
	Ainsi, par combinaison linéaire (qui se base sur le principe de superposition),
	$$
	\left\{ 
	\begin{array}{l}
    \R \to \R  \\
    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
  \end{array}
	\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
	\subset \Sol_{H ,\R}
	$$
	
	Réciproquement, soit $ f \in \Sol_{H ,\R}$ fq. Puisque $\R \subset \C$,  $ f \in \Sol_{H ,\C}$.
	
	$$
	\exists (a, b) \in \C^2 : f \left| \begin{array}{l}
    \R \to \C  \\
    t \mapsto a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t}
	\end{array}\right.$$

	Or, puisque toutes les valeurs de $f$ sont réelles, en notant $(a_r, a_i, b_r, b_i)$ les parties réelles et imaginaires respectives de $a$ et $b$.
	\begin{align*}
		\forall t \in \R, f(t) &= \Re(f(t)) \\
				&= \Re(a e^{(\alpha + i \beta) t}  + b e^{(\alpha - i \beta)t})\\
				&= \Re((a_r + i a_i) e^{(\alpha + i \beta) t}  + (b_r + i b_i) e^{(\alpha - i \beta)t})\\
			    &= a_r \cos(\beta t)e^\alpha - a_i\sin(\beta t)e^\alpha + b_r \cos(\beta t)e^\alpha + b_i \sin(\beta t) e^\alpha \\
			    &= (a_r + b_r) \cos(\beta t) e^\alpha + (b_i - a_i) \sin(\beta t) e^\alpha
	\end{align*}
	Ainsi,
	$$f\in \left\{ 
	\begin{array}{l}
    \R \to \R  \\
    t \mapsto \lambda e^{\alpha t } \cos (\beta t)   + \mu e^{\alpha t } \sin (\beta t)
  \end{array}
	\middle\vert  (\lambda, \mu) \in \R ^2 \right\}
$$
Ce qui conclut la preuve par double inclusion.
\end{question_kholle}

\begin{question_kholle}[
	Considérons le problème de Cauchy suivant :
	$$\left\{ \begin{array}{l}
		a_{2}y''+a_{1}y'+a_{0}y = b \text{ sur } J  \\
		y(t_{0}) = \alpha_{0} \\
		y'(t_{0}) = \alpha_{1}
	\end{array} \right. \text{ où } (\alpha_{0}, \alpha_{1}) \in \mathbb{K}^{2}, t_{0} \in J, (a_{0}, a_{1}, a_{2}) \in \mathbb{K}^{2} \times \mathbb{K}^{*}, b \in \mathcal{F}(J, \mathbb{K})$$
	Si $b$ est continu sur $J$, alors ce problème de Cauchy admet une unique solution définie sur $J$.
	]
	{Existence et unicité d'une solution au problème de Cauchy pour les EDL d'ordre 2 à coefficients constants et second membre continu sur $I$ (cas complexe puis cas réel).}
 
\textbf{Cas 1. } $\mathbb{K} = \mathbb{C}$ \\
Nous savons que sous l'hyphothèse de continuité de $b$ sur $J$, les solutions de (EDL2) définies sur $J$ constituent le plan affine $S$ :
$$S = \left\{ \lambda f_{1} + \mu f_{2} + s | (\lambda, \mu) \in \mathbb{C}^{2} \right\}$$
où $s$ est une solution particulière de (EDL2), $(f_{1}, f_{2})$ sont deux solutions de (EDLH2) qui engendrent $S_{h}$. On a : \\

$$\begin{array}{ccl}
    f : J \to \mathbb{C} \text{ est sol. du pb de Cauchy } 
    &\iff &\left\{ \begin{array}{l}
      f \text{ sol de (EDL2) sur } J    \\
      f(t_{0}) = \alpha_{0}    \\
      f'(t_{0}) = \alpha_{1}
    \end{array}  \right. \\\\
    &\iff &\left\{ \begin{array}{l}
      f \in S    \\
      f(t_{0}) = \alpha_{0}    \\
      f'(t_{0}) = \alpha_{1}
    \end{array}\right. \\\\
    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
      f = \lambda f_{1} + \mu f_{2} + s \\
      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) + s(t_{0}) = \alpha_{0} \\
      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) + s'(t_{0}) = \alpha_{1} \\
    \end{array} \right. \\\\
    &\iff &\exists (\lambda, \mu) \in \mathbb{C}^{2}: \left\{ \begin{array}{l}
      f = \lambda f_{1} + \mu f_{2} + s \\
      \lambda f_{1}(t_{0}) + \mu f_{2}(t_{0}) = \alpha_{0} - s(t_{0}) \\
      \lambda f'_{1}(t_{0}) + \mu f'_{2}(t_{0}) = \alpha_{1} - s'(t_{0}) \\
    \end{array} \right. \\\\
\end{array} $$
On en déduit donc que $(\lambda, \mu)$ doit être solution d'un système linéaire $(2,2)$. On a une unique solution si et seulement si les déterminant de ce système est nul. \\
Explicitons alors le déterminant de ce système, que l'on notera $D$.
$$D = \left| 
\begin{array}{cc}
f_{1}(t_{0}) &f_{2}(t_{0}) \\
f'_{1}(t_{0}) &f'_{2}(t_{0}) \\
\end{array}
\right| = f_{1}(t_{0}) \cdot f'_{2}(t_{0}) - f_{2}(t_{0}) \cdot f'_{1}(t_{0}) $$
Notons $\Delta$ le discriminant de l'équation caractéristique de (EDL2) ($a_{2}r^{2} + a_{1}r^{1} + a_{0} = 0$). On distingue alors deux cas selon la nullité ou non de $\Delta$. Traitons d'abord le cas $\Delta \neq 0$. On peut choisir : 
$$ f_{1}(t_{0}) = e^{r_{1}t_{0}} \text{ et } f_{2}(t_{0}) = e^{r_{2}t_{0}}$$
$$ f'_{1}(t_{0}) = r_{1}e^{r_{1}t_{0}} \text{ et } f'_{2}(t_{0}) = r_{2}e^{r_{2}t_{0}}$$
Donc (en sachant que $\Delta \neq 0 \Rightarrow r_{1} \neq r_{2}$):
$$ D = e^{r_{1}t_{0}} \cdot r_{2}e^{r_{2}t_{0}} - r_{1}e^{r_{1}t_{0}} \cdot e^{r_{2}t_{0}} = (r_{2} - r_{1}) \cdot e^{r_{1}t_{0} + r_{2}t_{0}} \neq 0$$

Dans le deuxième cas, on a $\Delta = 0$ ; on peut alors prendre :
$$ f_{1}(t_{0}) = e^{r_{0}t_{0}} \text{ et } f_{2}(t_{0}) = t_{0}e^{r_{0}t_{0}}$$
Ainsi : 
$$ D = e^{r_{0}t_{0}} \left(r_{0}t_{0}e^{r_{0}t_{0}} + e^{r_{0}t_{0}} \right) - r_{0}e^{r_{0}t_{0}} \times t_{0}e^{r_{0}t_{0}} = e^{2r_{0}t_{0}} \neq 0$$
On remarque alors que, dans les deux cas, $D \neq 0$, donc le système $(2, 2)$ étudié admet une unique solution, donc il existe un unique couple $(\lambda, \mu)$ le vérifiant d'où l'unicité et existence d'une solution au problème de Cauchy. 
\newline\newline

\textbf{Cas 2. } $\mathbb{K} = \mathbb{R}$ \\
$(a_{0}, a_{1}, a_{2}) \in \mathbb{R}^{2} \times \mathbb{R}^{*},(\alpha_{0}, \alpha_{1}) \in \mathbb{R}^{2}, b \in C^{0}(J, \mathbb{R})$ 
\newline
\textbf{Existence :} Puisque $\mathbb{R} \subset \mathbb{C}$, le problème de Cauchy admet, dans $\mathbb{R}$, une solution à valeurs complexes $g$. Posons $f = \Re(g)$ et montrons que $f$ est une solution réelle du problème de Cauchy. \\
\begin{itemize}
    \item[$\star$] $g \in \mathcal{D}^{2}(J, \mathbb{C}) \text{ donc } f \in \mathcal{D}^{2}(J, \mathbb{R})$
    \item[$\star$] $g$ vérifie $a_{2}g'' + a_{1}g' + a_{0}g = b$ sur $J$ donc en prenant $\Re(\cdot)$ : 
    $$\begin{array}{ccl}
      \Re(a_{2}g'' + a_{1}g' + a_{0}g = b) = \Re(b)   
      &\iff &a_{2}\Re(g'') + a_{1}\Re(g') + a_{0}\Re(g) = b  \\\\
      &\iff & a_{2}f'' + a_{1}f' + a_{0}f = b \text{ sur } J
    \end{array}$$
    \item[$\star$] $f(t_{0} = \Re(g(t_{0})) = \Re(\alpha_{0}) = \alpha_{0}$
    \item[$\star$] $f'(t_{0} = \Re(g(t_{0}))' = \Re(g'(t_{0})) = \Re(\alpha_{1}) = \alpha_{1}$
\end{itemize}
Donc $f$ est une solution réelle définie sur $J$ au problème de Cauchy. 
\newline

\textbf{Unicité : }Soient $f_{1}$ et $f_{2}$ deux fonctions à valeurs réelles solutions du problème de Cauchy ci-dessus fixées quelconques : puisque $\mathbb{R} \subset \mathbb{C}$, $f_{1}$ et $f_{2}$ sont des fonctions à valeurs dans $\mathbb{C}$ solutions du même problème de Cauchy; or il y a unicité de la solution au problème de Cauchy dans les fonctions à valeurs complexes, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{C})$, donc $f_{1} = f_{2}$ dans $\mathcal{F}(J, \mathbb{R})$.
\end{question_kholle}

\begin{question_kholle}[
	\[
	    \left\{ \begin{array}{cl}
	        y'' +ay'+by = 0 \\
	        y(3) = 1\\
	        y'(3) = 0
	        \end{array} \right.        
		\quad \text{et} \quad
	    \left\{ \begin{array}{cl}
	        y'' +ay'+by = 0 \\
	        y(3) = 0\\
	        y'(3) = 1
	        \end{array} \right.
	\]
	
	Comment s'exprime la solution définie sur $\mathbb{R}$ de $\left\{ \begin{array}{cl}
	    y'' +ay'+by = 0 \\
	    y(3) = \alpha \\
	    y'(3) = \beta
	    \end{array} \right. $ pour $(\alpha, \beta)\in \mathbb{R}^2$ fixés ? 
	
	Peut-on affirmer que le plan vectoriel des solutions définies sur $\mathbb{R}$ à valeurs dans 
	$\mathbb{C}$ de $y'' + ay' + by = 0$ est $\{ \lambda \cdot f + \mu \cdot g  | 
	(\lambda, \mu)\in \mathbb{C}^2\}$
	]
	{Soient $(a,b)\in \mathbb{C}^2$, $f$ et $g$ les  solutions, définies sur $\mathbb{R}$ à valeurs
		dans $\mathbb{C}$, des problèmes de Cauchy suivants :}

    La solution s'exprime simplement comme combinaison linéaire de f et g, plus précisément, la 
    combinaison linéaire en $\alpha$ et $\beta$. En effet, soient de tels scalaires, et soient $f$ et 
    $g$ de telles solutions, on a : 
    \[
        (\alpha \cdot f + \beta \cdot g)'' + a (\alpha \cdot f + \beta \cdot g)' + b (\alpha \cdot f + 
        \beta \cdot g) = 0 \text{, par définition des espaces vectoriels.}
    \]
    Et de même, $(\alpha \cdot f + \beta \cdot g)'(3) = \alpha \cdot f'(3) + \beta \cdot g'(3) = \alpha$,
    et $(\alpha \cdot f + \beta \cdot g)''(3) = \alpha \cdot f''(3) + \beta \cdot g''(3) = \beta$.
    \newline
    Ce qui suffit par unicité des solutions ( de la donc) d'un problème de Cauchy dans le cadre du 
    théorème du cours.
    \newline
    Pour ce qui est du plan vectoriel des solutions, noté $\Omega$, notons aussi $\Phi$ l'ensemble proposé.
    L'inclusion $\Phi \subset \Omega$ est triviale par propriété de linéarité des espaces vectoriels.
    Finalement, pour $\Omega \subset \Phi$, soit $\omega \in \Omega$, forcément, $\omega$ vérifie 
    l'$EDL_2$, mais aussi des conditions de Cauchy bien que celles-ci soient non-spécifiées, ainsi
    posons $\omega'(3) = \delta$ et $\omega''(3) = \theta$, donc en particulier, $ \omega = 
    \delta \cdot f + \theta \cdot g$, d'où l'égalité par double inclusion.
\end{question_kholle}


\end{document}
