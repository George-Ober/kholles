\documentclass{article}

\date{02 Janvier 2025}
\usepackage[nb-sem=13, auteurs={Hugo Vangilluwen, George Ober, Kylian Boyet, Felix Rondeau}]{../kholles}
\begin{document}
\maketitle

\begin{question_kholle}
	[Pour une matrice $A \in \mathcal{M}_{(n,p)}(\K)$, la matrice transposée est définie par :
	{\begin{equation*}
		\forall (k, l) \in [\![1,p]\!] \!\times\! [\![1,n]\!], \ \left[A\transp\right]_{kl} = A_{lk}
	\end{equation*}}
	Formellement, la transposition est une application de $\mathcal{M}_{(n,p)}(\K)$ dans $\mathcal{M}_{(p,n)}(\K)$.]
	{Montrer que $\left(A \times B\right)\transp = B\transp \times A\transp$}

	Soient $n,p$ et $q$ trois entiers naturels.
	Soient $A \in \mathcal{M}_{n,p}(\K)$ et $B\in \mathcal{M}_{p,q}(\K)$. \\
	$A \times B \in \mathcal{M}_{n,p}(\K)$ donc $\left(A \times B\right)\transp \in \mathcal{M}_{q,n}(\K)$.
	Soit $(i, j) \in [\![1,q]\!] \!\times\! [\![1,n]\!]$.
	\begin{equation*}
		\begin{aligned}
			\left[ \left(A \times B\right)\transp \right]_{i,j}
			 & = \left[A \times B\right]_{j,i}                                                               \\
			 & = \sum_{k=1}^{p}\bigl(A_{j,k} \times_\K B_{k,i}\bigr)                                         \\
			 & = \sum_{k=1}^{p}\bigl(B_{k,i} \times_\K A_{j,k}\bigr)                                         \\
			 & = \sum_{k=1}^{p}\Bigl(\left[B\transp\right]_{i,k} \times_\K \left[A\transp\right]_{k,j}\Bigr) \\
			 & = \left[ \left(B\transp\right) \times \left(A\transp\right) \right]_{i,j}
		\end{aligned}
	\end{equation*}
\end{question_kholle}

\begin{question_kholle}
	[Le symbole de Kronecker est défini de la manière suivante :
	\begin{equation*}
		\forall (x, y) \in \R^2, \delta_{xy} = \left\{ \begin{matrix}
			0 \text{ si } x \neq y \\
			1 \text{ si } x = y
		\end{matrix} \right.
	\end{equation*}
	La matrice $E^{i,j} \in \mathcal{M}_{(n, p)}(\K)$ avec {$(i, j) \in [\![ 1, n ]\!] \!\times\! [\![ 1, p ]\!]$} ne possède que des coefficients nuls sauf le coefficient de la $i^{e}$ ligne et $j^{e}$ colonne qui vaut 1. Formellement :
	{\begin{equation*}
		\forall (r, s) \in [\![ 1, n ]\!] \times [\![ 1, p ]\!], \
		\left[E^{i,j}\right]_{rs} = \delta_{ir} \delta_{js}
	\end{equation*}}]
	{Calculer $E^{i,j} \times E^{k,l}$ en fonction de $i$, $j$, $k$, $l$ et des symboles de Kronecker}

	Calculons $E^{i,j}(n,p) \times E^{k,l}(p,q)$.\\
	Soient $(r, s) \in [ \! [ 1, n] \!] \times [ \! [ 1, q ] \!]$ fixées quelconques.
	\begin{align*}
		\left[ E^{i,j} \times E^{k,l} \right] _{rs}
		 & = \sum_{t = 1}^{n}E^{i,j}_{r,t} E^{k,l}_{t,s}                     \\
		 & =\sum_{t = 1}^{n} \delta_{ir} \delta_{jt} \delta_{kt} \delta_{ls} \\
		 & = \delta_{jk} \delta_{ir} \delta_{ls}                             \\
		 & = \delta_{jk} \left[ E^{i,l} \right] _{rs}
	\end{align*}

	Donc $E^{i,j} \times E^{k,l} = \delta_{jk} E^{i,l}$.


	Ainsi, pour le calcul de $(E^{i,j})^{2}$, $q \leftarrow n$, $k \leftarrow i$, $l \leftarrow j$ :

	\begin{align*}
		(E^{i,j})^{2} = \delta_{ji} E^{i,j} = \left\{
		\begin{array}{ll}
			E^{i,j} \text{ si } i = j \\
			0_{n,p} \text{ si } i \neq j
		\end{array}
		\right.
	\end{align*}

\end{question_kholle}

\begin{question_kholle}
	{Les matrices triangulaires supérieures forment un sous-anneau de $\mathcal{M}_n(\K)$}
	\hfill \\
	\begin{itemize}[label=$\star$]
		\item $\mathcal{T}_n^+(\K) \subset \mathcal(M)_n(\K)$ et $(\mathcal{M}_n(\K), +, \times)$ est un anneau.
		\item Le neutre mutiplicatif $I_{n}$ de l’anneau $\mathcal{M}_n(\K)$ appartient à $\mathcal{T}_n^+(\K)$.
		\item $\mathcal{T}_n^+(\K) \neq \emptyset$ car $I_n \in \mathcal{T}_n^+(\K)$.
		\item Soient $(A, B) \in \mathcal{T}_n^+(\K)^2$, et $(i, j) \in [\![1,n]\!]^2$ $\text{ tels que }$ $i > j$.
		      \begin{equation*}
			      (A - B)_{i,j}
			      = \underbrace{A_{i,j}}_{=0 \text{ car } A \in \mathcal{T}_n^+(\K)} - \underbrace{B_{i,j}}_{=0 \text{ car } B \in \mathcal{T}_n^+(\K)}
			      = 0
		      \end{equation*}
		      Donc, $A - B \in \mathcal{T}_n^+(\K)$.

		\item Soient $(A, B) \in \mathcal{T}_n^+(\K)^2$, et $(i, j) \in [\![1,n]\!]^2$ $\text{ tels que }$ $i > j$.
		      \begin{align*}
			      (A \times B)_{i,j}
			       & = \sum_{k=1}^{n} A_{i,k} \times_\K B_{k,j}                                                                                        \\
			       & = \sum_{k=1}^{j} \underbrace{A_{i,k}}_{=0 \text{ car } i > j \geqslant k \text{ et } A \in \mathcal{T}_n^+(\K)} \times_\K B_{k,j}
			      + \sum_{k=j+1}^{n} A_{i,k} \times_\K \underbrace{B_{k,j}}_{=0 \text{ car } k > j \text{ et } B \in \mathcal{T}_n^+(\K)}              \\
			       & = 0
		      \end{align*}
		      Donc, $A \times B \in \mathcal{T}_n^+(\K)$.
	\end{itemize}
	Ainsi, $\mathcal{T}_n^+(\K) \subset \mathcal(M)_n(\K)$ est un sous-anneau de $\mathcal{M}_n(\K)$.
\end{question_kholle}

\begin{question_kholle}
	{Pour $A\in\GL_{n}(\K)$ et $\lambda\in\K$, montrer que $A\transp$ et $\lambda A$ sont également dans $\GL_{n}(\K)$}
	Soient $A \in \GL_n(\mathbb{K})$ et $\lambda \in \mathbb{K}^*$. D’une part,
	\[
		A\transp \times (A^{-1})\transp = (A^{-1} \times  A)\transp = I_{n}\transp = I_{n}
	\]
	Et d’autre part,
	\[
		(A^{-1})\transp \times A\transp = (A \times A^{-1})\transp = I_{n}\transp = I_{n}
	\]
	Ainsi, $A\transp$ est inversible et $(A\transp)^{-1}=(A^{-1})\transp$.
	De même,
	\[
		\lambda \cdot A \times A^{-1} = \lambda \cdot I_{n} \iff (\lambda A) \times A^{-1} = \lambda \cdot I_{n} \iff (\lambda \cdot A)\left(\frac{1}{\lambda} \cdot A^{-1}\right) = I_{n}
	\]
	et
	\[
		\lambda \cdot A^{-1} \times A = \lambda \cdot I_{n} \iff A^{-1} \times (\lambda A) = \lambda \cdot I_{n} \iff \left(\frac{1}{\lambda} \cdot A^{-1}\right)(\lambda \cdot A) = I_{n}
	\]
	donc $\lambda A$ est inversible et son inverse est $\displaystyle\frac{1}{\lambda}A^{-1}$.
\end{question_kholle}

\begin{question_kholle}
	{Si $N\in\M_{n}(\N)$ est une matrice nilpotente, alors $I_n + \lambda N$ est inversible.}
	Soient $N\in\M_{n}(\K)$ une matrice nilpotente d’indice de nilpotence $k\in\K$, et $\lambda\in\K$. On remarque que
	\[
		(\lambda N)^{k} = (-\lambda)^{k}N^{k} = 0 \quad\text{car } N^{k}=0
	\]
	On a donc, comme $I_{n}$ et $-\lambda N$ commutent,
	\[
		I_{n} = I_{n}^{k} - (-\lambda N)^{k} = (I_{n}-(-\lambda N))\sum_{j=0}^{k-1}I_{n}^{j}(-\lambda N)^{k-j-1} = (I_{n}+\lambda N)\sum_{j=0}^{k-1}(\lambda N)^{k-j-1}
	\]
	ce qui signifie que $I_{n}+\lambda N$ est inversible à droite, donc inversible et d’inverse
	\[
		(I_{n} + \lambda N)^{-1} = \sum_{j=0}^{k-1}(-\lambda N)^{k-j-1}
	\]
\end{question_kholle}

\begin{question_kholle}
	[$A \in \mathcal{M}_n(\K)$ est inversible si et seulement si pour tout $Y \in \mathcal{M}_{n,1}(\K)$, l'équation $AX = Y$ d'inconnue $X \in \mathcal{M}_{n,1}$ admet une unique solution.]
	{Caractérisation de l'inversibilité pour les matrices}
	\hfill\\
	\begin{description}
		\item[$(\implies )$]
		      Supposons que $A \in \GL_n(\K)$.
		      Soit $Y \in \mathcal{M}_{n,1}(\K)$ \fq. \\
		      \[AX = Y \iff A^{-1}AX = A^{-1}Y \iff X = A^{-1}Y\]
		      donc l'équation $AX = Y$ d'inconnue $X \in \mathcal{M}_{n,1}$ admet une unique solution.

		\item[$(\impliedby)$] Supposons maintenant que pour tout $Y \in \mathcal{M}_{n,1}(\K)$, l’équation $AX = Y$ admet une unique solution.\\
		      Pour $i \in \iset{1,n}$, notons  $X_i$ la solution de $AX = E^{i,1}$. \\
		      Posons $\displaystyle B = \left[ \begin{array}{c|c|c|c}
					          &     &        &     \\
					      X_1 & X_2 & \ldots & X_n \\
					          &     &        &     \\
				      \end{array} \right]$. \\
		      Calculons $\displaystyle AB
			      = \left[ \begin{array}{c|c|c|c}
					           &      &        &      \\
					      AX_1 & AX_2 & \ldots & AX_n \\
					           &      &        &      \\
				      \end{array} \right]
			      = \left[ \begin{array}{c|c|c|c}
					              &         &        &         \\
					      E^{1,1} & E^{2,1} & \ldots & E^{n,1} \\
					              &         &        &         \\
				      \end{array} \right]
			      = I_n$. \\
		      Ainsi A est inversible à droite donc $A \in \GL_n(\K)$ et $A^{-1} = B$.
	\end{description}
\end{question_kholle}

\begin{question_kholle}
	[Une matrice diagonale est inversible si et seulement si tous ses coefficients diagonaux sont non nuls.]
	{Caractérisation des matrices diagonales inversibles}

	Soit $D \in \mathcal{D}_n(\K)$ de coefficients diagonaux $(d_1, d_2, \ldots, d_n) \in \K^n$. \\
	Soit $Y = \begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix} \in \mathcal{M}_{n,1}(\K)$.
	\'Etudions l'équation $DX = Y$ d'inconnue $X = \begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix} \in \mathcal{M}_{n,1}(\K)$ :
	\begin{equation*}
		DX = Y \iff
		\left\{ \begin{array}{cccccccccc}
			d_1 x_1 &         &        &         & = & y_1 &     &        &       \\
			        & d_2 x_2 &        &         & = &     & y_2 &        &     & \\
			        &         & \ddots &         & = &     &     & \ddots &       \\
			        &         &        & d_n x_n & = &     &     &        & y_n   \\
		\end{array} \right.
	\end{equation*}

	\begin{itemize}
		\item Si il existe $i_0 \in \iset{1,n}$ tel que $d_{i_0} = 0$, la $i_0$-ème ligne du système ci-dessus deviens une condition de compatibilité $0 = y_{i_0}$ qui ne sera pas respectée pour $Y = E^{i_0,1}$.\\
		      Donc $D \notin \GL_{n}(\K)$.
		\item Sinon $\forall i \in [\![1;n]\!] : d_i \neq 0$, le système est donc triangulaire à coefficients diagonaux non nuls. Il admet donc une unique solution. Ainsi $D \in \GL_{n}(\K)$. De plus,
		      \begin{equation*}
			      DX = Y \iff
			      \left\{ \begin{array}{cccccccccc}
				      x_1 &     &        &     & = & d_1^{-1} y_1 &              &        &                \\
				          & x_2 &        &     & = &              & d_2^{-1} y_2 &        &              & \\
				          &     & \ddots &     & = &              &              & \ddots &                \\
				          &     &        & x_n & = &              &              &        & d_n^{-1} y_n   \\
			      \end{array} \right.
		      \end{equation*}
		      Ainsi $D^{-1} = \diag\!\left(d_1^{-1}, d_2^{-1}, \ldots, d_n^{-1}\right)$.
	\end{itemize}
\end{question_kholle}
\end{document}
